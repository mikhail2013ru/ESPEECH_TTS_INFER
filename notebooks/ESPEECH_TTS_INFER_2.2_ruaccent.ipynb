{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F6YzVP_1AlhR",
        "outputId": "50a3b64e-634e-477f-b669-c7a6454cbfb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting f5-tts\n",
            "  Downloading f5_tts-1.1.7-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Collecting ruaccent\n",
            "  Downloading ruaccent-1.5.8.3-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
            "Requirement already satisfied: accelerate>=0.33.0 in /usr/local/lib/python3.12/dist-packages (from f5-tts) (1.10.0)\n",
            "Collecting bitsandbytes>0.37.0 (from f5-tts)\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Collecting cached_path (from f5-tts)\n",
            "  Downloading cached_path-1.7.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from f5-tts) (8.2.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from f5-tts) (4.0.0)\n",
            "Collecting ema_pytorch>=0.5.2 (from f5-tts)\n",
            "  Downloading ema_pytorch-0.7.7-py3-none-any.whl.metadata (689 bytes)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.35.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting hydra-core>=1.3.0 (from f5-tts)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.42.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from f5-tts) (3.10.0)\n",
            "Collecting numpy<=1.26.4 (from f5-tts)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<=2.10.6 (from f5-tts)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.25.1)\n",
            "Collecting pypinyin (from f5-tts)\n",
            "  Downloading pypinyin-0.55.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.6.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.13.1)\n",
            "Collecting tomli (from f5-tts)\n",
            "  Downloading tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchdiffeq (from f5-tts)\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from f5-tts) (4.67.1)\n",
            "Collecting transformers_stream_generator (from f5-tts)\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode (from f5-tts)\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting vocos (from f5-tts)\n",
            "  Downloading vocos-0.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.21.1)\n",
            "Collecting x_transformers>=1.31.14 (from f5-tts)\n",
            "  Downloading x_transformers-2.7.2-py3-none-any.whl.metadata (90 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Collecting gradio-client==1.10.4 (from gradio)\n",
            "  Downloading gradio_client-1.10.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.10.4->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.10.4->gradio) (15.0.1)\n",
            "Collecting onnxruntime (from ruaccent)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from ruaccent) (0.2.1)\n",
            "Collecting python-crfsuite (from ruaccent)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting razdel (from ruaccent)\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.33.0->f5-tts) (5.9.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.0->f5-tts) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.0->f5-tts) (4.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.10.6->f5-tts) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->f5-tts)\n",
            "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from x_transformers>=1.31.14->f5-tts) (0.8.1)\n",
            "Collecting einx>=0.3.0 (from x_transformers>=1.31.14->f5-tts)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting loguru (from x_transformers>=1.31.14->f5-tts)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting boto3<2.0,>=1.0 (from cached_path->f5-tts)\n",
            "  Downloading boto3-1.40.17-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from cached_path->f5-tts) (2.19.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->f5-tts) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->f5-tts) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->f5-tts) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->f5-tts) (0.70.16)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->f5-tts) (1.17.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (3.2.3)\n",
            "Collecting coloredlogs (from onnxruntime->ruaccent)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime->ruaccent) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime->ruaccent) (5.29.5)\n",
            "Collecting encodec==0.1.1 (from vocos->f5-tts)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->f5-tts) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->f5-tts) (4.3.8)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->f5-tts) (2.35.0)\n",
            "Collecting botocore<1.41.0,>=1.40.17 (from boto3<2.0,>=1.0->cached_path->f5-tts)\n",
            "  Downloading botocore-1.40.17-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.0->cached_path->f5-tts)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3<2.0,>=1.0->cached_path->f5-tts)\n",
            "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->f5-tts) (2.22)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx>=0.3.0->x_transformers>=1.31.14->f5-tts) (2.4.6)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->f5-tts) (4.0.12)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (1.7.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->f5-tts) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->f5-tts) (3.6.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->ruaccent)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->f5-tts) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (4.9.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (0.6.1)\n",
            "Downloading f5_tts-1.1.7-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.35.0-py3-none-any.whl (54.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.4-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruaccent-1.5.8.3-py2.py3-none-any.whl (22 kB)\n",
            "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ema_pytorch-0.7.7-py3-none-any.whl (9.8 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading x_transformers-2.7.2-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cached_path-1.7.3-py3-none-any.whl (36 kB)\n",
            "Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin-0.55.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Downloading tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vocos-0.1.0-py3-none-any.whl (24 kB)\n",
            "Downloading boto3-1.40.17-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.17-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers_stream_generator, encodec\n",
            "  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12426 sha256=333a252b5e108a2539bc509609afcfb5b28fc7406f8f79eb495f0d0172626bc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/58/d2/014cb67c3cc6def738c1b1635dbf4e3dab6fb63aba7070dce0\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=034091451cb5c73fb9a0d09bcc151bffeb20f0b03a588a4968af8cf63620d156\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/eb/9f/e13610cc46ab39d3199fbabebd1c3e142d44b679526e0f228a\n",
            "Successfully built transformers_stream_generator encodec\n",
            "Installing collected packages: razdel, unidecode, tomli, python-crfsuite, pypinyin, pydantic-core, numpy, loguru, jmespath, humanfriendly, pydantic, hydra-core, einx, coloredlogs, botocore, s3transfer, onnxruntime, gradio-client, x_transformers, torchdiffeq, gradio, ema_pytorch, boto3, bitsandbytes, transformers_stream_generator, ruaccent, encodec, vocos, cached_path, f5-tts\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.11.1\n",
            "    Uninstalling gradio_client-1.11.1:\n",
            "      Successfully uninstalled gradio_client-1.11.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.42.0\n",
            "    Uninstalling gradio-5.42.0:\n",
            "      Successfully uninstalled gradio-5.42.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "mcp 1.13.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.10.6 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.47.0 boto3-1.40.17 botocore-1.40.17 cached_path-1.7.3 coloredlogs-15.0.1 einx-0.3.0 ema_pytorch-0.7.7 encodec-0.1.1 f5-tts-1.1.7 gradio-5.35.0 gradio-client-1.10.4 humanfriendly-10.0 hydra-core-1.3.2 jmespath-1.0.1 loguru-0.7.3 numpy-1.26.4 onnxruntime-1.22.1 pydantic-2.10.6 pydantic-core-2.27.2 pypinyin-0.55.0 python-crfsuite-0.9.11 razdel-0.5.0 ruaccent-1.5.8.3 s3transfer-0.13.1 tomli-2.2.1 torchdiffeq-0.2.5 transformers_stream_generator-0.0.5 unidecode-1.4.0 vocos-0.1.0 x_transformers-2.7.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "380b02460b5e481784b8f0097d255744",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install f5-tts gradio ruaccent runorm transformers torch torchaudio huggingface_hub soundfile pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXMWDSiTA_Gf"
      },
      "outputs": [],
      "source": [
        "# ĞĞĞ–ĞĞ¢Ğ¬ RESTART SESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i90o6-p9AvOA",
        "outputId": "f9458d9f-4cad-4393-b9f2-b4b4f08af84d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking CUDA availability...\n",
            "CUDA is available. Using device: Tesla T4\n",
            "Preloading model...\n",
            "CUDA is available. Using device: Tesla T4\n",
            "Trying to download model file 'espeech_tts_rlv2.pt' and 'vocab.txt' from hub 'ESpeech/ESpeech-TTS-1_RL-V2'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded model to /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/espeech_tts_rlv2.pt\n",
            "Downloaded vocab to /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/vocab.txt\n",
            "Loading model from: /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/espeech_tts_rlv2.pt\n",
            "\n",
            "vocab :  /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/vocab.txt\n",
            "token :  custom\n",
            "model :  /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/espeech_tts_rlv2.pt \n",
            "\n",
            "Model loaded and moved to CUDA: cuda\n",
            "Model preloaded.\n",
            "Loading RUAccent...\n",
            "RUAccent loaded.\n",
            "Preloading vocoder...\n",
            "CUDA is available. Using device: Tesla T4\n",
            "Loading vocoder...\n",
            "Download Vocos from huggingface charactr/vocos-mel-24khz\n",
            "Vocoder loaded and moved to CUDA: cuda\n",
            "Vocoder preloaded.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://29f0abcf0bb8391bb1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://29f0abcf0bb8391bb1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import gc\n",
        "import tempfile\n",
        "import traceback\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from huggingface_hub import hf_hub_download, snapshot_download\n",
        "from ruaccent import RUAccent\n",
        "from runorm import RUNorm\n",
        "from f5_tts.infer.utils_infer import (\n",
        "    infer_process,\n",
        "    load_model,\n",
        "    load_vocoder,\n",
        "    preprocess_ref_audio_text,\n",
        "    remove_silence_for_generated_wav,\n",
        "    save_spectrogram,\n",
        "    tempfile_kwargs,\n",
        ")\n",
        "from f5_tts.model import DiT\n",
        "\n",
        "# ğŸ”¹ Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ ÑÑ‚Ğ¸ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ´Ğ»Ñ Whisper\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    \"ESpeech-TTS-1_SFT-95K\": {\n",
        "        \"repo\": \"ESpeech/ESpeech-TTS-1_SFT-95K\",\n",
        "        \"model_file\": \"espeech_tts_95k.pt\",\n",
        "        \"vocab_file\": \"vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"ESpeech-TTS-1_RL-V1\": {\n",
        "        \"repo\": \"ESpeech/ESpeech-TTS-1_RL-V1\",\n",
        "        \"model_file\": \"espeech_tts_rlv1.pt\",\n",
        "        \"vocab_file\": \"vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"ESpeech-TTS-1_RL-V2\": {\n",
        "        \"repo\": \"ESpeech/ESpeech-TTS-1_RL-V2\",\n",
        "        \"model_file\": \"espeech_tts_rlv2.pt\",\n",
        "        \"vocab_file\": \"vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"F5TTS_v1_Base_v2_Misha24-10\": {\n",
        "        \"repo\": \"Misha24-10/F5-TTS_RUSSIAN\",\n",
        "        \"model_file\": \"F5TTS_v1_Base_v2/model_last_inference.safetensors\",\n",
        "        \"vocab_file\": \"F5TTS_v1_Base/vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"F5TTS_v1_Base_1.25M_SWivid\": {\n",
        "    \"repo\": \"SWivid/F5-TTS\",\n",
        "    \"model_file\": \"F5TTS_v1_Base/model_1250000.safetensors\",\n",
        "    \"vocab_file\": \"F5TTS_v1_Base/vocab.txt\",\n",
        "    \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "}\n",
        "\n",
        "# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "loaded_models = {}\n",
        "loaded_vocoder = None\n",
        "current_model_name = None\n",
        "stop_generation = False\n",
        "remember_seed = False\n",
        "last_seed = -1\n",
        "\n",
        "# ğŸ”´ ĞĞĞ’ĞĞ•: Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "local_models_config = {}\n",
        "\n",
        "def check_cuda_availability():\n",
        "    \"\"\"Check if CUDA is available and raise error if not\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA is not available! This application requires GPU with CUDA support.\")\n",
        "    print(f\"CUDA is available. Using device: {torch.cuda.get_device_name()}\")\n",
        "\n",
        "def add_local_model(model_path, vocab_path, model_name):\n",
        "    \"\"\"Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ\"\"\"\n",
        "    global local_models_config, MODELS_CONFIG\n",
        "    \n",
        "    if not model_path or not vocab_path or not model_name:\n",
        "        return gr.update(value=\"âŒ Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ²ÑĞµ Ğ¿Ğ¾Ğ»Ñ\", visible=True)\n",
        "    \n",
        "    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²\n",
        "    if not os.path.exists(model_path):\n",
        "        return gr.update(value=\"âŒ Ğ¤Ğ°Ğ¹Ğ» Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½\", visible=True)\n",
        "    \n",
        "    if not os.path.exists(vocab_path):\n",
        "        return gr.update(value=\"âŒ Ğ¤Ğ°Ğ¹Ğ» ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½\", visible=True)\n",
        "    \n",
        "    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ\n",
        "    local_models_config[model_name] = {\n",
        "        \"repo\": \"local\",\n",
        "        \"model_file\": model_path,\n",
        "        \"vocab_file\": vocab_path,\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    }\n",
        "    \n",
        "    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    updated_models_config = {**MODELS_CONFIG, **local_models_config}\n",
        "    \n",
        "    return gr.update(\n",
        "        choices=list(updated_models_config.keys()),\n",
        "        value=model_name\n",
        "    ), gr.update(value=f\"âœ… Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ '{model_name}' Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ°\", visible=True)\n",
        "\n",
        "def load_model_with_progress(model_name, progress_callback=None):\n",
        "    \"\"\"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°\"\"\"\n",
        "    global loaded_models, current_model_name, stop_generation, MODELS_CONFIG, local_models_config\n",
        "    \n",
        "    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ„Ğ»Ğ°Ğ³Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸\n",
        "    if stop_generation:\n",
        "        return None\n",
        "    \n",
        "    # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    all_models_config = {**MODELS_CONFIG, **local_models_config}\n",
        "    \n",
        "    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²\n",
        "    if not model_name or model_name not in all_models_config:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "    \n",
        "    # Ğ•ÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ĞµÑ‘\n",
        "    if model_name in loaded_models:\n",
        "        return loaded_models[model_name]\n",
        "    \n",
        "    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "    config = all_models_config[model_name]\n",
        "    \n",
        "    # ğŸ”´ Ğ”Ğ›Ğ¯ Ğ›ĞĞšĞĞ›Ğ¬ĞĞ«Ğ¥ ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™ - ĞŸĞ ĞĞ’Ğ•Ğ Ğ¯Ğ•Ğœ Ğ¤ĞĞ™Ğ›Ğ«\n",
        "    if config['repo'] == \"local\":\n",
        "        model_path = config['model_file']\n",
        "        vocab_path = config['vocab_file']\n",
        "        \n",
        "        if not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"Local model file not found: {model_path}\")\n",
        "        if not os.path.exists(vocab_path):\n",
        "            raise FileNotFoundError(f\"Local vocab file not found: {vocab_path}\")\n",
        "            \n",
        "        print(f\"Loading local model from: {model_path}\")\n",
        "        \n",
        "    else:\n",
        "        # Ğ¡Ñ‚Ğ°Ñ€Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ· HuggingFace\n",
        "        if progress_callback:\n",
        "            progress_callback(\"ğŸ” ĞŸĞ¾Ğ¸ÑĞº Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...\", 0.1)\n",
        "        \n",
        "        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ CUDA\n",
        "        check_cuda_availability()\n",
        "\n",
        "        model_path = None\n",
        "        vocab_path = None\n",
        "        \n",
        "        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ\n",
        "        if progress_callback:\n",
        "            progress_callback(\"ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...\", 0.3)\n",
        "        \n",
        "        # Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "        try:\n",
        "            model_path = hf_hub_download(repo_id=config['repo'], filename=config['model_file'])\n",
        "            vocab_path = hf_hub_download(repo_id=config['repo'], filename=config['vocab_file'])\n",
        "            print(f\"Downloaded model to {model_path}\")\n",
        "            print(f\"Downloaded vocab to {vocab_path}\")\n",
        "        except Exception as e:\n",
        "            print(\"hf_hub_download failed:\", e)\n",
        "            \n",
        "        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ„Ğ»Ğ°Ğ³ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸\n",
        "        if stop_generation:\n",
        "            return None\n",
        "            \n",
        "        # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹, Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ²ÑÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n",
        "        if model_path is None or vocab_path is None:\n",
        "            try:\n",
        "                local_dir = f\"cache_{config['repo'].replace('/', '_')}\"\n",
        "                if progress_callback:\n",
        "                    progress_callback(\"ğŸ“¦ Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...\", 0.5)\n",
        "                snapshot_dir = snapshot_download(repo_id=config['repo'], cache_dir=None, local_dir=local_dir)\n",
        "                possible_model = os.path.join(snapshot_dir, config['model_file'])\n",
        "                possible_vocab = os.path.join(snapshot_dir, config['vocab_file'])\n",
        "                if os.path.exists(possible_model):\n",
        "                    model_path = possible_model\n",
        "                if os.path.exists(possible_vocab):\n",
        "                    vocab_path = possible_vocab\n",
        "            except Exception as e:\n",
        "                print(\"snapshot_download failed:\", e)\n",
        "                \n",
        "        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ„Ğ»Ğ°Ğ³ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸\n",
        "        if stop_generation:\n",
        "            return None\n",
        "            \n",
        "        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñ‹ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‚\n",
        "        if not model_path or not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
        "        if not vocab_path or not os.path.exists(vocab_path):\n",
        "            raise FileNotFoundError(f\"Vocab file not found: {vocab_path}\")\n",
        "\n",
        "    # ğŸ”´ ĞĞ‘Ğ©ĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ˜ ĞœĞĞ”Ğ•Ğ›Ğ˜\n",
        "    if progress_callback:\n",
        "        progress_callback(\"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ...\", 0.7)\n",
        "    \n",
        "    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n",
        "    print(f\"Loading model from: {model_path}\")\n",
        "    model = load_model(DiT, config['model_cfg'], model_path, vocab_file=vocab_path)\n",
        "\n",
        "    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ„Ğ»Ğ°Ğ³ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸\n",
        "    if stop_generation:\n",
        "        return None\n",
        "        \n",
        "    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ\n",
        "    if progress_callback:\n",
        "        progress_callback(\"ğŸš€ ĞŸĞµÑ€ĞµĞ½Ğ¾Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° GPU...\", 0.9)\n",
        "    \n",
        "    # ĞŸĞµÑ€ĞµĞ¼ĞµÑ‰Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° GPU\n",
        "    device = torch.device(\"cuda\")\n",
        "    model.to(device)\n",
        "    print(f\"Model loaded and moved to CUDA: {device}\")\n",
        "\n",
        "    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² ĞºÑÑˆ\n",
        "    loaded_models[model_name] = model\n",
        "    current_model_name = model_name\n",
        "\n",
        "    # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°\n",
        "    if progress_callback:\n",
        "        progress_callback(\"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°!\", 1.0)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def ensure_model(model_name, progress_callback=None):\n",
        "    \"\"\"Ensure model is loaded with progress tracking\"\"\"\n",
        "    global loaded_models, MODELS_CONFIG, local_models_config\n",
        "    \n",
        "    if not model_name:\n",
        "        raise ValueError(\"Model name must be specified\")\n",
        "    \n",
        "    # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    all_models_config = {**MODELS_CONFIG, **local_models_config}\n",
        "    \n",
        "    if model_name not in all_models_config:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "    \n",
        "    # Ğ•ÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ĞµÑ‘\n",
        "    if model_name in loaded_models:\n",
        "        return loaded_models[model_name]\n",
        "    \n",
        "    # Ğ˜Ğ½Ğ°Ñ‡Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ñ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°\n",
        "    return load_model_with_progress(model_name, progress_callback)\n",
        "\n",
        "def ensure_vocoder():\n",
        "    global loaded_vocoder\n",
        "    if loaded_vocoder is not None:\n",
        "        return loaded_vocoder\n",
        "\n",
        "    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° CUDA\n",
        "    check_cuda_availability()\n",
        "\n",
        "    print(\"â³ Loading vocoder...\")\n",
        "    \n",
        "    try:\n",
        "        loaded_vocoder = load_vocoder()\n",
        "        device = torch.device(\"cuda\")\n",
        "        loaded_vocoder.to(device)\n",
        "        print(\"âœ… Vocoder loaded successfully\")\n",
        "        return loaded_vocoder\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Vocoder loading failed: {e}\")\n",
        "        raise e\n",
        "\n",
        "def stop_generation_process():\n",
        "    \"\"\"ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸\"\"\"\n",
        "    global stop_generation\n",
        "    stop_generation = True\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return \"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\"\n",
        "\n",
        "def reset_stop_flag():\n",
        "    \"\"\"Ğ¡Ğ±Ñ€Ğ¾Ñ Ñ„Ğ»Ğ°Ğ³Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸\"\"\"\n",
        "    global stop_generation\n",
        "    stop_generation = False\n",
        "\n",
        "# --- Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° RUNorm ---\n",
        "print(\"Loading RUNorm (text normalizer)...\")\n",
        "try:\n",
        "    normalizer = RUNorm()\n",
        "    normalizer.load(\n",
        "        model_size=\"medium\",\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        workdir=\"./local_cache\"  # ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    )\n",
        "    print(\"RUNorm loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load RUNorm: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# --- Check CUDA ---\n",
        "print(\"Loading RUAccent...\")\n",
        "accentizer = RUAccent()\n",
        "accentizer.load(omograph_model_size='turbo3.1', use_dictionary=True, tiny_mode=False)\n",
        "print(\"RUAccent loaded.\")\n",
        "\n",
        "\n",
        "print(\"Loading Whisper ASR model (supports Russian and English)...\")\n",
        "try:\n",
        "    from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "    ASR_MODEL_NAME = \"openai/whisper-medium\"  # Ğ‘Ñ‹ÑÑ‚Ñ€Ğ¾ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾. ĞœĞ¾Ğ¶Ğ½Ğ¾: \"openai/whisper-base\", \"medium\", \"large-v3\"\n",
        "    asr_processor = WhisperProcessor.from_pretrained(ASR_MODEL_NAME)\n",
        "    asr_model = WhisperForConditionalGeneration.from_pretrained(ASR_MODEL_NAME)\n",
        "    asr_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Whisper model loaded. Supports Russian, English, and many other languages.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load Whisper model: {e}\")\n",
        "    asr_processor = None\n",
        "    asr_model = None\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    if not audio_path or asr_processor is None or asr_model is None:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        # 1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "        # 2. Ğ ĞµÑĞµĞ¼Ğ¿Ğ»Ğ¸Ğ½Ğ³ Ğ² 16 ĞºĞ“Ñ†\n",
        "        if sample_rate != 16000:\n",
        "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "            waveform = resampler(waveform)\n",
        "\n",
        "        # 3. ĞœĞ¾Ğ½Ğ¾\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # 4. Ğ’ numpy\n",
        "        input_audio = waveform.squeeze().numpy()\n",
        "\n",
        "        # 5. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°: Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ input_features (Ğ±ĞµĞ· Ğ¿Ğ°Ğ´Ğ´Ğ¸Ğ½Ğ³Ğ°)\n",
        "        inputs = asr_processor(\n",
        "            input_audio,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\",\n",
        "            # â— Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ padding Ğ¸ attention_mask â€” Ğ±ÑƒĞ´ĞµĞ¼ Ğ¿Ğ°Ğ´Ğ¸Ñ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ\n",
        "        )\n",
        "\n",
        "        input_features = inputs.input_features  # [1, 80, T], Ğ³Ğ´Ğµ T < 3000\n",
        "\n",
        "        # ğŸ”¹ ğŸ”¥ Ğ Ğ£Ğ§ĞĞĞ™ ĞŸĞĞ”Ğ”Ğ˜ĞĞ“ Ğ”Ğ 3000\n",
        "        current_length = input_features.shape[-1]\n",
        "        if current_length < 3000:\n",
        "            pad_length = 3000 - current_length\n",
        "            input_features = torch.nn.functional.pad(input_features, (0, pad_length), mode='constant', value=0)\n",
        "        elif current_length > 3000:\n",
        "            input_features = input_features[..., :3000]  # Ğ¾Ğ±Ñ€ĞµĞ·Ğ°ĞµĞ¼, ĞµÑĞ»Ğ¸ Ğ²Ğ´Ñ€ÑƒĞ³ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ\n",
        "\n",
        "        print(\"Input features shape:\", input_features.shape)  # Ğ”Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ğ±Ñ‹Ñ‚ÑŒ [1, 80, 3000]\n",
        "\n",
        "        # 6. ĞŸĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼ Ğ½Ğ° GPU\n",
        "        input_features = input_features.to(asr_model.device)\n",
        "\n",
        "        # 7. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ\n",
        "        with torch.no_grad():\n",
        "            generated_ids = asr_model.generate(\n",
        "                input_features=input_features,\n",
        "                language=None,\n",
        "                task=\"transcribe\",\n",
        "            )\n",
        "\n",
        "        # 8. Ğ”ĞµÑ†Ğ¾Ğ´Ğ¸Ğ½Ğ³\n",
        "        transcription = asr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        return transcription.strip().capitalize() + \".\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"ASR transcription failed:\", e)\n",
        "        return \"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ.\"\n",
        "# --- ĞšĞ¾Ğ½ĞµÑ† Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ ---\n",
        "\n",
        "def validate_and_transcribe_audio(audio_path):\n",
        "    if not audio_path:\n",
        "        return None, \"\", gr.update(value=\"\", visible=False)\n",
        "\n",
        "    try:\n",
        "        # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¾Ğº\n",
        "        transcription = transcribe_audio(audio_path)\n",
        "        \n",
        "        # âœ… Ğ’ÑĞµĞ³Ğ´Ğ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»\n",
        "        return audio_path, transcription, gr.update(value=\"\", visible=False)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Validation failed:\", e)\n",
        "        return None, \"\", gr.update(value=\"âš ï¸ **ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞµ Ğ°ÑƒĞ´Ğ¸Ğ¾**\", visible=True)\n",
        "\n",
        "# Check CUDA availability at startup\n",
        "print(\"Checking CUDA availability...\")\n",
        "try:\n",
        "    check_cuda_availability()\n",
        "except RuntimeError as e:\n",
        "    print(f\"FATAL ERROR: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# --- ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ°: Ğ¡ĞĞĞ§ĞĞ›Ğ runorm, ĞŸĞĞ¢ĞĞœ ruaccent ---\n",
        "def process_text_with_accent(text):\n",
        "    if not text or not text.strip():\n",
        "        return text\n",
        "\n",
        "    # --- 1. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°: ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ (+) Ğ² ÑĞ»Ğ¾Ğ²Ğ°Ñ…? ---\n",
        "    # Ğ˜Ñ‰ĞµĞ¼ + Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±ÑƒĞºĞ²Ğ°Ğ¼Ğ¸: \"Ğ¿Ñ€Ğ¸Ğ²+ĞµÑ‚\", \"Ğ²Ñ‹Ñ+Ğ¾ĞºĞ¸Ğ¹\", Ğ½Ğ¾ Ğ½Ğµ \"5 + 3\"\n",
        "    has_accent_in_words = bool(re.search(r'\\w\\+\\w', text))\n",
        "    # ---\n",
        "\n",
        "    # --- 2. Ğ•ÑĞ»Ğ¸ ĞĞ•Ğ¢ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ğ¹ â†’ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· runorm ---\n",
        "    if not has_accent_in_words:\n",
        "        try:\n",
        "            # Ğ—Ğ°Ğ¼ĞµĞ½ÑĞµĞ¼ + Ğ½Ğ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ», Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ runorm Ğ½Ğµ Ñ‚Ñ€Ğ¾Ğ³Ğ°Ğ» ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ\n",
        "            text_safe = text.replace(\"+\", \"âš¡\")\n",
        "            text_normalized = normalizer.norm(text_safe)\n",
        "            # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ + Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ (Ğ½Ğ° Ğ²ÑÑĞºĞ¸Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹)\n",
        "            text = text_normalized.replace(\"âš¡\", \"+\")\n",
        "        except Exception as e:\n",
        "            print(f\"runorm.norm() failed: {e}\")\n",
        "            text = text\n",
        "    else:\n",
        "        # Ğ£Ğ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ ÑƒĞ¶Ğµ ĞµÑÑ‚ÑŒ â†’ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ runorm\n",
        "        text = text\n",
        "    # ---\n",
        "\n",
        "    # --- 3. Ğ Ğ°ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· ruaccent (ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ +) ---\n",
        "    if '+' in text:\n",
        "        return text\n",
        "    try:\n",
        "        return accentizer.process_all(text)\n",
        "    except Exception as e:\n",
        "        print(f\"ruaccent failed: {e}\")\n",
        "        return text\n",
        "\n",
        "def process_texts_only(ref_text, gen_text):\n",
        "    # Ğ‘Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¿ÑƒÑ‚ĞµĞ¹ Ğº Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼\n",
        "    if ref_text and isinstance(ref_text, str):\n",
        "        if any(bad in ref_text for bad in [\"/tmp/\", \".wav\", \".mp3\", \".ogg\", \".flac\", \"/home/\", \"/root/\"]):\n",
        "            ref_text = \"\"  # Ğ¸Ğ»Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼\n",
        "    return (\n",
        "        process_text_with_accent(ref_text),\n",
        "        process_text_with_accent(gen_text)\n",
        "    )\n",
        "\n",
        "def get_current_seed_display():\n",
        "    \"\"\"ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ seed Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\"\"\"\n",
        "    global last_seed\n",
        "    # Ğ•ÑĞ»Ğ¸ last_seed ĞµÑ‰Ğµ Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½, Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹\n",
        "    if last_seed == -1:\n",
        "        last_seed = np.random.randint(0, 2**31 - 1)\n",
        "        print(f\"ğŸ² Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ seed: {last_seed}\")\n",
        "    return last_seed\n",
        "\n",
        "# ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯: ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "def update_model_loading_status(model_name):\n",
        "    \"\"\"ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\"\"\"\n",
        "    global loaded_models, MODELS_CONFIG, local_models_config\n",
        "    \n",
        "    if not model_name:\n",
        "        return gr.update(value=\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    all_models_config = {**MODELS_CONFIG, **local_models_config}\n",
        "    \n",
        "    if model_name not in all_models_config:\n",
        "        return gr.update(value=f\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_name} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    # ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚\n",
        "    if model_name in loaded_models:\n",
        "        model_type = \"ğŸ”§ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ\" if all_models_config[model_name]['repo'] == \"local\" else \"ğŸŒ HuggingFace\"\n",
        "        return gr.update(value=f\"<div class='model-status model-loaded'>âœ… {model_name} ({model_type}) Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°</div>\", visible=True)\n",
        "    else:\n",
        "        # ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ \"Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°\" Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°\n",
        "        model_type = \"ğŸ”§ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ\" if all_models_config[model_name]['repo'] == \"local\" else \"ğŸŒ HuggingFace\"\n",
        "        return gr.update(value=f\"<div class='model-status model-loading'>ğŸ”„ {model_name} ({model_type}) Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°</div>\", visible=True)\n",
        "\n",
        "# ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯: Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ°\n",
        "def load_model_with_status(model_name, progress=gr.Progress()):\n",
        "    \"\"\"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ°\"\"\"\n",
        "    global loaded_models\n",
        "    \n",
        "    if not model_name:\n",
        "        return gr.update(value=\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    # Ğ•ÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°, Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ\n",
        "    if model_name in loaded_models:\n",
        "        return update_model_loading_status(model_name)\n",
        "    \n",
        "    try:\n",
        "        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸\n",
        "        progress(0.1, desc=\"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...\")\n",
        "        \n",
        "        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n",
        "        model = load_model_with_progress(model_name, lambda msg, p: progress(p, desc=msg))\n",
        "        \n",
        "        if model:\n",
        "            # Ğ£ÑĞ¿ĞµÑˆĞ½Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°\n",
        "            return update_model_loading_status(model_name)\n",
        "        else:\n",
        "            return gr.update(value=\"<div class='model-status model-error'>âŒ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¾Ñ‚Ğ¼ĞµĞ½ĞµĞ½Ğ°</div>\", visible=True)\n",
        "            \n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸: {str(e)}\"\n",
        "        print(f\"Model loading error: {traceback.format_exc()}\")\n",
        "        return gr.update(value=f\"<div class='model-status model-error'>{error_msg}</div>\", visible=True)\n",
        "\n",
        "def on_model_select(model_name):\n",
        "    \"\"\"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² dropdown\"\"\"\n",
        "    global MODELS_CONFIG, local_models_config\n",
        "    \n",
        "    if not model_name:\n",
        "        return gr.update(value=\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    all_models_config = {**MODELS_CONFIG, **local_models_config}\n",
        "    \n",
        "    if model_name not in all_models_config:\n",
        "        return gr.update(value=f\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_name} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    # ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ±ĞµĞ· Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸\n",
        "    return update_model_loading_status(model_name)\n",
        "\n",
        "def synthesize(\n",
        "    ref_audio,\n",
        "    ref_text,\n",
        "    gen_text,\n",
        "    remove_silence,\n",
        "    seed_input_value,\n",
        "    remember_seed_checkbox,\n",
        "    model_choice,\n",
        "    cross_fade_duration=0.15,\n",
        "    nfe_step=32,\n",
        "    speed=1.0,\n",
        "    sway_sampling_coef=-1,\n",
        "    cfg_strength=2,\n",
        "    audio_format=\"wav\",\n",
        "    bitrate=\"192k\",\n",
        "    progress=gr.Progress()\n",
        "):\n",
        "    global stop_generation, last_seed, remember_seed\n",
        "    \n",
        "    # ğŸ”´ ĞĞ‘ĞĞĞ’Ğ›Ğ¯Ğ•Ğœ Ğ¤Ğ›ĞĞ“ Ğ—ĞĞŸĞĞœĞ˜ĞĞĞĞ˜Ğ¯ Ğ¡Ğ˜Ğ”Ğ\n",
        "    remember_seed = remember_seed_checkbox\n",
        "    \n",
        "    reset_stop_flag()\n",
        "    \n",
        "    # ğŸ”´ Ğ¡Ğ ĞĞ—Ğ£ ĞĞ‘ĞĞĞ’Ğ›Ğ¯Ğ•Ğœ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ ĞœĞĞ”Ğ•Ğ›Ğ˜\n",
        "    current_model_status = update_model_loading_status(model_choice)\n",
        "    \n",
        "    # ğŸ”´ Ğ ĞĞĞĞ¯Ğ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "    if stop_generation:\n",
        "        gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "    \n",
        "    # ğŸ”„ ĞĞ‘ĞĞĞ’Ğ›Ğ¯Ğ•Ğœ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ˜\n",
        "    progress(0.05, desc=\"ğŸ”„ ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ°...\")\n",
        "    \n",
        "    # ğŸ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ’Ğ¥ĞĞ”ĞĞ«Ğ¥ Ğ”ĞĞĞĞ«Ğ¥\n",
        "    if not ref_audio:\n",
        "        gr.Warning(\"âŒ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ğ¾Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "    \n",
        "    if not gen_text or not gen_text.strip():\n",
        "        gr.Warning(\"âŒ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "        \n",
        "    if not ref_text or not ref_text.strip():\n",
        "        gr.Warning(\"âŒ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "\n",
        "    # ğŸ” Ğ—ĞĞ©Ğ˜Ğ¢Ğ ĞĞ¢ ĞŸĞ£Ğ¢Ğ•Ğ™ Ğš Ğ¤ĞĞ™Ğ›ĞĞœ\n",
        "    if gen_text and isinstance(gen_text, str):\n",
        "        if any(x in gen_text for x in [\"/tmp/\", \".wav\", \".mp3\", \".ogg\", \".flac\"]):\n",
        "            gr.Warning(\"âš ï¸ ĞŸĞ¾Ğ»Ğµ 'Text to Generate' ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ¿ÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚ĞµĞºÑÑ‚ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ.\")\n",
        "            return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "\n",
        "    # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "    if stop_generation:\n",
        "        gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "\n",
        "    # ğŸ² Ğ£Ğ¡Ğ¢ĞĞĞĞ’ĞšĞ SEED - ĞšĞ›Ğ®Ğ§Ğ•Ğ’ĞĞ• Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ•!\n",
        "    current_seed = seed_input_value\n",
        "    if seed_input_value is None or seed_input_value < 0 or seed_input_value > 2**31 - 1:\n",
        "        # ğŸ”´ Ğ“Ğ•ĞĞ•Ğ Ğ˜Ğ Ğ£Ğ•Ğœ Ğ¡Ğ›Ğ£Ğ§ĞĞ™ĞĞ«Ğ™ Ğ¡Ğ˜Ğ”\n",
        "        current_seed = np.random.randint(0, 2**31 - 1)\n",
        "        print(f\"ğŸ² Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ seed: {current_seed}\")\n",
        "    \n",
        "    # ğŸ”´ Ğ—ĞĞŸĞĞœĞ˜ĞĞĞ•Ğœ Ğ¡Ğ˜Ğ” Ğ•Ğ¡Ğ›Ğ˜ Ğ’ĞšĞ›Ğ®Ğ§Ğ•ĞĞ Ğ“ĞĞ›ĞĞ§ĞšĞ\n",
        "    if remember_seed:\n",
        "        last_seed = current_seed\n",
        "        print(f\"ğŸ’¾ Seed ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {current_seed}\")\n",
        "    \n",
        "    torch.manual_seed(int(current_seed))\n",
        "    \n",
        "    # ğŸ”´ Ğ’Ğ«Ğ’ĞĞ”Ğ˜Ğœ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ® Ğ Ğ¡Ğ˜Ğ”Ğ•\n",
        "    print(f\"ğŸ² Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ seed: {current_seed} (Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚ÑŒ: {remember_seed})\")\n",
        "\n",
        "    # ğŸ“ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ\n",
        "    progress(0.08, desc=\"ğŸ“ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ°...\")\n",
        "\n",
        "    # --- âœ… Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚Ñ‹ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ ---\n",
        "    processed_ref_text = ref_text\n",
        "    processed_gen_text = gen_text\n",
        "\n",
        "    # --- âœ… Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ processed_ref_text_final Ğ”Ğ try ---\n",
        "    processed_ref_text_final = ref_text  \n",
        "\n",
        "    try:\n",
        "        # --- 1. ĞĞ¢Ğ›ĞĞ–Ğ•ĞĞĞĞ¯ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™ ---\n",
        "        progress(0.1, desc=\"ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹...\")\n",
        "        \n",
        "        # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        # ğŸ“¥ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ ĞĞ¡ĞĞĞ’ĞĞĞ™ ĞœĞĞ”Ğ•Ğ›Ğ˜\n",
        "        progress(0.15, desc=\"ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ TTS...\")\n",
        "        model = ensure_model(model_choice, lambda msg, p: progress(p, desc=msg))\n",
        "        \n",
        "        # ğŸ”´ ĞĞ‘ĞĞĞ’Ğ›Ğ¯Ğ•Ğœ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ ĞŸĞĞ¡Ğ›Ğ• Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ˜ ĞœĞĞ”Ğ•Ğ›Ğ˜\n",
        "        if model:\n",
        "            current_model_status = update_model_loading_status(model_choice)\n",
        "        \n",
        "        # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        # ğŸ”Š Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ’ĞĞšĞĞ”Ğ•Ğ Ğ (ĞĞ¢Ğ›ĞĞ–Ğ•ĞĞĞĞ¯)\n",
        "        progress(0.2, desc=\"ğŸ”Š Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ²Ğ¾ĞºĞ¾Ğ´ĞµÑ€Ğ°...\")\n",
        "        vocoder = ensure_vocoder()\n",
        "        \n",
        "        # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "            \n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: {str(e)}\"\n",
        "        gr.Warning(error_msg)\n",
        "        print(f\"Model loading error: {traceback.format_exc()}\")\n",
        "        return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "    # ğŸ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞĞ™ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ˜\n",
        "    if model is None or vocoder is None:\n",
        "        gr.Warning(\"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\")\n",
        "        return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    try:\n",
        "        # --- 2. ĞŸĞ Ğ•Ğ”ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ ĞĞ£Ğ”Ğ˜Ğ Ğ˜ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ ---\n",
        "        progress(0.3, desc=\"ğŸ”§ ĞŸÑ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾...\")\n",
        "        \n",
        "        # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        try:\n",
        "            ref_audio_proc, processed_ref_text_final = preprocess_ref_audio_text(\n",
        "                ref_audio,\n",
        "                processed_ref_text,\n",
        "                show_info=gr.Info\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: {str(e)}\"\n",
        "            gr.Warning(error_msg)\n",
        "            traceback.print_exc()\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        # --- 3. Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞ£Ğ”Ğ˜Ğ ---\n",
        "        progress(0.5, desc=\"ğŸµ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾...\")\n",
        "        \n",
        "        # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        try:\n",
        "            final_wave, final_sample_rate, combined_spectrogram = infer_process(\n",
        "                ref_audio_proc,\n",
        "                processed_ref_text_final,\n",
        "                processed_gen_text,\n",
        "                model,\n",
        "                vocoder,\n",
        "                cross_fade_duration=cross_fade_duration,\n",
        "                nfe_step=nfe_step,\n",
        "                speed=speed,\n",
        "                sway_sampling_coef=sway_sampling_coef,\n",
        "                cfg_strength=cfg_strength,\n",
        "                show_info=gr.Info,\n",
        "                progress=progress,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾: {str(e)}\"\n",
        "            gr.Warning(error_msg)\n",
        "            traceback.print_exc()\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "        # --- 4. Ğ£Ğ”ĞĞ›Ğ•ĞĞ˜Ğ• Ğ¢Ğ˜Ğ¨Ğ˜ĞĞ« (ĞĞŸĞ¦Ğ˜ĞĞĞĞ›Ğ¬ĞĞ) ---\n",
        "        if remove_silence:\n",
        "            progress(0.7, desc=\"ğŸ”‡ Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñ‹...\")\n",
        "            \n",
        "            # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "            if stop_generation:\n",
        "                gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "                return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "            \n",
        "            try:\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".wav\", **tempfile_kwargs) as f:\n",
        "                    temp_path = f.name\n",
        "                    sf.write(temp_path, final_wave, final_sample_rate)\n",
        "                    remove_silence_for_generated_wav(temp_path)\n",
        "                    final_wave_tensor, _ = torchaudio.load(temp_path)\n",
        "                    final_wave = final_wave_tensor.squeeze().cpu().numpy()\n",
        "            except Exception as e:\n",
        "                print(\"âš ï¸ Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñ‹ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ:\", e)\n",
        "                # ĞĞµ Ğ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ, Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ñ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾\n",
        "\n",
        "        # --- 5. Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢ Ğ’ Ğ¤ĞĞ ĞœĞĞ¢ ---\n",
        "        progress(0.8, desc=\"ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°...\")\n",
        "        \n",
        "        # ğŸ”´ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ STOP_FLAG\n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "        # ğŸµ ĞŸĞĞ”Ğ“ĞĞ¢ĞĞ’ĞšĞ ĞĞ£Ğ”Ğ˜Ğ Ğ”Ğ›Ğ¯ Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢Ğ\n",
        "        safe_kwargs = {k: v for k, v in tempfile_kwargs.items() if k != 'delete'}\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(suffix=f\".{audio_format}\", delete=False, **safe_kwargs) as tmp:\n",
        "            temp_output_path = tmp.name\n",
        "\n",
        "        wave = final_wave\n",
        "        if wave.ndim == 1:\n",
        "            channels = 1\n",
        "        else:\n",
        "            channels = min(wave.shape[0], 2)\n",
        "            wave = wave[:channels].T\n",
        "\n",
        "        # ğŸ”§ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ĞĞ£Ğ”Ğ˜Ğ\n",
        "        if np.max(np.abs(wave)) == 0:\n",
        "            wave_int16 = np.zeros(wave.shape, dtype=np.int16)\n",
        "        else:\n",
        "            wave_int16 = np.int16(wave / np.max(np.abs(wave)) * 32767)\n",
        "\n",
        "        # ğŸ’¾ Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ• Ğ’ Ğ’Ğ«Ğ‘Ğ ĞĞĞĞĞœ Ğ¤ĞĞ ĞœĞĞ¢Ğ•\n",
        "        audio_segment = AudioSegment(\n",
        "            wave_int16.tobytes(),\n",
        "            frame_rate=final_sample_rate,\n",
        "            sample_width=2,\n",
        "            channels=channels\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            if audio_format == \"mp3\":\n",
        "                audio_segment.export(temp_output_path, format=\"mp3\", bitrate=bitrate)\n",
        "            elif audio_format == \"ogg\":\n",
        "                audio_segment.export(temp_output_path, format=\"ogg\", bitrate=bitrate)\n",
        "            elif audio_format == \"flac\":\n",
        "                audio_segment.export(temp_output_path, format=\"flac\")\n",
        "            else:\n",
        "                audio_segment.export(temp_output_path, format=\"wav\")\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ğ°ÑƒĞ´Ğ¸Ğ¾: {str(e)}\"\n",
        "            gr.Warning(error_msg)\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "        # ğŸ“ Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞĞ“Ğ Ğ¤ĞĞ™Ğ›Ğ\n",
        "        timestamp = int(time.time())\n",
        "        safe_text = f\"audio_{timestamp}\"\n",
        "        final_output_path = os.path.join(os.path.dirname(temp_output_path), f\"{safe_text}.{audio_format}\")\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(final_output_path):\n",
        "                os.remove(final_output_path)\n",
        "            os.rename(temp_output_path, final_output_path)\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°: {str(e)}\"\n",
        "            gr.Warning(error_msg)\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "        # --- 6. Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ• Ğ¡ĞŸĞ•ĞšĞ¢Ğ ĞĞ“Ğ ĞĞœĞœĞ« ---\n",
        "        progress(0.9, desc=\"ğŸ“Š Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹...\")\n",
        "        \n",
        "        spectrogram_path = None\n",
        "        try:\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".png\", **tempfile_kwargs) as tmp_spectrogram:\n",
        "                spectrogram_path = tmp_spectrogram.name\n",
        "                save_spectrogram(combined_spectrogram, spectrogram_path)\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ:\", e)\n",
        "            # ĞĞµ Ğ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ, Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ğ±ĞµĞ· ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹\n",
        "\n",
        "        progress(1.0, desc=\"âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!\")\n",
        "        \n",
        "        # ğŸ‰ Ğ’ĞĞ—Ğ’Ğ ĞĞ¢ Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞĞ“Ğ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ\n",
        "        return (\n",
        "            final_output_path,\n",
        "            spectrogram_path,\n",
        "            processed_ref_text_final,\n",
        "            processed_gen_text,\n",
        "            gr.update(value=current_seed),  # ğŸ”´ Ğ’ĞĞ—Ğ’Ğ ĞĞ©ĞĞ•Ğœ Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ™ Ğ¡Ğ˜Ğ”\n",
        "            current_model_status  # ğŸ”´ Ğ’ĞĞ—Ğ’Ğ ĞĞ©ĞĞ•Ğœ ĞĞšĞ¢Ğ£ĞĞ›Ğ¬ĞĞ«Ğ™ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ ĞœĞĞ”Ğ•Ğ›Ğ˜\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ĞĞµĞ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {str(e)}\"\n",
        "        print(f\"Unexpected error in synthesize: {traceback.format_exc()}\")\n",
        "        gr.Warning(error_msg)\n",
        "        return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "    finally:\n",
        "        # ğŸ§¹ ĞĞ§Ğ˜Ğ¡Ğ¢ĞšĞ ĞŸĞĞœĞ¯Ğ¢Ğ˜ (Ğ•Ğ¡Ğ›Ğ˜ ĞĞ• Ğ‘Ğ«Ğ›Ğ ĞĞ¡Ğ¢ĞĞĞĞ’ĞšĞ˜)\n",
        "        if not stop_generation:\n",
        "            try:\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "            except Exception as e:\n",
        "                print(\"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸:\", e)\n",
        "\n",
        "with gr.Blocks(title=\"ESpeech-TTS\", css=\"\"\"\n",
        "    .error-markdown {\n",
        "        color: red !important;\n",
        "        font-weight: bold;\n",
        "        text-align: center;\n",
        "        font-size: 18px !important;\n",
        "        margin: 10px 0;\n",
        "        animation: fadeIn 0.3s, fadeOut 0.3s 4.7s forwards;\n",
        "    }\n",
        "    .model-status {\n",
        "        padding: 10px;\n",
        "        border-radius: 5px;\n",
        "        margin: 10px 0;\n",
        "        text-align: center;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .model-loaded {\n",
        "        background: #d4edda;\n",
        "        color: #155724;\n",
        "        border: 1px solid #c3e6cb;\n",
        "    }\n",
        "    .model-error {\n",
        "        background: #f8d7da;\n",
        "        color: #721c24;\n",
        "        border: 1px solid #f5c6cb;\n",
        "    }\n",
        "    .model-loading {\n",
        "        background: #fff3cd;\n",
        "        color: #856404;\n",
        "        border: 1px solid #ffeaa7;\n",
        "    }\n",
        "    .loading-status {\n",
        "        padding: 10px;\n",
        "        margin: 10px 0;\n",
        "        border-radius: 5px;\n",
        "        text-align: center;\n",
        "    }\n",
        "    .local-model-input {\n",
        "        background: #f8f9fa;\n",
        "        padding: 15px;\n",
        "        border-radius: 8px;\n",
        "        border: 1px solid #dee2e6;\n",
        "        margin: 10px 0;\n",
        "    }\n",
        "    @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }\n",
        "    @keyframes fadeOut { from { opacity: 1; } to { opacity: 0; } }\n",
        "    \"\"\") as app:\n",
        "    gr.Markdown(\"# ESpeech-TTS\")\n",
        "    gr.Markdown(\"ğŸ’¡ **Ğ¡Ğ¾Ğ²ĞµÑ‚:** Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ» '+' Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, 'Ğ¿Ñ€Ğ¸Ğ²+ĞµÑ‚')\")\n",
        "    gr.Markdown(\"ğŸ² **Ğ¡Ğ¾Ğ²ĞµÑ‚:** Seed Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµÑ‚ Ğ·Ğ° Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. Ğ’Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ğ¾Ğ´Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ´Ğ»Ñ ÑĞµĞ±Ñ ÑƒĞ´Ğ°Ñ‡Ğ½Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ»Ğ¸ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ€Ğ°Ğ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ seed\")\n",
        "    gr.Markdown(\"ğŸš€ **CUDA Required:** This application requires GPU with CUDA support\")\n",
        "\n",
        "    # ğŸ”´ ĞĞĞ’Ğ«Ğ™ Ğ‘Ğ›ĞĞš: Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    with gr.Accordion(\"ğŸ”§ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\", open=False):\n",
        "        with gr.Row():\n",
        "            local_model_path = gr.Textbox(\n",
        "                label=\"ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\",\n",
        "                placeholder=\"hf://SWivid/F5-TTS/F5TTS_v1_Base/model_1250000.safetensors Ğ¸Ğ»Ğ¸ /path/to/model.safetensors\",\n",
        "                scale=3\n",
        "            )\n",
        "            local_vocab_path = gr.Textbox(\n",
        "                label=\"ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\", \n",
        "                placeholder=\"hf://SWivid/F5-TTS/F5TTS_v1_Base/vocab.txt Ğ¸Ğ»Ğ¸ /path/to/vocab.txt\",\n",
        "                scale=3\n",
        "            )\n",
        "            local_model_name = gr.Textbox(\n",
        "                label=\"Ğ˜Ğ¼Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\",\n",
        "                placeholder=\"My Local Model\",\n",
        "                scale=2\n",
        "            )\n",
        "        with gr.Row():\n",
        "            add_local_model_btn = gr.Button(\"â• Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\", variant=\"secondary\")\n",
        "            local_model_status = gr.HTML(visible=False)\n",
        "\n",
        "    # --- ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞ«Ğ™ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ ĞœĞĞ”Ğ•Ğ›Ğ˜ ---\n",
        "    initial_model = \"ESpeech-TTS-1_SFT-95K\"\n",
        "    initial_status = update_model_loading_status(initial_model)\n",
        "\n",
        "    model_status = gr.HTML(\n",
        "        value=initial_status[\"value\"],\n",
        "        visible=initial_status[\"visible\"]\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            # --- Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ---\n",
        "            model_choice = gr.Dropdown(\n",
        "                choices=list(MODELS_CONFIG.keys()),\n",
        "                value=initial_model,\n",
        "                label=\"Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\",\n",
        "                info=\"ğŸŒ HuggingFace Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ»Ğ¸ ğŸ”§ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\"\n",
        "            )\n",
        "            \n",
        "            # --- ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ ĞšĞĞĞŸĞšĞ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ˜ ĞœĞĞ”Ğ•Ğ›Ğ˜ ---\n",
        "            load_model_btn = gr.Button(\"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\", variant=\"secondary\")\n",
        "            \n",
        "        with gr.Column():\n",
        "            ref_audio_input = gr.Audio(label=\"Reference Audio\", type=\"filepath\")\n",
        "            ref_text_input = gr.Textbox(\n",
        "                label=\"Reference Text\",\n",
        "                lines=2,\n",
        "                placeholder=\"Text corresponding to reference audio\"\n",
        "            )\n",
        "            # ĞĞ¾Ğ²Ğ¾Ğµ: Ñ‚ĞµĞºÑÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸\n",
        "            ref_audio_warning = gr.Markdown(\"\", visible=False, elem_classes=\"error-markdown\")\n",
        "        with gr.Column():\n",
        "            gen_text_input = gr.Textbox(\n",
        "                label=\"Text to Generate\",\n",
        "                lines=5,\n",
        "                max_lines=20,\n",
        "                placeholder=\"Enter text to synthesize...\"\n",
        "            )\n",
        "\n",
        "    # --- ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞ«Ğ• ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜ĞšĞ˜ Ğ”Ğ›Ğ¯ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ˜ ĞœĞĞ”Ğ•Ğ›Ğ˜ ---\n",
        "    def on_model_select(model_name):\n",
        "        \"\"\"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² dropdown\"\"\"\n",
        "        if model_name:\n",
        "            return update_model_loading_status(model_name)\n",
        "        return gr.update(value=\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°</div>\", visible=True)\n",
        "\n",
        "    # ğŸ”´ ĞĞĞ’Ğ«Ğ™ ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜Ğš: Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "    add_local_model_btn.click(\n",
        "        fn=add_local_model,\n",
        "        inputs=[local_model_path, local_vocab_path, local_model_name],\n",
        "        outputs=[model_choice, local_model_status]\n",
        "    )\n",
        "\n",
        "    # ĞĞ²Ñ‚Ğ¾Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğµ - Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡\n",
        "    model_choice.change(\n",
        "        fn=on_model_select,\n",
        "        inputs=model_choice,\n",
        "        outputs=model_status\n",
        "    )\n",
        "\n",
        "    # ĞšĞ½Ğ¾Ğ¿ĞºĞ° Ğ¿Ñ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸\n",
        "    load_model_btn.click(\n",
        "        fn=load_model_with_status,\n",
        "        inputs=[model_choice],\n",
        "        outputs=model_status\n",
        "    )\n",
        "\n",
        "    # --- ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ âœ…---\n",
        "    ref_audio_input.change(\n",
        "        fn=validate_and_transcribe_audio,\n",
        "        inputs=ref_audio_input,\n",
        "        outputs=[ref_audio_input, ref_text_input, ref_audio_warning]\n",
        "    )\n",
        "\n",
        "    process_text_btn = gr.Button(\"âœï¸ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°\", variant=\"secondary\")\n",
        "\n",
        "    with gr.Accordion(\"Advanced Settings\", open=False):\n",
        "        with gr.Row():\n",
        "            # ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ seed\n",
        "            seed_input = gr.Number(label=\"Seed (random)\", value=get_current_seed_display(), precision=0)\n",
        "            remember_seed_checkbox = gr.Checkbox(label=\"ğŸ’¾ Ğ—Ğ°Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ¾Ñ‚ seed\", value=False)\n",
        "            remove_silence = gr.Checkbox(label=\"Remove Silences\", value=False)\n",
        "        with gr.Row():\n",
        "            speed_slider = gr.Slider(label=\"Speed\", minimum=0.3, maximum=2.0, value=1.0, step=0.1)\n",
        "            nfe_slider = gr.Slider(label=\"NFE Steps\", minimum=4, maximum=64, value=48, step=2)\n",
        "        with gr.Row():\n",
        "            cross_fade_slider = gr.Slider(label=\"Cross-Fade Duration (s)\", minimum=0.0, maximum=1.0, value=0.15, step=0.01)\n",
        "            sway_sampling_slider = gr.Slider(label=\"Sway Sampling Coef\", minimum=-1, maximum=1, value=-1, step=0.1)\n",
        "        with gr.Row():\n",
        "            cfg_strength_slider = gr.Slider(label=\"CFG Strength\", minimum=0.5, maximum=5.0, value=2.0, step=0.1)\n",
        "        with gr.Row():\n",
        "            audio_format = gr.Radio([\"wav\", \"mp3\", \"ogg\", \"flac\"], label=\"Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚\", value=\"wav\")\n",
        "            bitrate = gr.Radio([\"128k\", \"192k\", \"320k\"], label=\"Ğ‘Ğ¸Ñ‚Ñ€ĞµĞ¹Ñ‚ (mp3/ogg)\", value=\"192k\", visible=lambda fmt: fmt in [\"mp3\", \"ogg\"])\n",
        "\n",
        "    # --- ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° ---\n",
        "    def update_bitrate_visibility(audio_format):\n",
        "        return gr.update(visible=audio_format in [\"mp3\", \"ogg\"])\n",
        "\n",
        "    audio_format.change(\n",
        "        update_bitrate_visibility,\n",
        "        inputs=audio_format,\n",
        "        outputs=bitrate\n",
        "    )\n",
        "\n",
        "    # --- ğŸ”´ Ğ”ĞĞ‘ĞĞ’Ğ›Ğ•ĞĞ: ĞšĞ½Ğ¾Ğ¿ĞºĞ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ ---\n",
        "    with gr.Row():\n",
        "        generate_btn = gr.Button(\"ğŸ¤ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
        "        stop_btn = gr.Button(\"ğŸ›‘ Stop Generation\", variant=\"stop\", size=\"lg\")\n",
        "\n",
        "    with gr.Row():\n",
        "        audio_output = gr.Audio(label=\"ğŸ§ ĞÑƒĞ´Ğ¸Ğ¾\", type=\"filepath\")\n",
        "        spectrogram_output = gr.Image(label=\"Spectrogram\", type=\"filepath\")\n",
        "\n",
        "    process_text_btn.click(\n",
        "        process_texts_only,\n",
        "        inputs=[ref_text_input, gen_text_input],\n",
        "        outputs=[ref_text_input, gen_text_input]\n",
        "    )\n",
        "\n",
        "    # --- ğŸ”´ Ğ”ĞĞ‘ĞĞ’Ğ›Ğ•ĞĞ: ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ ---\n",
        "    stop_btn.click(\n",
        "        fn=stop_generation_process,\n",
        "        outputs=None,\n",
        "        queue=False\n",
        "    )\n",
        "\n",
        "    # ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞ«Ğ™ Ğ’Ğ«Ğ—ĞĞ’ Ğ¡Ğ˜ĞĞ¢Ğ•Ğ—Ğ Ğ¡ ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ•Ğœ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡Ğ\n",
        "    generate_btn.click(\n",
        "        synthesize,\n",
        "        inputs=[\n",
        "            ref_audio_input,\n",
        "            ref_text_input,\n",
        "            gen_text_input,\n",
        "            remove_silence,\n",
        "            seed_input,\n",
        "            remember_seed_checkbox,\n",
        "            model_choice,\n",
        "            cross_fade_slider,\n",
        "            nfe_slider,\n",
        "            speed_slider,\n",
        "            sway_sampling_slider,\n",
        "            cfg_strength_slider,\n",
        "            audio_format,\n",
        "            bitrate,\n",
        "        ],\n",
        "        outputs=[\n",
        "            audio_output, \n",
        "            spectrogram_output, \n",
        "            ref_text_input, \n",
        "            gen_text_input, \n",
        "            seed_input,\n",
        "            model_status  # ğŸ”´ Ğ”ĞĞ‘ĞĞ’Ğ›Ğ¯Ğ•Ğœ ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡Ğ ĞœĞĞ”Ğ•Ğ›Ğ˜\n",
        "        ]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
