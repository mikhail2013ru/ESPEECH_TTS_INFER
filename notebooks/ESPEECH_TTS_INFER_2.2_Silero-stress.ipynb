{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F6YzVP_1AlhR",
        "outputId": "50a3b64e-634e-477f-b669-c7a6454cbfb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting f5-tts\n",
            "  Downloading f5_tts-1.1.7-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Collecting ruaccent\n",
            "  Downloading ruaccent-1.5.8.3-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
            "Requirement already satisfied: accelerate>=0.33.0 in /usr/local/lib/python3.12/dist-packages (from f5-tts) (1.10.0)\n",
            "Collecting bitsandbytes>0.37.0 (from f5-tts)\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Collecting cached_path (from f5-tts)\n",
            "  Downloading cached_path-1.7.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from f5-tts) (8.2.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from f5-tts) (4.0.0)\n",
            "Collecting ema_pytorch>=0.5.2 (from f5-tts)\n",
            "  Downloading ema_pytorch-0.7.7-py3-none-any.whl.metadata (689 bytes)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.35.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting hydra-core>=1.3.0 (from f5-tts)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.42.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from f5-tts) (3.10.0)\n",
            "Collecting numpy<=1.26.4 (from f5-tts)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<=2.10.6 (from f5-tts)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.25.1)\n",
            "Collecting pypinyin (from f5-tts)\n",
            "  Downloading pypinyin-0.55.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.6.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.13.1)\n",
            "Collecting tomli (from f5-tts)\n",
            "  Downloading tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchdiffeq (from f5-tts)\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from f5-tts) (4.67.1)\n",
            "Collecting transformers_stream_generator (from f5-tts)\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode (from f5-tts)\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting vocos (from f5-tts)\n",
            "  Downloading vocos-0.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from f5-tts) (0.21.1)\n",
            "Collecting x_transformers>=1.31.14 (from f5-tts)\n",
            "  Downloading x_transformers-2.7.2-py3-none-any.whl.metadata (90 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Collecting gradio-client==1.10.4 (from gradio)\n",
            "  Downloading gradio_client-1.10.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.10.4->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.10.4->gradio) (15.0.1)\n",
            "Collecting onnxruntime (from ruaccent)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from ruaccent) (0.2.1)\n",
            "Collecting python-crfsuite (from ruaccent)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting razdel (from ruaccent)\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.33.0->f5-tts) (5.9.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.0->f5-tts) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.0->f5-tts) (4.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.10.6->f5-tts) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->f5-tts)\n",
            "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from x_transformers>=1.31.14->f5-tts) (0.8.1)\n",
            "Collecting einx>=0.3.0 (from x_transformers>=1.31.14->f5-tts)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting loguru (from x_transformers>=1.31.14->f5-tts)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting boto3<2.0,>=1.0 (from cached_path->f5-tts)\n",
            "  Downloading boto3-1.40.17-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from cached_path->f5-tts) (2.19.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->f5-tts) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->f5-tts) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->f5-tts) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->f5-tts) (0.70.16)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->f5-tts) (1.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->f5-tts) (1.17.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->f5-tts) (3.2.3)\n",
            "Collecting coloredlogs (from onnxruntime->ruaccent)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime->ruaccent) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime->ruaccent) (5.29.5)\n",
            "Collecting encodec==0.1.1 (from vocos->f5-tts)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->f5-tts) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->f5-tts) (4.3.8)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->f5-tts) (2.35.0)\n",
            "Collecting botocore<1.41.0,>=1.40.17 (from boto3<2.0,>=1.0->cached_path->f5-tts)\n",
            "  Downloading botocore-1.40.17-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.0->cached_path->f5-tts)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3<2.0,>=1.0->cached_path->f5-tts)\n",
            "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->f5-tts) (2.22)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx>=0.3.0->x_transformers>=1.31.14->f5-tts) (2.4.6)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->f5-tts) (4.0.12)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (1.7.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->f5-tts) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->f5-tts) (3.6.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->ruaccent)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->f5-tts) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->f5-tts) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (4.9.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->f5-tts) (0.6.1)\n",
            "Downloading f5_tts-1.1.7-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.35.0-py3-none-any.whl (54.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.4-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruaccent-1.5.8.3-py2.py3-none-any.whl (22 kB)\n",
            "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ema_pytorch-0.7.7-py3-none-any.whl (9.8 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading x_transformers-2.7.2-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cached_path-1.7.3-py3-none-any.whl (36 kB)\n",
            "Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin-0.55.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Downloading tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vocos-0.1.0-py3-none-any.whl (24 kB)\n",
            "Downloading boto3-1.40.17-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.17-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers_stream_generator, encodec\n",
            "  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12426 sha256=333a252b5e108a2539bc509609afcfb5b28fc7406f8f79eb495f0d0172626bc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/58/d2/014cb67c3cc6def738c1b1635dbf4e3dab6fb63aba7070dce0\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=034091451cb5c73fb9a0d09bcc151bffeb20f0b03a588a4968af8cf63620d156\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/eb/9f/e13610cc46ab39d3199fbabebd1c3e142d44b679526e0f228a\n",
            "Successfully built transformers_stream_generator encodec\n",
            "Installing collected packages: razdel, unidecode, tomli, python-crfsuite, pypinyin, pydantic-core, numpy, loguru, jmespath, humanfriendly, pydantic, hydra-core, einx, coloredlogs, botocore, s3transfer, onnxruntime, gradio-client, x_transformers, torchdiffeq, gradio, ema_pytorch, boto3, bitsandbytes, transformers_stream_generator, ruaccent, encodec, vocos, cached_path, f5-tts\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.11.1\n",
            "    Uninstalling gradio_client-1.11.1:\n",
            "      Successfully uninstalled gradio_client-1.11.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.42.0\n",
            "    Uninstalling gradio-5.42.0:\n",
            "      Successfully uninstalled gradio-5.42.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "mcp 1.13.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.10.6 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.47.0 boto3-1.40.17 botocore-1.40.17 cached_path-1.7.3 coloredlogs-15.0.1 einx-0.3.0 ema_pytorch-0.7.7 encodec-0.1.1 f5-tts-1.1.7 gradio-5.35.0 gradio-client-1.10.4 humanfriendly-10.0 hydra-core-1.3.2 jmespath-1.0.1 loguru-0.7.3 numpy-1.26.4 onnxruntime-1.22.1 pydantic-2.10.6 pydantic-core-2.27.2 pypinyin-0.55.0 python-crfsuite-0.9.11 razdel-0.5.0 ruaccent-1.5.8.3 s3transfer-0.13.1 tomli-2.2.1 torchdiffeq-0.2.5 transformers_stream_generator-0.0.5 unidecode-1.4.0 vocos-0.1.0 x_transformers-2.7.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "380b02460b5e481784b8f0097d255744",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -q gradio runorm transformers torch torchaudio\n",
        "!pip install -q huggingface_hub soundfile pydub silero-stress\n",
        "!pip install -q git+https://github.com/mikhail2013ru/F5-TTS-RUS.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXMWDSiTA_Gf"
      },
      "outputs": [],
      "source": [
        "# ĞĞĞ–ĞĞ¢Ğ¬ RESTART SESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i90o6-p9AvOA",
        "outputId": "f9458d9f-4cad-4393-b9f2-b4b4f08af84d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking CUDA availability...\n",
            "CUDA is available. Using device: Tesla T4\n",
            "Preloading model...\n",
            "CUDA is available. Using device: Tesla T4\n",
            "Trying to download model file 'espeech_tts_rlv2.pt' and 'vocab.txt' from hub 'ESpeech/ESpeech-TTS-1_RL-V2'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded model to /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/espeech_tts_rlv2.pt\n",
            "Downloaded vocab to /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/vocab.txt\n",
            "Loading model from: /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/espeech_tts_rlv2.pt\n",
            "\n",
            "vocab :  /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/vocab.txt\n",
            "token :  custom\n",
            "model :  /root/.cache/huggingface/hub/models--ESpeech--ESpeech-TTS-1_RL-V2/snapshots/f582b6e5897fe8a5835059405a8439d13bdf7684/espeech_tts_rlv2.pt \n",
            "\n",
            "Model loaded and moved to CUDA: cuda\n",
            "Model preloaded.\n",
            "Loading RUAccent...\n",
            "RUAccent loaded.\n",
            "Preloading vocoder...\n",
            "CUDA is available. Using device: Tesla T4\n",
            "Loading vocoder...\n",
            "Download Vocos from huggingface charactr/vocos-mel-24khz\n",
            "Vocoder loaded and moved to CUDA: cuda\n",
            "Vocoder preloaded.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://29f0abcf0bb8391bb1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://29f0abcf0bb8391bb1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import gc\n",
        "import tempfile\n",
        "import traceback\n",
        "import json\n",
        "import threading\n",
        "import numpy as np\n",
        "import math\n",
        "from pydub import AudioSegment\n",
        "from pydub.effects import normalize\n",
        "from pathlib import Path\n",
        "\n",
        "import gradio as gr\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from huggingface_hub import login, hf_hub_download, snapshot_download\n",
        "\n",
        "# ================ Ğ£Ğ›Ğ£Ğ§Ğ¨Ğ•ĞĞĞĞ¯ ĞĞ’Ğ¢ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ HUGGINGFACE ================\n",
        "def setup_huggingface_auth():\n",
        "    \"\"\"ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ HuggingFace Ğ´Ğ»Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¼ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸ÑĞ¼\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ” ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ ĞĞ’Ğ¢ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ˜ HUGGINGFACE\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    hf_token = None\n",
        "    token_source = \"ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½\"\n",
        "    \n",
        "    if os.environ.get(\"HF_TOKEN\"):\n",
        "        hf_token = os.environ[\"HF_TOKEN\"]\n",
        "        token_source = \"Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ HF_TOKEN\"\n",
        "    elif os.path.exists(\"/root/.cache/huggingface/token\"):\n",
        "        try:\n",
        "            with open(\"/root/.cache/huggingface/token\", \"r\") as f:\n",
        "                hf_token = f.read().strip()\n",
        "            if hf_token:\n",
        "                token_source = \"Ñ„Ğ°Ğ¹Ğ» /root/.cache/huggingface/token\"\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ° Ñ‚Ğ¾ĞºĞµĞ½Ğ°: {e}\")\n",
        "    else:\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            hf_token = userdata.get('HF_TOKEN')\n",
        "            if hf_token:\n",
        "                token_source = \"ÑĞµĞºÑ€ĞµÑ‚Ñ‹ Colab\"\n",
        "        except ImportError:\n",
        "            print(\"âš ï¸ ĞĞµ Ğ² Colab Ğ¸Ğ»Ğ¸ google.colab Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ° Ğ¸Ğ· Colab: {e}\")\n",
        "    \n",
        "    if not hf_token:\n",
        "        hf_cache_token = os.path.expanduser(\"~/.cache/huggingface/token\")\n",
        "        if os.path.exists(hf_cache_token):\n",
        "            try:\n",
        "                with open(hf_cache_token, \"r\") as f:\n",
        "                    hf_token = f.read().strip()\n",
        "                if hf_token:\n",
        "                    token_source = f\"Ñ„Ğ°Ğ¹Ğ» {hf_cache_token}\"\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    if hf_token:\n",
        "        try:\n",
        "            print(f\"âœ… Ğ¢Ğ¾ĞºĞµĞ½ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² {token_source}\")\n",
        "            \n",
        "            if not hf_token.startswith(\"hf_\"):\n",
        "                print(f\"âš ï¸ ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ: Ğ¢Ğ¾ĞºĞµĞ½ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ĞµĞ²ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°. Ğ”Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ‚ÑŒÑÑ Ñ 'hf_'\")\n",
        "            \n",
        "            login(token=hf_token)\n",
        "            os.environ[\"HF_TOKEN\"] = hf_token\n",
        "            \n",
        "            try:\n",
        "                os.makedirs(\"/root/.cache/huggingface\", exist_ok=True)\n",
        "                with open(\"/root/.cache/huggingface/token\", \"w\") as f:\n",
        "                    f.write(hf_token)\n",
        "                print(\"âœ… Ğ¢Ğ¾ĞºĞµĞ½ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ²\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½ Ğ² Ñ„Ğ°Ğ¹Ğ»: {e}\")\n",
        "            \n",
        "            print(\"âœ… ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ HuggingFace ÑƒÑĞ¿ĞµÑˆĞ½Ğ°!\")\n",
        "            return hf_token\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {error_msg}\")\n",
        "            \n",
        "            if \"401\" in error_msg:\n",
        "                print(\"âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½Ğ°.\")\n",
        "            elif \"400\" in error_msg:\n",
        "                print(\"âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ°. Ğ¢Ğ¾ĞºĞµĞ½ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ‚ÑŒÑÑ Ñ 'hf_'.\")\n",
        "            elif \"connection\" in error_msg.lower():\n",
        "                print(\"âŒ ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğº Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ñƒ. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ.\")\n",
        "            \n",
        "            return None\n",
        "    else:\n",
        "        print(\"â„¹ï¸  Ğ¢Ğ¾ĞºĞµĞ½ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ğ±ĞµĞ· Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.\")\n",
        "        print(\"   Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹.\")\n",
        "        \n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(\"ğŸ“‹ ĞšĞ°Ğº Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½:\")\n",
        "        print(\"1. ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½ Ğ½Ğ° https://huggingface.co/settings/tokens\")\n",
        "        print(\"2. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ğ¸Ğ· ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ²:\")\n",
        "        print(\"   â€¢ Ğ’ Colab: Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ² ÑĞµĞºÑ€ĞµÑ‚Ñ‹ Ñ ĞºĞ»ÑÑ‡Ğ¾Ğ¼ 'HF_TOKEN'\")\n",
        "        print(\"   â€¢ Ğ’ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ: export HF_TOKEN='Ğ²Ğ°Ñˆ_Ñ‚Ğ¾ĞºĞµĞ½'\")\n",
        "        print(\"   â€¢ Ğ’ Ñ„Ğ°Ğ¹Ğ»: echo 'Ğ²Ğ°Ñˆ_Ñ‚Ğ¾ĞºĞµĞ½' > /root/.cache/huggingface/token\")\n",
        "        print(\"-\"*60)\n",
        "        \n",
        "        return None\n",
        "\n",
        "# Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸš€ Ğ—ĞĞŸĞ£Ğ¡Ğš ESpeech-TTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "HF_TOKEN = setup_huggingface_auth()\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ================ Ğ“Ğ›ĞĞ‘ĞĞ›Ğ¬ĞĞ«Ğ• Ğ¤Ğ›ĞĞ“Ğ˜ Ğ”Ğ›Ğ¯ Ğ£ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ¯ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ•Ğ™ ================\n",
        "stop_generation = False\n",
        "generation_thread = None\n",
        "generation_event = threading.Event()\n",
        "stop_requested = False\n",
        "\n",
        "from silero_stress import load_accentor\n",
        "from runorm import RUNorm\n",
        "from f5_tts.infer.utils_infer import (\n",
        "    infer_process,\n",
        "    load_model,\n",
        "    load_vocoder,\n",
        "    preprocess_ref_audio_text,\n",
        "    remove_silence_for_generated_wav,\n",
        "    save_spectrogram,\n",
        "    tempfile_kwargs,\n",
        ")\n",
        "from f5_tts.model import DiT\n",
        "\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    \"ESpeech-TTS-1_SFT-95K\": {\n",
        "        \"repo\": \"ESpeech/ESpeech-TTS-1_SFT-95K\",\n",
        "        \"model_file\": \"espeech_tts_95k.pt\",\n",
        "        \"vocab_file\": \"vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"ESpeech-TTS-1_RL-V1\": {\n",
        "        \"repo\": \"ESpeech/ESpeech-TTS-1_RL-V1\",\n",
        "        \"model_file\": \"espeech_tts_rlv1.pt\",\n",
        "        \"vocab_file\": \"vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"ESpeech-TTS-1_RL-V2\": {\n",
        "        \"repo\": \"ESpeech/ESpeech-TTS-1_RL-V2\",\n",
        "        \"model_file\": \"espeech_tts_rlv2.pt\",\n",
        "        \"vocab_file\": \"vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"F5TTS_v1_Base_v2_Misha24-10\": {\n",
        "        \"repo\": \"Misha24-10/F5-TTS_RUSSIAN\",\n",
        "        \"model_file\": \"F5TTS_v1_Base_v2/model_last_inference.safetensors\",\n",
        "        \"vocab_file\": \"F5TTS_v1_Base/vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"F5TTS_v1_Base_v4_winter\": {\n",
        "        \"repo\": \"Misha24-10/F5-TTS_RUSSIAN\",\n",
        "        \"model_file\": \"F5TTS_v1_Base_v4_winter/model_212000.safetensors\",\n",
        "        \"vocab_file\": \"F5TTS_v1_Base/vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "    \"F5TTS_v1_Base_1.25M_SWivid\": {\n",
        "        \"repo\": \"SWivid/F5-TTS\",\n",
        "        \"model_file\": \"F5TTS_v1_Base/model_1250000.safetensors\",\n",
        "        \"vocab_file\": \"F5TTS_v1_Base/vocab.txt\",\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    },\n",
        "}\n",
        "\n",
        "# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "loaded_models = {}\n",
        "loaded_vocoder = None\n",
        "current_model_name = None\n",
        "remember_seed = False\n",
        "last_seed = -1\n",
        "\n",
        "# Ğ”Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹\n",
        "normalized_audio_cache = {}\n",
        "\n",
        "# Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "LOCAL_MODELS_FILE = \"local_models.json\"\n",
        "local_models_config = {}\n",
        "\n",
        "def load_local_models():\n",
        "    \"\"\"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°\"\"\"\n",
        "    global local_models_config\n",
        "    try:\n",
        "        if os.path.exists(LOCAL_MODELS_FILE):\n",
        "            with open(LOCAL_MODELS_FILE, 'r', encoding='utf-8') as f:\n",
        "                local_models_config = json.load(f)\n",
        "            print(f\"âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(local_models_config)} Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\")\n",
        "        else:\n",
        "            local_models_config = {}\n",
        "            print(\"âœ… Ğ¤Ğ°Ğ¹Ğ» Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½, ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: {e}\")\n",
        "        local_models_config = {}\n",
        "\n",
        "def save_local_models():\n",
        "    \"\"\"Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ñ„Ğ°Ğ¹Ğ»\"\"\"\n",
        "    try:\n",
        "        with open(LOCAL_MODELS_FILE, 'w', encoding='utf-8') as f:\n",
        "            json.dump(local_models_config, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"âœ… Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ {len(local_models_config)} Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: {e}\")\n",
        "\n",
        "load_local_models()\n",
        "\n",
        "def get_all_models_config():\n",
        "    \"\"\"ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\"\"\"\n",
        "    return {**MODELS_CONFIG, **local_models_config}\n",
        "\n",
        "def clear_loaded_models():\n",
        "    \"\"\"ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ· Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸\"\"\"\n",
        "    global loaded_models, loaded_vocoder, current_model_name, normalized_audio_cache\n",
        "    \n",
        "    removed_local_models = list(local_models_config.keys())\n",
        "    \n",
        "    loaded_models.clear()\n",
        "    loaded_vocoder = None\n",
        "    current_model_name = None\n",
        "    normalized_audio_cache.clear()\n",
        "    \n",
        "    local_models_config.clear()\n",
        "    save_local_models()\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    updated_models_config = get_all_models_config()\n",
        "    new_model = list(updated_models_config.keys())[0] if updated_models_config else None\n",
        "    \n",
        "    removed_count = len(removed_local_models)\n",
        "    status_message = f\"âœ… Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¾ {removed_count} Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ Ğ¸Ğ· Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸\"\n",
        "    \n",
        "    print(status_message)\n",
        "    \n",
        "    return (\n",
        "        gr.update(value=f\"<div class='model-status model-loaded'>{status_message}</div>\", visible=True),\n",
        "        gr.update(value=\"\"),\n",
        "        gr.update(value=\"\"),\n",
        "        gr.update(value=\"\"),\n",
        "        gr.update(choices=list(updated_models_config.keys()), value=new_model)\n",
        "    )\n",
        "\n",
        "def remove_local_model(model_name):\n",
        "    \"\"\"Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ· ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸\"\"\"\n",
        "    global local_models_config\n",
        "    \n",
        "    if model_name in local_models_config:\n",
        "        del local_models_config[model_name]\n",
        "        save_local_models()\n",
        "        \n",
        "        updated_models_config = get_all_models_config()\n",
        "        new_model = list(updated_models_config.keys())[0] if updated_models_config else None\n",
        "        \n",
        "        return (\n",
        "            gr.update(choices=list(updated_models_config.keys()), value=new_model),\n",
        "            gr.update(value=f\"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ '{model_name}' ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ°\", visible=True)\n",
        "        )\n",
        "    else:\n",
        "        return gr.update(), gr.update(value=f\"âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ '{model_name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°\", visible=True)\n",
        "\n",
        "def check_cuda_availability():\n",
        "    \"\"\"Check if CUDA is available and raise error if not\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA is not available! This application requires GPU with CUDA support.\")\n",
        "    print(f\"CUDA is available. Using device: {torch.cuda.get_device_name()}\")\n",
        "\n",
        "def parse_hf_path(hf_path):\n",
        "    \"\"\"ĞŸĞ°Ñ€ÑĞ¸Ñ‚ HF Ğ¿ÑƒÑ‚ÑŒ Ğ² repo_id Ğ¸ filename\"\"\"\n",
        "    if hf_path.startswith('hf://'):\n",
        "        path_parts = hf_path.replace('hf://', '').split('/')\n",
        "        if len(path_parts) >= 2:\n",
        "            repo_id = '/'.join(path_parts[:2])\n",
        "            filename = '/'.join(path_parts[2:])\n",
        "            return repo_id, filename\n",
        "    return None, None\n",
        "\n",
        "def add_local_model(model_path, vocab_path, model_name):\n",
        "    \"\"\"Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ\"\"\"\n",
        "    global local_models_config, MODELS_CONFIG\n",
        "    \n",
        "    if not model_path or not vocab_path or not model_name:\n",
        "        return gr.update(), gr.update(value=\"âŒ Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ²ÑĞµ Ğ¿Ğ¾Ğ»Ñ\", visible=True)\n",
        "    \n",
        "    def validate_hf_path(file_path, file_type):\n",
        "        if file_path.startswith('hf://'):\n",
        "            repo_id, filename = parse_hf_path(file_path)\n",
        "            if not repo_id or not filename:\n",
        "                return False, f\"âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ HF Ğ¿ÑƒÑ‚Ğ¸ Ğ´Ğ»Ñ {file_type}\"\n",
        "            \n",
        "            if '/' not in repo_id or len(repo_id.split('/')) != 2:\n",
        "                return False, f\"âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ repo_id: {repo_id}\"\n",
        "                \n",
        "            return True, None\n",
        "        else:\n",
        "            if os.path.exists(file_path):\n",
        "                return True, None\n",
        "            else:\n",
        "                return False, f\"âŒ Ğ¤Ğ°Ğ¹Ğ» {file_type} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {file_path}\"\n",
        "    \n",
        "    is_model_valid, model_error = validate_hf_path(model_path, \"Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\")\n",
        "    if not is_model_valid:\n",
        "        return gr.update(), gr.update(value=model_error, visible=True)\n",
        "    \n",
        "    is_vocab_valid, vocab_error = validate_hf_path(vocab_path, \"ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\")\n",
        "    if not is_vocab_valid:\n",
        "        return gr.update(), gr.update(value=vocab_error, visible=True)\n",
        "    \n",
        "    local_models_config[model_name] = {\n",
        "        \"repo\": \"local\",\n",
        "        \"model_file\": model_path,\n",
        "        \"vocab_file\": vocab_path,\n",
        "        \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    }\n",
        "\n",
        "    save_local_models()\n",
        "    \n",
        "    updated_models_config = {**MODELS_CONFIG, **local_models_config}\n",
        "    \n",
        "    return gr.update(\n",
        "        choices=list(updated_models_config.keys()),\n",
        "        value=model_name\n",
        "    ), gr.update(value=f\"âœ… Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ '{model_name}' Ğ´Ğ¾Ğ±Ğ°Ğ²ĞµĞ½Ğ°\", visible=True)\n",
        "\n",
        "def check_token_validity(token):\n",
        "    \"\"\"ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½Ğ°\"\"\"\n",
        "    if not token:\n",
        "        return False, \"Ğ¢Ğ¾ĞºĞµĞ½ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹\"\n",
        "    \n",
        "    if not token.startswith(\"hf_\"):\n",
        "        return False, \"Ğ¢Ğ¾ĞºĞµĞ½ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ‚ÑŒÑÑ Ñ 'hf_'\"\n",
        "    \n",
        "    if len(token) < 20:\n",
        "        return False, \"Ğ¢Ğ¾ĞºĞµĞ½ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹\"\n",
        "    \n",
        "    return True, \"Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¹\"\n",
        "\n",
        "def update_hf_token(new_token):\n",
        "    \"\"\"ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ° HuggingFace\"\"\"\n",
        "    global HF_TOKEN\n",
        "    \n",
        "    if not new_token:\n",
        "        return gr.update(value=\"âŒ Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½\", visible=True)\n",
        "    \n",
        "    is_valid, validation_msg = check_token_validity(new_token)\n",
        "    if not is_valid:\n",
        "        return gr.update(value=f\"âŒ {validation_msg}\", visible=True)\n",
        "    \n",
        "    try:\n",
        "        print(f\"ğŸ”„ ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ¼...\")\n",
        "        \n",
        "        login(token=new_token)\n",
        "        HF_TOKEN = new_token\n",
        "        \n",
        "        try:\n",
        "            os.makedirs(\"/root/.cache/huggingface\", exist_ok=True)\n",
        "            with open(\"/root/.cache/huggingface/token\", \"w\") as f:\n",
        "                f.write(new_token)\n",
        "            print(f\"âœ… Ğ¢Ğ¾ĞºĞµĞ½ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ Ğ² Ñ„Ğ°Ğ¹Ğ»\")\n",
        "        except Exception as file_error:\n",
        "            print(f\"âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½ Ğ² Ñ„Ğ°Ğ¹Ğ»: {file_error}\")\n",
        "        \n",
        "        os.environ[\"HF_TOKEN\"] = new_token\n",
        "        \n",
        "        print(f\"âœ… Ğ¢Ğ¾ĞºĞµĞ½ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½\")\n",
        "        return gr.update(value=\"âœ… Ğ¢Ğ¾ĞºĞµĞ½ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½!\", visible=True)\n",
        "    \n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ°: {error_msg}\")\n",
        "        \n",
        "        if \"401\" in error_msg:\n",
        "            detailed_msg = \"âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½Ğ°.\"\n",
        "        elif \"400\" in error_msg:\n",
        "            detailed_msg = \"âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ°.\"\n",
        "        elif \"connection\" in error_msg.lower():\n",
        "            detailed_msg = \"âŒ ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğº Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ñƒ. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ.\"\n",
        "        else:\n",
        "            detailed_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:100]}\"\n",
        "        \n",
        "        return gr.update(value=detailed_msg, visible=True)\n",
        "\n",
        "def add_local_model_with_auth(model_path, vocab_path, model_name, hf_token=None):\n",
        "    \"\"\"Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\"\"\"\n",
        "    global local_models_config, MODELS_CONFIG, HF_TOKEN\n",
        "    \n",
        "    if not model_path or not vocab_path or not model_name:\n",
        "        return gr.update(), gr.update(value=\"âŒ Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ²ÑĞµ Ğ¿Ğ¾Ğ»Ñ\", visible=True)\n",
        "    \n",
        "    use_token = hf_token if hf_token else HF_TOKEN\n",
        "    \n",
        "    def validate_hf_path(file_path, file_type):\n",
        "        if file_path.startswith('hf://'):\n",
        "            repo_id, filename = parse_hf_path(file_path)\n",
        "            if not repo_id or not filename:\n",
        "                return False, f\"âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ HF Ğ¿ÑƒÑ‚Ğ¸ Ğ´Ğ»Ñ {file_type}\"\n",
        "            \n",
        "            if '/' not in repo_id or len(repo_id.split('/')) != 2:\n",
        "                return False, f\"âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ repo_id: {repo_id}\"\n",
        "                \n",
        "            return True, None\n",
        "        else:\n",
        "            if os.path.exists(file_path):\n",
        "                return True, None\n",
        "            else:\n",
        "                return False, f\"âŒ Ğ¤Ğ°Ğ¹Ğ» {file_type} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {file_path}\"\n",
        "    \n",
        "    is_model_valid, model_error = validate_hf_path(model_path, \"Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\")\n",
        "    if not is_model_valid:\n",
        "        return gr.update(), gr.update(value=model_error, visible=True)\n",
        "    \n",
        "    is_vocab_valid, vocab_error = validate_hf_path(vocab_path, \"ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\")\n",
        "    if not is_vocab_valid:\n",
        "        return gr.update(), gr.update(value=vocab_error, visible=True)\n",
        "    \n",
        "    def download_hf_file_with_token(hf_path, file_type):\n",
        "        if hf_path.startswith('hf://'):\n",
        "            try:\n",
        "                repo_id, filename = parse_hf_path(hf_path)\n",
        "                if not repo_id or not filename:\n",
        "                    raise ValueError(f\"Invalid HF path: {hf_path}\")\n",
        "                \n",
        "                print(f\"Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ {file_type} Ğ¸Ğ· {repo_id}/{filename}\")\n",
        "                \n",
        "                downloaded_path = hf_hub_download(\n",
        "                    repo_id=repo_id,\n",
        "                    filename=filename,\n",
        "                    repo_type=\"model\",\n",
        "                    token=use_token\n",
        "                )\n",
        "                print(f\"âœ… {file_type} ÑĞºĞ°Ñ‡Ğ°Ğ½: {downloaded_path}\")\n",
        "                return downloaded_path\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_msg = str(e)\n",
        "                if \"401\" in error_msg or \"403\" in error_msg:\n",
        "                    if use_token is None:\n",
        "                        raise PermissionError(f\"âŒ Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ {repo_id} Ğ¿Ñ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ñ‹Ğ¹. Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ñ‚Ğ¾ĞºĞµĞ½ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸!\")\n",
        "                    else:\n",
        "                        raise PermissionError(f\"âŒ ĞĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº {repo_id}. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ°.\")\n",
        "                elif \"404\" in error_msg:\n",
        "                    raise FileNotFoundError(f\"âŒ Ğ¤Ğ°Ğ¹Ğ» {filename} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ {repo_id}\")\n",
        "                else:\n",
        "                    raise e\n",
        "        else:\n",
        "            if not os.path.exists(hf_path):\n",
        "                raise FileNotFoundError(f\"Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {hf_path}\")\n",
        "            return hf_path\n",
        "    \n",
        "    try:\n",
        "        downloaded_model = download_hf_file_with_token(model_path, \"Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\")\n",
        "        downloaded_vocab = download_hf_file_with_token(vocab_path, \"ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\")\n",
        "        \n",
        "        local_models_config[model_name] = {\n",
        "            \"repo\": \"local\",\n",
        "            \"model_file\": downloaded_model,\n",
        "            \"vocab_file\": downloaded_vocab,\n",
        "            \"model_cfg\": dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "        }\n",
        "\n",
        "        save_local_models()\n",
        "        \n",
        "        updated_models_config = {**MODELS_CONFIG, **local_models_config}\n",
        "        \n",
        "        return gr.update(\n",
        "            choices=list(updated_models_config.keys()),\n",
        "            value=model_name\n",
        "        ), gr.update(value=f\"âœ… Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ '{model_name}' Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ°\", visible=True)\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)}\"\n",
        "        print(f\"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {traceback.format_exc()}\")\n",
        "        return gr.update(), gr.update(value=error_msg, visible=True)\n",
        "\n",
        "def load_model_with_progress(model_name, progress_callback=None):\n",
        "    \"\"\"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°\"\"\"\n",
        "    global loaded_models, current_model_name, stop_generation\n",
        "    \n",
        "    if stop_generation:\n",
        "        print(\"ğŸ›‘ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ\")\n",
        "        return None\n",
        "    \n",
        "    all_models_config = get_all_models_config()\n",
        "    \n",
        "    if not model_name or model_name not in all_models_config:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "    \n",
        "    if model_name in loaded_models:\n",
        "        print(f\"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ '{model_name}' ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°\")\n",
        "        return loaded_models[model_name]\n",
        "    \n",
        "    config = all_models_config[model_name]\n",
        "    \n",
        "    print(f\"ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {model_name}\")\n",
        "    \n",
        "    def download_hf_file(hf_path, file_type, progress_stage):\n",
        "        if hf_path.startswith('hf://'):\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° {file_type} Ğ¸Ğ· Hugging Face...\", progress_stage)\n",
        "            \n",
        "            try:\n",
        "                repo_id, filename = parse_hf_path(hf_path)\n",
        "                if not repo_id or not filename:\n",
        "                    raise ValueError(f\"Invalid HF path format: {hf_path}\")\n",
        "                \n",
        "                print(f\"Downloading {file_type} from HF: {repo_id}/{filename}\")\n",
        "\n",
        "                downloaded_path = hf_hub_download(\n",
        "                    repo_id=repo_id, \n",
        "                    filename=filename,\n",
        "                    repo_type=\"model\",\n",
        "                    token=HF_TOKEN\n",
        "                )\n",
        "                print(f\"âœ… {file_type} downloaded to: {downloaded_path}\")\n",
        "                return downloaded_path\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Failed to download {file_type} from HF: {e}\")\n",
        "                if \"404\" in str(e):\n",
        "                    raise FileNotFoundError(f\"Ğ¤Ğ°Ğ¹Ğ» {filename} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ {repo_id}\")\n",
        "                elif \"401\" in str(e):\n",
        "                    if HF_TOKEN is None:\n",
        "                        raise PermissionError(f\"ĞĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ {repo_id}. Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ!\")\n",
        "                    else:\n",
        "                        raise PermissionError(f\"ĞĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ {repo_id}. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½ Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ°.\")\n",
        "                else:\n",
        "                    raise e\n",
        "        else:\n",
        "            if not os.path.exists(hf_path):\n",
        "                raise FileNotFoundError(f\"{file_type} file not found: {hf_path}\")\n",
        "            return hf_path\n",
        "    \n",
        "    if config['repo'] == \"local\":\n",
        "        if progress_callback:\n",
        "            progress_callback(\"ğŸ” ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...\", 0.1)\n",
        "\n",
        "        if stop_generation:\n",
        "            print(\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\")\n",
        "            return None\n",
        "        \n",
        "        model_path = config['model_file']\n",
        "        vocab_path = config['vocab_file']\n",
        "        \n",
        "        try:\n",
        "            model_path = download_hf_file(model_path, \"model\", 0.2)\n",
        "            vocab_path = download_hf_file(vocab_path, \"vocab\", 0.3)\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            raise e\n",
        "            \n",
        "        print(f\"ğŸ“ Loading local model from: {model_path}\")\n",
        "        \n",
        "    else:\n",
        "        if progress_callback:\n",
        "            progress_callback(\"ğŸ” ĞŸĞ¾Ğ¸ÑĞº Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² HuggingFace...\", 0.1)\n",
        "        \n",
        "        if stop_generation:\n",
        "            print(\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² HF\")\n",
        "            return None\n",
        "        \n",
        "        check_cuda_availability()\n",
        "\n",
        "        if stop_generation:\n",
        "            print(\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ CUDA\")\n",
        "            return None\n",
        "        \n",
        "        if progress_callback:\n",
        "            progress_callback(\"ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...\", 0.3)\n",
        "        \n",
        "        if stop_generation:\n",
        "            print(\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²\")\n",
        "            return None\n",
        "        \n",
        "        try:\n",
        "            model_path = hf_hub_download(\n",
        "                repo_id=config['repo'], \n",
        "                filename=config['model_file'],\n",
        "                repo_type=\"model\"\n",
        "            )\n",
        "            vocab_path = hf_hub_download(\n",
        "                repo_id=config['repo'], \n",
        "                filename=config['vocab_file'],\n",
        "                repo_type=\"model\"\n",
        "            )\n",
        "            print(f\"âœ… Model downloaded to: {model_path}\")\n",
        "            print(f\"âœ… Vocab downloaded to: {vocab_path}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(\"âŒ hf_hub_download failed:\", e)\n",
        "            \n",
        "            if progress_callback:\n",
        "                progress_callback(\"ğŸ“¦ Ğ ĞµĞ·ĞµÑ€Ğ²Ğ½Ğ¾Ğµ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...\", 0.5)\n",
        "            \n",
        "            if stop_generation:\n",
        "                print(\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿ĞµÑ€ĞµĞ´ Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸ĞµĞ¹\")\n",
        "                return None\n",
        "            \n",
        "            try:\n",
        "                local_dir = f\"cache_{config['repo'].replace('/', '_')}\"\n",
        "                snapshot_dir = snapshot_download(\n",
        "                    repo_id=config['repo'], \n",
        "                    cache_dir=None, \n",
        "                    local_dir=local_dir,\n",
        "                    repo_type=\"model\",\n",
        "                    allow_patterns=[config['model_file'], config['vocab_file']]\n",
        "                )\n",
        "                \n",
        "                possible_model = os.path.join(snapshot_dir, config['model_file'])\n",
        "                possible_vocab = os.path.join(snapshot_dir, config['vocab_file'])\n",
        "                \n",
        "                if os.path.exists(possible_model):\n",
        "                    model_path = possible_model\n",
        "                    print(f\"âœ… Model found in snapshot: {model_path}\")\n",
        "                else:\n",
        "                    print(f\"âŒ Model file not found in snapshot: {possible_model}\")\n",
        "                    \n",
        "                if os.path.exists(possible_vocab):\n",
        "                    vocab_path = possible_vocab\n",
        "                    print(f\"âœ… Vocab found in snapshot: {vocab_path}\")\n",
        "                else:\n",
        "                    print(f\"âŒ Vocab file not found in snapshot: {possible_vocab}\")\n",
        "                    \n",
        "            except Exception as snapshot_error:\n",
        "                print(\"âŒ snapshot_download also failed:\", snapshot_error)\n",
        "                combined_error = f\"Original error: {e}\\nSnapshot error: {snapshot_error}\"\n",
        "                raise Exception(f\"Failed to download model: {combined_error}\")\n",
        "    \n",
        "    if stop_generation:\n",
        "        print(\"ğŸ›‘ Generation stopped during file download\")\n",
        "        return None\n",
        "    \n",
        "    if not model_path or not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"âŒ Model file not found: {model_path}\")\n",
        "    if not vocab_path or not os.path.exists(vocab_path):\n",
        "        raise FileNotFoundError(f\"âŒ Vocab file not found: {vocab_path}\")\n",
        "    \n",
        "    if stop_generation:\n",
        "        print(\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¾Ğ¹ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ\")\n",
        "        return None\n",
        "\n",
        "    if progress_callback:\n",
        "        progress_callback(\"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ...\", 0.7)\n",
        "    \n",
        "    try:\n",
        "        print(f\"ğŸ¤– Loading model architecture from: {model_path}\")\n",
        "        print(f\"ğŸ“– Using vocab file: {vocab_path}\")\n",
        "        \n",
        "        model = load_model(DiT, config['model_cfg'], model_path, vocab_file=vocab_path)\n",
        "        print(\"âœ… Model architecture loaded successfully\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ Failed to load model architecture: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        print(f\"Model config: {config['model_cfg']}\")\n",
        "        raise e\n",
        "\n",
        "    if stop_generation:\n",
        "        print(\"ğŸ›‘ Generation stopped during model loading\")\n",
        "        return None\n",
        "        \n",
        "    if stop_generation:\n",
        "        print(\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿ĞµÑ€ĞµĞ´ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¾Ğ¼ Ğ½Ğ° GPU\")\n",
        "        return None\n",
        "        \n",
        "    if progress_callback:\n",
        "        progress_callback(\"ğŸš€ ĞŸĞµÑ€ĞµĞ½Ğ¾Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° GPU...\", 0.9)\n",
        "    \n",
        "    try:\n",
        "        device = torch.device(\"cuda\")\n",
        "        model.to(device)\n",
        "        print(f\"âœ… Model moved to CUDA: {device}\")\n",
        "        \n",
        "        if next(model.parameters()).is_cuda:\n",
        "            print(\"âœ… Model parameters are on GPU\")\n",
        "        else:\n",
        "            print(\"âš ï¸ Warning: Model parameters might not be on GPU\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ Failed to move model to GPU: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        raise e\n",
        "\n",
        "    if stop_generation:\n",
        "        print(\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿ĞµÑ€ĞµĞ´ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ² ĞºÑÑˆ\")\n",
        "        return None\n",
        "\n",
        "    loaded_models[model_name] = model\n",
        "    current_model_name = model_name\n",
        "\n",
        "    if progress_callback:\n",
        "        progress_callback(\"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°!\", 1.0)\n",
        "    \n",
        "    print(f\"ğŸ‰ Model '{model_name}' successfully loaded and cached\")\n",
        "    print(f\"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "def ensure_model(model_name, progress_callback=None):\n",
        "    \"\"\"Ensure model is loaded with progress tracking\"\"\"\n",
        "    global loaded_models\n",
        "    \n",
        "    if not model_name:\n",
        "        raise ValueError(\"Model name must be specified\")\n",
        "    \n",
        "    all_models_config = get_all_models_config()\n",
        "    \n",
        "    if model_name not in all_models_config:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "    \n",
        "    if model_name in loaded_models:\n",
        "        return loaded_models[model_name]\n",
        "    \n",
        "    return load_model_with_progress(model_name, progress_callback)\n",
        "\n",
        "def ensure_vocoder():\n",
        "    global loaded_vocoder\n",
        "    if loaded_vocoder is not None:\n",
        "        return loaded_vocoder\n",
        "\n",
        "    check_cuda_availability()\n",
        "\n",
        "    print(\"â³ Loading vocoder...\")\n",
        "    \n",
        "    try:\n",
        "        loaded_vocoder = load_vocoder()\n",
        "        device = torch.device(\"cuda\")\n",
        "        loaded_vocoder.to(device)\n",
        "        print(\"âœ… Vocoder loaded successfully\")\n",
        "        return loaded_vocoder\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Vocoder loading failed: {e}\")\n",
        "        raise e\n",
        "\n",
        "def stop_generation_process():\n",
        "    \"\"\"ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ - ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ„Ğ»Ğ°Ğ³\"\"\"\n",
        "    global stop_generation, generation_event, stop_requested\n",
        "    \n",
        "    print(\"ğŸ›‘ ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¸Ğ» Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºÑƒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸...\")\n",
        "    stop_generation = True\n",
        "    stop_requested = True\n",
        "    generation_event.set()\n",
        "    \n",
        "    global generation_thread\n",
        "    if generation_thread and generation_thread.is_alive():\n",
        "        print(\"âš ï¸ ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸...\")\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    print(\"âœ… Ğ¤Ğ»Ğ°Ğ³ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½, Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ° Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ CUDA\")\n",
        "    return \"ğŸ›‘ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºÑƒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½...\"\n",
        "\n",
        "def reset_generation_flags():\n",
        "    \"\"\"Ğ¡Ğ±Ñ€Ğ¾Ñ Ñ„Ğ»Ğ°Ğ³Ğ¾Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµĞ´ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾Ğ¼ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸\"\"\"\n",
        "    global stop_generation, generation_event, stop_requested\n",
        "    stop_generation = False\n",
        "    stop_requested = False\n",
        "    generation_event.clear()\n",
        "    print(\"ğŸ”„ Ğ¤Ğ»Ğ°Ğ³Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ±Ñ€Ğ¾ÑˆĞµĞ½Ñ‹\")\n",
        "\n",
        "def check_stop_generation():\n",
        "    \"\"\"ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ„Ğ»Ğ°Ğ³Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ (Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¸Ğ· Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸)\"\"\"\n",
        "    global stop_generation, generation_event\n",
        "    \n",
        "    if stop_generation:\n",
        "        print(\"ğŸ›‘ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸!\")\n",
        "        raise KeyboardInterrupt(\"Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼\")\n",
        "    \n",
        "    if generation_event.is_set():\n",
        "        print(\"ğŸ›‘ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸!\")\n",
        "        raise KeyboardInterrupt(\"Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼\")\n",
        "    \n",
        "    return False\n",
        "\n",
        "# ================ ĞĞĞ’Ğ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ”Ğ›Ğ¯ ĞĞĞĞ›Ğ˜Ğ—Ğ Ğ˜ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ˜ ĞĞ£Ğ”Ğ˜Ğ ================\n",
        "\n",
        "def analyze_audio_loudness(audio_path):\n",
        "    \"\"\"\n",
        "    ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸\n",
        "    \n",
        "    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚:\n",
        "    - ÑÑ€ĞµĞ´Ğ½ÑÑ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ (dBFS)\n",
        "    - Ğ¿Ğ¸ĞºĞ¾Ğ²ÑƒÑ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ (dBFS)\n",
        "    - Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½\n",
        "    - Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸\n",
        "    - Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸\n",
        "    \"\"\"\n",
        "    if not audio_path or not os.path.exists(audio_path):\n",
        "        return None, None, None, \"âŒ ĞÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½\", \"\"\n",
        "    \n",
        "    try:\n",
        "        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        \n",
        "        # Ğ Ğ°ÑÑÑ‡ĞµÑ‚ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸\n",
        "        loudness = audio.dBFS  # Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ Ğ² dBFS\n",
        "        max_loudness = audio.max_dBFS  # ĞŸĞ¸ĞºĞ¾Ğ²Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ\n",
        "        \n",
        "        # Ğ Ğ°ÑÑÑ‡ĞµÑ‚ RMS Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°\n",
        "        samples = np.array(audio.get_array_of_samples())\n",
        "        if audio.channels == 2:\n",
        "            samples = samples.reshape((-1, 2)).mean(axis=1)\n",
        "        \n",
        "        rms = np.sqrt(np.mean(samples.astype(np.float64)**2))\n",
        "        rms_db = 20 * np.log10(rms / (2**15)) if rms > 0 else -100\n",
        "        \n",
        "        # Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½\n",
        "        dynamic_range = max_loudness - loudness if max_loudness > -100 and loudness > -100 else 0\n",
        "        \n",
        "        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸\n",
        "        loudness_status = \"ğŸ”´ Ğ¡Ğ›Ğ˜Ğ¨ĞšĞĞœ Ğ¢Ğ˜Ğ¥Ğ\"\n",
        "        loudness_emoji = \"ğŸ”´\"\n",
        "        recommendation = \"Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸ Ğ½Ğ° 10-15 dB\"\n",
        "        \n",
        "        if loudness > -20:\n",
        "            loudness_status = \"ğŸŸ¢ ĞĞŸĞ¢Ğ˜ĞœĞĞ›Ğ¬ĞĞ\"\n",
        "            loudness_emoji = \"ğŸŸ¢\"\n",
        "            recommendation = \"Ğ“Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ Ğ² Ğ½Ğ¾Ñ€Ğ¼Ğµ. ĞœĞ¾Ğ¶Ğ½Ğ¾ ÑĞ»ĞµĞ³ĞºĞ° ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ñ (+3 dB)\"\n",
        "        elif loudness > -25:\n",
        "            loudness_status = \"ğŸŸ¡ ĞĞĞ ĞœĞĞ›Ğ¬ĞĞ\"\n",
        "            loudness_emoji = \"ğŸŸ¡\"\n",
        "            recommendation = \"Ğ“Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ»ĞµĞ¼Ğ°Ñ. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ»ĞµĞ³ĞºĞ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (+5 dB)\"\n",
        "        elif loudness > -30:\n",
        "            loudness_status = \"ğŸŸ  Ğ¢Ğ˜Ğ¥Ğ\"\n",
        "            loudness_emoji = \"ğŸŸ \"\n",
        "            recommendation = \"Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ñ‚Ğ¸Ñ…Ğ°Ñ. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (+10 dB)\"\n",
        "        \n",
        "        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¸ĞºĞ¾Ğ²\n",
        "        peak_status = \"ğŸŸ¢ ĞĞĞ ĞœĞ\"\n",
        "        if max_loudness > -1:\n",
        "            peak_status = \"ğŸ”´ ĞŸĞ•Ğ Ğ•Ğ“Ğ Ğ£Ğ—ĞšĞ!\"\n",
        "            recommendation += \" Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ ĞºĞ»Ğ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³ (Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºĞ°)!\"\n",
        "        elif max_loudness > -3:\n",
        "            peak_status = \"ğŸŸ  Ğ‘Ğ›Ğ˜Ğ—ĞšĞ Ğš ĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ£\"\n",
        "            recommendation += \" Ğ‘ÑƒĞ´ÑŒÑ‚Ğµ Ğ¾ÑÑ‚Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ñ‹: Ğ¿Ğ¸ĞºĞ¸ Ğ±Ğ»Ğ¸Ğ·ĞºĞ¸ Ğº Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñƒ.\"\n",
        "        \n",
        "        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸\n",
        "        loudness_bar = create_loudness_visualization(loudness, max_loudness)\n",
        "        \n",
        "        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°\n",
        "        analysis_report = f\"\"\"\n",
        "        <div style=\"background: #f8f9fa; padding: 20px; border-radius: 10px; border-left: 5px solid {'#28a745' if loudness_emoji == 'ğŸŸ¢' else '#ffc107' if loudness_emoji == 'ğŸŸ¡' else '#fd7e14' if loudness_emoji == 'ğŸŸ ' else '#dc3545'};\">\n",
        "            <h3>ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸</h3>\n",
        "            \n",
        "            <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin: 15px 0;\">\n",
        "                <div style=\"background: white; padding: 10px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
        "                    <strong>Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ:</strong><br>\n",
        "                    <span style=\"font-size: 24px; font-weight: bold; color: {'#28a745' if loudness_emoji == 'ğŸŸ¢' else '#ffc107' if loudness_emoji == 'ğŸŸ¡' else '#fd7e14' if loudness_emoji == 'ğŸŸ ' else '#dc3545'}\">\n",
        "                        {loudness:.1f} dBFS\n",
        "                    </span><br>\n",
        "                    <strong>Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:</strong> {loudness_status}\n",
        "                </div>\n",
        "                \n",
        "                <div style=\"background: white; padding: 10px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
        "                    <strong>ĞŸĞ¸ĞºĞ¾Ğ²Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ:</strong><br>\n",
        "                    <span style=\"font-size: 24px; font-weight: bold; color: {'#28a745' if max_loudness < -3 else '#ffc107' if max_loudness < -1 else '#dc3545'}\">\n",
        "                        {max_loudness:.1f} dBFS\n",
        "                    </span><br>\n",
        "                    <strong>Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:</strong> {peak_status}\n",
        "                </div>\n",
        "            </div>\n",
        "            \n",
        "            <div style=\"margin: 15px 0;\">\n",
        "                <strong>Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ:</strong><br>\n",
        "                {loudness_bar}\n",
        "            </div>\n",
        "            \n",
        "            <div style=\"background: white; padding: 15px; border-radius: 5px; margin: 15px 0; border-left: 4px solid #007bff;\">\n",
        "                <strong>ğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸:</strong><br>\n",
        "                {recommendation}\n",
        "            </div>\n",
        "            \n",
        "            <div style=\"font-size: 12px; color: #6c757d; margin-top: 10px;\">\n",
        "                ğŸ“ˆ <strong>Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸:</strong><br>\n",
        "                â€¢ Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½: {dynamic_range:.1f} dB<br>\n",
        "                â€¢ RMS ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ: {rms_db:.1f} dBFS<br>\n",
        "                â€¢ Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: {len(audio)/1000:.1f} ÑĞµĞº<br>\n",
        "                â€¢ Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ğ°: {audio.frame_rate} Ğ“Ñ†<br>\n",
        "                â€¢ ĞšĞ°Ğ½Ğ°Ğ»Ñ‹: {audio.channels}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        \n",
        "        return loudness, max_loudness, dynamic_range, analysis_report, loudness_bar\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ°ÑƒĞ´Ğ¸Ğ¾: {e}\")\n",
        "        return None, None, None, f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {str(e)[:100]}\", \"\"\n",
        "\n",
        "def create_loudness_visualization(loudness, max_loudness):\n",
        "    \"\"\"Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸\"\"\"\n",
        "    # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\n",
        "    loudness_norm = max(0, min(100, (loudness + 60) * 1.67))  # -60dB = 0%, 0dB = 100%\n",
        "    max_norm = max(0, min(100, (max_loudness + 60) * 1.67))\n",
        "    \n",
        "    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ·Ğ¾Ğ½Ñ‹\n",
        "    def get_color(value):\n",
        "        if value < 25:\n",
        "            return \"#dc3545\"  # ĞšÑ€Ğ°ÑĞ½Ñ‹Ğ¹ - ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ñ‚Ğ¸Ñ…Ğ¾\n",
        "        elif value < 50:\n",
        "            return \"#fd7e14\"  # ĞÑ€Ğ°Ğ½Ğ¶ĞµĞ²Ñ‹Ğ¹ - Ñ‚Ğ¸Ñ…Ğ¾\n",
        "        elif value < 75:\n",
        "            return \"#ffc107\"  # Ğ–ĞµĞ»Ñ‚Ñ‹Ğ¹ - Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾\n",
        "        else:\n",
        "            return \"#28a745\"  # Ğ—ĞµĞ»ĞµĞ½Ñ‹Ğ¹ - Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾\n",
        "    \n",
        "    loudness_color = get_color(loudness_norm)\n",
        "    peak_color = \"#6f42c1\" if max_norm > 95 else get_color(max_norm)\n",
        "    \n",
        "    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ HTML Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\n",
        "    visualization = f\"\"\"\n",
        "    <div style=\"width: 100%; height: 40px; background: linear-gradient(to right, #dc3545 0%, #fd7e14 25%, #ffc107 50%, #28a745 75%, #28a745 100%); border-radius: 5px; position: relative; margin: 10px 0;\">\n",
        "        <!-- Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ -->\n",
        "        <div style=\"position: absolute; left: {loudness_norm}%; top: 0; bottom: 0; width: 4px; background: {loudness_color}; border-radius: 2px; transform: translateX(-50%);\">\n",
        "            <div style=\"position: absolute; bottom: 100%; left: 50%; transform: translateX(-50%); white-space: nowrap; font-size: 12px; font-weight: bold; color: {loudness_color};\">\n",
        "                Ğ¡Ñ€ĞµĞ´: {loudness:.1f}dB\n",
        "            </div>\n",
        "        </div>\n",
        "        \n",
        "        <!-- ĞŸĞ¸ĞºĞ¾Ğ²Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ -->\n",
        "        <div style=\"position: absolute; left: {max_norm}%; top: 0; bottom: 0; width: 4px; background: {peak_color}; border-radius: 2px; transform: translateX(-50%);\">\n",
        "            <div style=\"position: absolute; top: 100%; left: 50%; transform: translateX(-50%); white-space: nowrap; font-size: 12px; font-weight: bold; color: {peak_color};\">\n",
        "                ĞŸĞ¸Ğº: {max_loudness:.1f}dB\n",
        "            </div>\n",
        "        </div>\n",
        "        \n",
        "        <!-- Ğ Ğ°Ğ·Ğ¼ĞµÑ‚ĞºĞ° -->\n",
        "        <div style=\"position: absolute; left: 0; right: 0; top: 50%; transform: translateY(-50%); display: flex; justify-content: space-between; padding: 0 5px; font-size: 10px; color: #666;\">\n",
        "            <span>-60dB</span>\n",
        "            <span>-30dB</span>\n",
        "            <span>0dB</span>\n",
        "        </div>\n",
        "    </div>\n",
        "    \n",
        "    <div style=\"display: flex; justify-content: space-between; font-size: 11px; color: #6c757d; margin-top: 5px;\">\n",
        "        <span>ğŸ”´ Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ñ‚Ğ¸Ñ…Ğ¾</span>\n",
        "        <span>ğŸŸ  Ğ¢Ğ¸Ñ…Ğ¾</span>\n",
        "        <span>ğŸŸ¡ ĞĞ¾Ñ€Ğ¼Ğ°</span>\n",
        "        <span>ğŸŸ¢ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾</span>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    \n",
        "    return visualization\n",
        "\n",
        "def normalize_audio_enhanced(audio_path, target_loudness=-16.0, headroom=1.0, audio_format=None):\n",
        "    \"\"\"\n",
        "    Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ñ‚Ğ¾Ñ‚ Ğ¶Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚\n",
        "    \n",
        "    Args:\n",
        "        audio_path: Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ñƒ\n",
        "        target_loudness: Ñ†ĞµĞ»ĞµĞ²Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ Ğ² dBFS (ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚: -16 dBFS Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´ĞºĞ°ÑÑ‚Ğ¾Ğ², -14 Ğ´Ğ»Ñ Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸)\n",
        "        headroom: Ğ·Ğ°Ğ¿Ğ°Ñ Ğ´Ğ¾ ĞºĞ»Ğ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° Ğ² dB\n",
        "        audio_format: Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ (ĞµÑĞ»Ğ¸ None, Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ÑÑ Ğ¸Ğ· Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°)\n",
        "    \n",
        "    Returns:\n",
        "        Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ñ„Ğ°Ğ¹Ğ»Ñƒ\n",
        "    \"\"\"\n",
        "    if not audio_path or not os.path.exists(audio_path):\n",
        "        return None, \"âŒ ĞÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½\"\n",
        "    \n",
        "    try:\n",
        "        print(f\"ğŸšï¸ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾: {audio_path}\")\n",
        "        \n",
        "        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚\n",
        "        if audio_format is None:\n",
        "            audio_format = os.path.splitext(audio_path)[1].lower().replace('.', '')\n",
        "            if audio_format not in ['wav', 'mp3', 'ogg', 'flac']:\n",
        "                audio_format = 'wav'  # Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ\n",
        "        \n",
        "        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        \n",
        "        # ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ\n",
        "        current_loudness = audio.dBFS\n",
        "        max_loudness = audio.max_dBFS\n",
        "        print(f\"ğŸ“Š Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ: {current_loudness:.1f} dBFS\")\n",
        "        print(f\"ğŸ“Š ĞŸĞ¸ĞºĞ¾Ğ²Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ: {max_loudness:.1f} dBFS\")\n",
        "        \n",
        "        # Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼ÑƒÑ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ\n",
        "        needed_gain = target_loudness - current_loudness\n",
        "        \n",
        "        # Ğ£Ñ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ¿Ğ°Ñ Ğ´Ğ¾ ĞºĞ»Ğ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°\n",
        "        if max_loudness + needed_gain > -headroom:\n",
        "            # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ ĞºĞ»Ğ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°\n",
        "            safe_gain = (-headroom) - max_loudness\n",
        "            if safe_gain < needed_gain:\n",
        "                needed_gain = safe_gain\n",
        "                print(f\"âš ï¸ ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ğ½Ğ¸Ñ ĞºĞ»Ğ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°: {needed_gain:.1f} dB\")\n",
        "        \n",
        "        print(f\"ğŸ›ï¸ ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ: {needed_gain:.1f} dB\")\n",
        "        \n",
        "        # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ\n",
        "        if abs(needed_gain) > 0.5:  # ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ğ° Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ\n",
        "            normalized_audio = audio.apply_gain(needed_gain)\n",
        "        else:\n",
        "            print(\"â„¹ï¸ Ğ“Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ ÑƒĞ¶Ğµ Ğ±Ğ»Ğ¸Ğ·ĞºĞ° Ğº Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ¹, ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ\")\n",
        "            normalized_audio = audio\n",
        "        \n",
        "        # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· pydub (ĞºĞ¾Ğ¼Ğ¿Ñ€ĞµÑÑĞ¸Ñ Ğ¼ÑĞ³ĞºĞ¸Ñ… Ğ¿Ğ¸ĞºĞ¾Ğ²)\n",
        "        try:\n",
        "            normalized_audio = normalize(normalized_audio)\n",
        "            print(\"âœ… ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ° Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\")\n",
        "        except:\n",
        "            print(\"âš ï¸ Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²ÑƒÑ\")\n",
        "        \n",
        "        # ĞœÑĞ³ĞºĞ¾Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¸ĞºĞ¾Ğ² (soft clipping)\n",
        "        try:\n",
        "            from pydub.effects import compress_dynamic_range\n",
        "            normalized_audio = compress_dynamic_range(normalized_audio, threshold=-3.0, ratio=2.0)\n",
        "            print(\"âœ… ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ° Ğ¼ÑĞ³ĞºĞ°Ñ ĞºĞ¾Ğ¼Ğ¿Ñ€ĞµÑÑĞ¸Ñ Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ñ Ğ¿Ğ¸ĞºĞ¾Ğ²\")\n",
        "        except:\n",
        "            print(\"âš ï¸ ĞšĞ¾Ğ¼Ğ¿Ñ€ĞµÑÑĞ¸Ñ Ğ½Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼\")\n",
        "        \n",
        "        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°\n",
        "        timestamp = int(time.time())\n",
        "        base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "        normalized_filename = f\"{base_name}_normalized_{timestamp}.{audio_format}\"\n",
        "        normalized_path = os.path.join(os.path.dirname(audio_path), normalized_filename)\n",
        "        \n",
        "        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°\n",
        "        export_params = {}\n",
        "        if audio_format == 'mp3':\n",
        "            export_params = {'format': 'mp3', 'bitrate': '192k'}\n",
        "        elif audio_format == 'ogg':\n",
        "            export_params = {'format': 'ogg', 'bitrate': '192k'}\n",
        "        elif audio_format == 'flac':\n",
        "            export_params = {'format': 'flac'}\n",
        "        else:  # wav\n",
        "            export_params = {'format': 'wav'}\n",
        "        \n",
        "        normalized_audio.export(normalized_path, **export_params)\n",
        "        \n",
        "        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚\n",
        "        normalized_audio_check = AudioSegment.from_file(normalized_path)\n",
        "        final_loudness = normalized_audio_check.dBFS\n",
        "        final_max = normalized_audio_check.max_dBFS\n",
        "        \n",
        "        print(f\"âœ… ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!\")\n",
        "        print(f\"ğŸ“Š Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ: {final_loudness:.1f} dBFS\")\n",
        "        print(f\"ğŸ“Š Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¸Ğº: {final_max:.1f} dBFS\")\n",
        "        print(f\"ğŸ’¾ Ğ¤Ğ°Ğ¹Ğ» ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {normalized_path}\")\n",
        "        \n",
        "        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² ĞºÑÑˆ\n",
        "        global normalized_audio_cache\n",
        "        normalized_audio_cache[audio_path] = normalized_path\n",
        "        \n",
        "        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚\n",
        "        report = f\"\"\"\n",
        "        <div style=\"background: #d4edda; padding: 15px; border-radius: 8px; border-left: 5px solid #28a745; margin: 10px 0;\">\n",
        "            <h4 style=\"margin-top: 0; color: #155724;\">âœ… ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!</h4>\n",
        "            <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 10px;\">\n",
        "                <div style=\"background: white; padding: 8px; border-radius: 5px;\">\n",
        "                    <strong>Ğ‘Ñ‹Ğ»Ğ¾:</strong><br>\n",
        "                    Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ: {current_loudness:.1f} dBFS<br>\n",
        "                    ĞŸĞ¸ĞºĞ¾Ğ²Ğ°Ñ: {max_loudness:.1f} dBFS\n",
        "                </div>\n",
        "                <div style=\"background: white; padding: 8px; border-radius: 5px;\">\n",
        "                    <strong>Ğ¡Ñ‚Ğ°Ğ»Ğ¾:</strong><br>\n",
        "                    Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ: {final_loudness:.1f} dBFS<br>\n",
        "                    ĞŸĞ¸ĞºĞ¾Ğ²Ğ°Ñ: {final_max:.1f} dBFS\n",
        "                </div>\n",
        "            </div>\n",
        "            <div style=\"margin-top: 10px; font-size: 14px;\">\n",
        "                <strong>Ğ£ÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ:</strong> {needed_gain:.1f} dB<br>\n",
        "                <strong>Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚:</strong> {audio_format.upper()}<br>\n",
        "                <strong>Ğ¤Ğ°Ğ¹Ğ»:</strong> {normalized_filename}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        \n",
        "        return normalized_path, report\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {str(e)}\"\n",
        "        print(f\"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾: {traceback.format_exc()}\")\n",
        "        return None, error_msg\n",
        "\n",
        "def get_normalized_audio_path(original_path):\n",
        "    \"\"\"ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸Ğ· ĞºÑÑˆĞ°\"\"\"\n",
        "    global normalized_audio_cache\n",
        "    return normalized_audio_cache.get(original_path)\n",
        "\n",
        "# ================ ĞšĞĞĞ•Ğ¦ ĞĞĞ’Ğ«Ğ¥ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ™ ================\n",
        "\n",
        "print(\"Loading RUNorm (text normalizer)...\")\n",
        "try:\n",
        "    normalizer = RUNorm()\n",
        "    normalizer.load(\n",
        "        model_size=\"medium\",\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        workdir=\"./local_cache\"\n",
        "    )\n",
        "    \n",
        "    test_text = \"13,8 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ¾Ğ² Ğ»ĞµÑ‚\"\n",
        "    try:\n",
        "        result = normalizer.norm(test_text)\n",
        "        print(f\"âœ… RUNorm.norm SUCCESS: '{test_text}' -> '{result}'\")\n",
        "        print(\"âœ… RUNorm loaded successfully with 'norm' method\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ RUNorm.norm failed: {e}\")\n",
        "        class DummyNormalizer:\n",
        "            def norm(self, text):\n",
        "                return text\n",
        "        normalizer = DummyNormalizer()\n",
        "        print(\"âš ï¸ Using dummy normalizer due to error\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to load RUNorm: {e}\")\n",
        "    print(f\"ğŸ” RUNorm error details: {traceback.format_exc()}\")\n",
        "    \n",
        "    class DummyNormalizer:\n",
        "        def norm(self, text):\n",
        "            return text\n",
        "    normalizer = DummyNormalizer()\n",
        "    print(\"âš ï¸ Using dummy normalizer due to load error\")\n",
        "\n",
        "print(\"Loading Silero Stress model...\")\n",
        "accentor = load_accentor()\n",
        "\n",
        "test_word = \"Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚\"\n",
        "test_result = accentor(test_word)\n",
        "print(f\"âœ… Silero Stress loaded. Ğ¢ĞµÑÑ‚: '{test_word}' -> '{test_result}'\")\n",
        "\n",
        "print(\"Loading Whisper ASR model (supports Russian and English)...\")\n",
        "try:\n",
        "    from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "    ASR_MODEL_NAME = \"openai/whisper-medium\"\n",
        "    asr_processor = WhisperProcessor.from_pretrained(ASR_MODEL_NAME)\n",
        "    asr_model = WhisperForConditionalGeneration.from_pretrained(ASR_MODEL_NAME)\n",
        "    asr_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Whisper model loaded. Supports Russian, English, and many other languages.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load Whisper model: {e}\")\n",
        "    asr_processor = None\n",
        "    asr_model = None\n",
        "\n",
        "def check_audio_file(audio_path):\n",
        "    \"\"\"ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ°\"\"\"\n",
        "    if not audio_path:\n",
        "        return gr.update(value=\"âŒ ĞĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ°\", visible=True)\n",
        "    \n",
        "    try:\n",
        "        if not os.path.exists(audio_path):\n",
        "            return gr.update(value=\"âŒ Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚\", visible=True)\n",
        "        \n",
        "        valid_extensions = ('.wav', '.mp3', '.ogg', '.flac', '.m4a', '.aac')\n",
        "        if not audio_path.lower().endswith(valid_extensions):\n",
        "            return gr.update(value=\"âŒ ĞĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚\", visible=True)\n",
        "        \n",
        "        try:\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            duration = len(audio) / 1000.0\n",
        "            \n",
        "            return gr.update(\n",
        "                value=f\"âœ… ĞÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ» ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚ĞµĞ½:<br>\"\n",
        "                      f\"â€¢ Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: {duration:.1f} ÑĞµĞº<br>\"\n",
        "                      f\"â€¢ Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ğ°: {audio.frame_rate} Ğ“Ñ†<br>\"\n",
        "                      f\"â€¢ ĞšĞ°Ğ½Ğ°Ğ»Ñ‹: {audio.channels}<br>\"\n",
        "                      f\"â€¢ Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {os.path.getsize(audio_path) / 1024:.1f} KB\",\n",
        "                visible=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            return gr.update(value=f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾: {str(e)[:50]}\", visible=True)\n",
        "            \n",
        "    except Exception as e:\n",
        "        return gr.update(value=f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:50]}\", visible=True)\n",
        "\n",
        "def test_whisper_model():\n",
        "    \"\"\"ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Whisper Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ¼\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ¤– Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ• WHISPER ĞœĞĞ”Ğ•Ğ›Ğ˜\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    if asr_processor is None or asr_model is None:\n",
        "        print(\"âŒ Whisper Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        sample_rate = 16000\n",
        "        duration = 2.0\n",
        "        t = np.linspace(0, duration, int(sample_rate * duration))\n",
        "        test_audio = 0.5 * np.sin(2 * np.pi * 440 * t)\n",
        "        \n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
        "            test_file = f.name\n",
        "            sf.write(test_file, test_audio, sample_rate)\n",
        "        \n",
        "        print(\"ğŸµ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»...\")\n",
        "        \n",
        "        transcription = transcribe_audio(test_file)\n",
        "        \n",
        "        try:\n",
        "            os.unlink(test_file)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        if transcription:\n",
        "            print(f\"âœ… Whisper Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚! Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ: '{transcription}'\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"âŒ Whisper Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¿ÑƒÑÑ‚ÑƒÑ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Whisper: {e}\")\n",
        "        return False\n",
        "\n",
        "def check_all_models_before_launch():\n",
        "    \"\"\"ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ²ÑĞµÑ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸš€ ĞŸĞ Ğ•Ğ”Ğ’ĞĞ Ğ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞĞ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    try:\n",
        "        check_cuda_availability()\n",
        "        print(\"âœ… CUDA Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"âŒ CUDA Ğ½Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {e}\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        test_text = \"13,8 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ¾Ğ² Ğ»ĞµÑ‚\"\n",
        "        result = normalizer.norm(test_text)\n",
        "        print(f\"âœ… RUNorm Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚: '{test_text}' -> '{result}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ RUNorm Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚: {e}\")\n",
        "    \n",
        "    try:\n",
        "        test_word = \"Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚\"\n",
        "        result = accentor(test_word)\n",
        "        print(f\"âœ… Silero Stress Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚: '{test_word}' -> '{result}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Silero Stress Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚: {e}\")\n",
        "    \n",
        "    whisper_ok = test_whisper_model()\n",
        "    \n",
        "    if not whisper_ok:\n",
        "        print(\"âš ï¸ Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: Whisper Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾!\")\n",
        "        print(\"   ĞÑƒĞ´Ğ¸Ğ¾ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°.\")\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    return True\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    if not audio_path or asr_processor is None or asr_model is None:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "        if sample_rate != 16000:\n",
        "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "            waveform = resampler(waveform)\n",
        "\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        input_audio = waveform.squeeze().numpy()\n",
        "\n",
        "        inputs = asr_processor(\n",
        "            input_audio,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_features = inputs.input_features\n",
        "\n",
        "        current_length = input_features.shape[-1]\n",
        "        if current_length < 3000:\n",
        "            pad_length = 3000 - current_length\n",
        "            input_features = torch.nn.functional.pad(input_features, (0, pad_length), mode='constant', value=0)\n",
        "        elif current_length > 3000:\n",
        "            input_features = input_features[..., :3000]\n",
        "\n",
        "        print(\"Input features shape:\", input_features.shape)\n",
        "\n",
        "        input_features = input_features.to(asr_model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            generated_ids = asr_model.generate(\n",
        "                input_features=input_features,\n",
        "                language=None,\n",
        "                task=\"transcribe\",\n",
        "            )\n",
        "\n",
        "        transcription = asr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        return transcription.strip().capitalize() + \".\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"ASR transcription failed:\", e)\n",
        "        return \"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ.\"\n",
        "\n",
        "def validate_and_transcribe_audio(audio_path):\n",
        "    \"\"\"Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ° (Ğ±ĞµĞ· Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸)\"\"\"\n",
        "    if not audio_path:\n",
        "        return None, \"\", gr.update(value=\"\", visible=False)\n",
        "    \n",
        "    try:\n",
        "        return audio_path, \"\", gr.update(value=\"\", visible=False)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Validation failed:\", e)\n",
        "        return None, \"\", gr.update(value=\"âš ï¸ **ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞµ Ğ°ÑƒĞ´Ğ¸Ğ¾**\", visible=True)\n",
        "\n",
        "def manual_transcribe_audio(audio_path):\n",
        "    \"\"\"Ğ ÑƒÑ‡Ğ½Ğ°Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾\"\"\"\n",
        "    if not audio_path:\n",
        "        return \"\", gr.update(value=\"âŒ ĞĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ°\", visible=True)\n",
        "    \n",
        "    if asr_processor is None or asr_model is None:\n",
        "        return \"\", gr.update(value=\"âŒ Whisper Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½\", visible=True)\n",
        "    \n",
        "    try:\n",
        "        transcription = transcribe_audio(audio_path)\n",
        "        if transcription:\n",
        "            return transcription, gr.update(value=\"âœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°\", visible=True)\n",
        "        else:\n",
        "            return \"\", gr.update(value=\"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ\", visible=True)\n",
        "    except Exception as e:\n",
        "        print(f\"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸: {e}\")\n",
        "        return \"\", gr.update(value=f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:50]}\", visible=True)\n",
        "\n",
        "def process_text_with_accent(text):\n",
        "    \"\"\"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ° Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· silero-stress Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ±ÑƒĞºĞ² 'Ñ‘'\"\"\"\n",
        "    if not text or not text.strip():\n",
        "        print(\"âŒ ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸\")\n",
        "        return text\n",
        "\n",
        "    if '+' in text:\n",
        "        print(\"âœ… Ğ¢ĞµĞºÑÑ‚ ÑƒĞ¶Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ\")\n",
        "        return text\n",
        "\n",
        "    try:\n",
        "        print(f\"ğŸ¯ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ñ‚ĞµĞºÑÑ‚Ğ°: '{text}'\")\n",
        "        \n",
        "        words_and_delimiters = re.split(r'(\\W+)', text)\n",
        "        result_parts = []\n",
        "        \n",
        "        print(f\"ğŸ” ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(words_and_delimiters)} Ñ‡Ğ°ÑÑ‚ĞµĞ¹\")\n",
        "        \n",
        "        for i, part in enumerate(words_and_delimiters):\n",
        "            if part.strip() and re.match(r'^\\w+$', part):\n",
        "                print(f\"ğŸ”¤ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ»Ğ¾Ğ²Ğ° {i+1}: '{part}'\")\n",
        "                try:\n",
        "                    processed_word = accentor(part)\n",
        "                    print(f\"âœ… Ğ¡Ğ»Ğ¾Ğ²Ğ¾ '{part}' -> '{processed_word}'\")\n",
        "                    \n",
        "                    processed_word_list = list(processed_word)\n",
        "                    original_word = part\n",
        "                    \n",
        "                    for j, orig_char in enumerate(original_word):\n",
        "                        if j < len(processed_word_list):\n",
        "                            if (orig_char in ['Ñ‘', 'Ğ'] and \n",
        "                                processed_word_list[j].lower() == 'Ğµ'):\n",
        "                                processed_word_list[j] = orig_char\n",
        "                                print(f\"ğŸ”„ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ±ÑƒĞºĞ²Ğ° '{orig_char}' Ğ½Ğ° Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ {j}\")\n",
        "                    \n",
        "                    processed_word = ''.join(processed_word_list)\n",
        "                    print(f\"ğŸ”„ ĞŸĞ¾ÑĞ»Ğµ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ‘/Ğ: '{processed_word}'\")\n",
        "                    \n",
        "                    if part and processed_word:\n",
        "                        if part[0].isupper():\n",
        "                            processed_word = processed_word[0].upper() + processed_word[1:]\n",
        "                            print(f\"ğŸ”  Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ²ĞµÑ€Ñ…Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€: '{processed_word}'\")\n",
        "                        else:\n",
        "                            processed_word = processed_word[0].lower() + processed_word[1:]\n",
        "                            print(f\"ğŸ”¡ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ½Ğ¸Ğ¶Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€: '{processed_word}'\")\n",
        "                        \n",
        "                        result_parts.append(processed_word)\n",
        "                    else:\n",
        "                        print(f\"âš ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ÑĞ»Ğ¾Ğ²Ğ¾ '{part}'\")\n",
        "                        result_parts.append(part)\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ Silero stress failed for word '{part}': {e}\")\n",
        "                    result_parts.append(part)\n",
        "            else:\n",
        "                if part.strip():\n",
        "                    print(f\"ğŸ“ ĞĞµ-ÑĞ»Ğ¾Ğ²Ğ¾: '{part}'\")\n",
        "                result_parts.append(part)\n",
        "        \n",
        "        final_result = ''.join(result_parts)\n",
        "        final_result = final_result.replace('[', '').replace(']', '')\n",
        "\n",
        "        print(f\"ğŸ¯ Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ñ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ¸ (Ğ±ĞµĞ· []): '{final_result}'\")\n",
        "        print(f\"ğŸ“Š Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ: Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹: '{text}' -> ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹: '{final_result}'\")\n",
        "        return final_result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Text processing failed: {e}\")\n",
        "        print(f\"ğŸ” Traceback: {traceback.format_exc()}\")\n",
        "        return text\n",
        "\n",
        "def normalize_gen_text(gen_text):\n",
        "    \"\"\"ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ (silero-stress)\"\"\"\n",
        "    if gen_text and isinstance(gen_text, str):\n",
        "        if any(bad in gen_text for bad in [\"/tmp/\", \".wav\", \".mp3\", \".ogg\", \".flac\", \"/home/\", \"/root/\"]):\n",
        "            gen_text = \"\"\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ğŸ”„ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ Ğ”Ğ›Ğ¯ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜\")\n",
        "    print(f\"ğŸ“– Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: '{gen_text}'\")\n",
        "    \n",
        "    contains_digits = any(char.isdigit() for char in gen_text) if gen_text else False\n",
        "    \n",
        "    if gen_text and contains_digits:\n",
        "        print(\"ğŸ”¢ Ğ¢ĞµĞºÑÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€Ñ‹, Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ RUNorm...\")\n",
        "        print(\"ğŸ”§ Ğ¨Ğ°Ğ³ 1: ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· RUNorm...\")\n",
        "        try:\n",
        "            normalized_text = normalizer.norm(gen_text)\n",
        "            print(f\"ğŸ“ ĞŸĞ¾ÑĞ»Ğµ RUNorm: '{normalized_text}'\")\n",
        "        except Exception as norm_error:\n",
        "            print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° RUNorm: {norm_error}\")\n",
        "            normalized_text = gen_text\n",
        "    else:\n",
        "        if gen_text and not contains_digits:\n",
        "            print(\"ğŸ”¤ Ğ¢ĞµĞºÑÑ‚ Ğ½Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ RUNorm...\")\n",
        "        normalized_text = gen_text if gen_text else \"\"\n",
        "    \n",
        "    if normalized_text:\n",
        "        print(\"ğŸ”§ Ğ¨Ğ°Ğ³ 2: ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ğ¹...\")\n",
        "        processed_gen = process_text_with_accent(normalized_text)\n",
        "        print(f\"âœ… Ğ¢ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: '{processed_gen}'\")\n",
        "    else:\n",
        "        processed_gen = \"\"\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    return processed_gen\n",
        "\n",
        "def normalize_ref_text(ref_text):\n",
        "    \"\"\"ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ° (RUNorm + silero-stress)\"\"\"\n",
        "    if ref_text and isinstance(ref_text, str):\n",
        "        if any(bad in ref_text for bad in [\"/tmp/\", \".wav\", \".mp3\", \".ogg\", \".flac\", \"/home/\", \"/root/\"]):\n",
        "            ref_text = \"\"\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ğŸ”„ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ Ğ•Ğ¤Ğ•Ğ Ğ•ĞĞ¡ĞĞĞ“Ğ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ\")\n",
        "    print(f\"ğŸ“– Ğ ĞµÑ„ĞµÑ€ĞµĞ½Ñ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: '{ref_text}'\")\n",
        "    \n",
        "    contains_digits = any(char.isdigit() for char in ref_text) if ref_text else False\n",
        "    \n",
        "    if ref_text and contains_digits:\n",
        "        print(\"ğŸ”¢ Ğ¢ĞµĞºÑÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€Ñ‹, Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ RUNorm...\")\n",
        "        print(\"ğŸ”§ Ğ¨Ğ°Ğ³ 1: ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· RUNorm...\")\n",
        "        try:\n",
        "            normalized_text = normalizer.norm(ref_text)\n",
        "            print(f\"ğŸ“ ĞŸĞ¾ÑĞ»Ğµ RUNorm: '{normalized_text}'\")\n",
        "        except Exception as norm_error:\n",
        "            print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° RUNorm: {norm_error}\")\n",
        "            normalized_text = ref_text\n",
        "    else:\n",
        "        if ref_text and not contains_digits:\n",
        "            print(\"ğŸ”¤ Ğ¢ĞµĞºÑÑ‚ Ğ½Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ RUNorm...\")\n",
        "        normalized_text = ref_text if ref_text else \"\"\n",
        "    \n",
        "    if normalized_text:\n",
        "        print(\"ğŸ”§ Ğ¨Ğ°Ğ³ 2: ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ğ¹...\")\n",
        "        processed_ref = process_text_with_accent(normalized_text)\n",
        "        print(f\"âœ… Ğ ĞµÑ„ĞµÑ€ĞµĞ½Ñ Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: '{processed_ref}'\")\n",
        "    else:\n",
        "        processed_ref = \"\"\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    return processed_ref\n",
        "\n",
        "def normalize_ref_text_with_steps(ref_text):\n",
        "    \"\"\"ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ° Ñ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ ÑˆĞ°Ğ³Ğ°Ğ¼Ğ¸ RUNorm â†’ Silero Stress\"\"\"\n",
        "    if not ref_text or not ref_text.strip():\n",
        "        return ref_text, \"âŒ ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚\", \"âŒ ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚\"\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ğŸ”„ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ Ğ•Ğ¤Ğ•Ğ Ğ•ĞĞ¡ĞĞĞ“Ğ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ (2 Ğ¨ĞĞ“Ğ)\")\n",
        "    print(f\"ğŸ“– Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚: '{ref_text}'\")\n",
        "    \n",
        "    step1_result = \"\"\n",
        "    step2_result = \"\"\n",
        "    step1_status = \"\"\n",
        "    \n",
        "    try:\n",
        "        contains_digits = any(char.isdigit() for char in ref_text)\n",
        "        \n",
        "        if contains_digits:\n",
        "            print(\"ğŸ”¢ Ğ¢ĞµĞºÑÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€Ñ‹, Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ RUNorm...\")\n",
        "            print(\"ğŸ”§ Ğ¨Ğ°Ğ³ 1: Ğ—Ğ°Ğ¿ÑƒÑĞº RUNorm...\")\n",
        "            step1_result = normalizer.norm(ref_text)\n",
        "            print(f\"âœ… RUNorm Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: '{step1_result}'\")\n",
        "            step1_status = f\"âœ… RUNorm (Ñ†Ğ¸Ñ„Ñ€Ñ‹ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹): '{step1_result}'\"\n",
        "        else:\n",
        "            print(\"ğŸ”¤ Ğ¢ĞµĞºÑÑ‚ Ğ½Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ RUNorm...\")\n",
        "            step1_result = ref_text\n",
        "            step1_status = \"â­ï¸ RUNorm Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ (Ğ½ĞµÑ‚ Ñ†Ğ¸Ñ„Ñ€)\"\n",
        "        \n",
        "        print(\"ğŸ”§ Ğ¨Ğ°Ğ³ 2: Ğ—Ğ°Ğ¿ÑƒÑĞº Silero Stress...\")\n",
        "        step2_result = process_text_with_accent(step1_result)\n",
        "        print(f\"âœ… Silero Stress Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: '{step2_result}'\")\n",
        "\n",
        "        step2_cleaned = step2_result.replace('[', '').replace(']', '')\n",
        "        print(f\"ğŸ§¹ Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ñ‹ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ []: '{step2_result}' â†’ '{step2_cleaned}'\")\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"ğŸ¯ Ğ˜Ñ‚Ğ¾Ğ³: '{ref_text}' â†’ '{step2_cleaned}'\")\n",
        "        print(f\"ğŸ“ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:\")\n",
        "        print(f\"   Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚: {len(ref_text)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²\")\n",
        "        print(f\"   ĞŸĞ¾ÑĞ»Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: {len(step2_cleaned)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²\")\n",
        "\n",
        "        return step2_cleaned, step1_status, f\"âœ… Silero Stress: '{step2_cleaned}'\"\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return ref_text, f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:50]}\", \"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ° ÑˆĞ°Ğ³Ğµ 2\"\n",
        "\n",
        "def normalize_gen_text_with_steps(gen_text):\n",
        "    \"\"\"ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ ÑˆĞ°Ğ³Ğ°Ğ¼Ğ¸ RUNorm â†’ Silero Stress\"\"\"\n",
        "    if not gen_text or not gen_text.strip():\n",
        "        return gen_text, \"âŒ ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚\", \"âŒ ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚\"\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ğŸ”„ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ (2 Ğ¨ĞĞ“Ğ)\")\n",
        "    print(f\"ğŸ“– Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚: '{gen_text}'\")\n",
        "    \n",
        "    step1_result = \"\"\n",
        "    step2_result = \"\"\n",
        "    step1_status = \"\"\n",
        "    \n",
        "    try:\n",
        "        contains_digits = any(char.isdigit() for char in gen_text)\n",
        "        \n",
        "        if contains_digits:\n",
        "            print(\"ğŸ”¢ Ğ¢ĞµĞºÑÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€Ñ‹, Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ RUNorm...\")\n",
        "            print(\"ğŸ”§ Ğ¨Ğ°Ğ³ 1: Ğ—Ğ°Ğ¿ÑƒÑĞº RUNorm...\")\n",
        "            \n",
        "            try:\n",
        "                step1_result = normalizer.norm(gen_text)\n",
        "                print(f\"âœ… RUNorm Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: '{step1_result}'\")\n",
        "                step1_status = f\"âœ… RUNorm (Ñ†Ğ¸Ñ„Ñ€Ñ‹ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹): '{step1_result}'\"\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_msg = str(e)\n",
        "                print(f\"âš ï¸ RUNorm Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ: {error_msg}\")\n",
        "                \n",
        "                if \"'token_type_ids'\" in error_msg:\n",
        "                    print(\"ğŸ› ï¸ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ° token_type_ids, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ patch Ğ´Ğ»Ñ RUNorm...\")\n",
        "                    \n",
        "                    try:\n",
        "                        if hasattr(normalizer, 'tokenizer'):\n",
        "                            tokenizer = normalizer.tokenizer\n",
        "                            model = normalizer.model\n",
        "                            device = normalizer.device\n",
        "                            \n",
        "                            def patched_norm(text):\n",
        "                                inputs = tokenizer(\n",
        "                                    text, \n",
        "                                    return_tensors=\"pt\", \n",
        "                                    padding=True,\n",
        "                                    truncation=True,\n",
        "                                    max_length=512\n",
        "                                )\n",
        "                                \n",
        "                                if \"token_type_ids\" in inputs:\n",
        "                                    del inputs[\"token_type_ids\"]\n",
        "                                \n",
        "                                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "                                \n",
        "                                with torch.no_grad():\n",
        "                                    outputs = model.generate(\n",
        "                                        **inputs,\n",
        "                                        max_length=512,\n",
        "                                        num_beams=5,\n",
        "                                        early_stopping=True,\n",
        "                                        no_repeat_ngram_size=3\n",
        "                                    )\n",
        "                                \n",
        "                                decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "                                return decoded[0] if decoded else text\n",
        "                            \n",
        "                            normalizer.norm = patched_norm\n",
        "                            \n",
        "                            step1_result = normalizer.norm(gen_text)\n",
        "                            print(f\"âœ… RUNorm (Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹) Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: '{step1_result}'\")\n",
        "                            step1_status = f\"âœ… RUNorm (Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½, Ñ†Ğ¸Ñ„Ñ€Ñ‹ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹): '{step1_result}'\"\n",
        "                            \n",
        "                        else:\n",
        "                            step1_result = simple_digit_replacement(gen_text)\n",
        "                            print(f\"ğŸ”„ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚ÑƒÑ Ğ·Ğ°Ğ¼ĞµĞ½Ñƒ Ñ†Ğ¸Ñ„Ñ€: '{step1_result}'\")\n",
        "                            step1_status = f\"âš ï¸ RUNorm Ğ¾ÑˆĞ¸Ğ±ĞºĞ°, Ğ¿Ñ€Ğ¾ÑÑ‚Ğ°Ñ Ğ·Ğ°Ğ¼ĞµĞ½Ğ°: '{step1_result}'\"\n",
        "                            \n",
        "                    except Exception as patch_error:\n",
        "                        print(f\"âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ RUNorm: {patch_error}\")\n",
        "                        step1_result = simple_digit_replacement(gen_text)\n",
        "                        step1_status = f\"âš ï¸ RUNorm Ğ½ĞµĞ¸ÑĞ¿Ñ€Ğ°Ğ²ĞµĞ½, Ñ€ÑƒÑ‡Ğ½Ğ°Ñ Ğ·Ğ°Ğ¼ĞµĞ½Ğ°: '{step1_result}'\"\n",
        "                        \n",
        "                else:\n",
        "                    step1_result = simple_digit_replacement(gen_text)\n",
        "                    step1_status = f\"âš ï¸ RUNorm Ğ¾ÑˆĞ¸Ğ±ĞºĞ°, Ñ€ÑƒÑ‡Ğ½Ğ°Ñ Ğ·Ğ°Ğ¼ĞµĞ½Ğ°: '{step1_result}'\"\n",
        "        else:\n",
        "            print(\"ğŸ”¤ Ğ¢ĞµĞºÑÑ‚ Ğ½Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ RUNorm...\")\n",
        "            step1_result = gen_text\n",
        "            step1_status = \"â­ï¸ RUNorm Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ (Ğ½ĞµÑ‚ Ñ†Ğ¸Ñ„Ñ€)\"\n",
        "        \n",
        "        print(\"ğŸ”§ Ğ¨Ğ°Ğ³ 2: Ğ—Ğ°Ğ¿ÑƒÑĞº Silero Stress...\")\n",
        "        step2_result = process_text_with_accent(step1_result)\n",
        "        print(f\"âœ… Silero Stress Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: '{step2_result}'\")\n",
        "\n",
        "        step2_cleaned = step2_result.replace('[', '').replace(']', '')\n",
        "        print(f\"ğŸ§¹ Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ñ‹ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ []: '{step2_result}' â†’ '{step2_cleaned}'\")\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"ğŸ¯ Ğ˜Ñ‚Ğ¾Ğ³: '{gen_text}' â†’ '{step2_cleaned}'\")\n",
        "\n",
        "        return step2_cleaned, step1_status, f\"âœ… {step2_cleaned}\"\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return gen_text, f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:50]}\", \"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ° ÑˆĞ°Ğ³Ğµ 2\"\n",
        "\n",
        "def simple_digit_replacement(text):\n",
        "    \"\"\"ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ·Ğ°Ğ¼ĞµĞ½Ğ° Ñ†Ğ¸Ñ„Ñ€ Ğ½Ğ° ÑĞ»Ğ¾Ğ²Ğ° (fallback)\"\"\"\n",
        "    digit_map = {\n",
        "        '0': 'Ğ½Ğ¾Ğ»ÑŒ',\n",
        "        '1': 'Ğ¾Ğ´Ğ¸Ğ½',\n",
        "        '2': 'Ğ´Ğ²Ğ°', \n",
        "        '3': 'Ñ‚Ñ€Ğ¸',\n",
        "        '4': 'Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ',\n",
        "        '5': 'Ğ¿ÑÑ‚ÑŒ',\n",
        "        '6': 'ÑˆĞµÑÑ‚ÑŒ',\n",
        "        '7': 'ÑĞµĞ¼ÑŒ',\n",
        "        '8': 'Ğ²Ğ¾ÑĞµĞ¼ÑŒ',\n",
        "        '9': 'Ğ´ĞµĞ²ÑÑ‚ÑŒ'\n",
        "    }\n",
        "    \n",
        "    import re\n",
        "    \n",
        "    def replace_single_digit(match):\n",
        "        num = match.group()\n",
        "        return digit_map.get(num, num)\n",
        "    \n",
        "    result = re.sub(r'\\b\\d\\b', replace_single_digit, text)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def patch_runorm_on_startup():\n",
        "    \"\"\"Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ RUNorm Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹\"\"\"\n",
        "    global normalizer\n",
        "    \n",
        "    print(\"\\nğŸ› ï¸ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ RUNorm...\")\n",
        "    \n",
        "    try:\n",
        "        test_text = \"13,8 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ¾Ğ² Ğ»ĞµÑ‚\"\n",
        "        print(f\"ğŸ§ª Ğ¢ĞµÑÑ‚ RUNorm Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼: '{test_text}'\")\n",
        "        \n",
        "        try:\n",
        "            result = normalizer.norm(test_text)\n",
        "            print(f\"âœ… RUNorm Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾: '{result}'\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            print(f\"âš ï¸ RUNorm Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {error_msg}\")\n",
        "            \n",
        "            if \"'token_type_ids'\" in error_msg:\n",
        "                print(\"ğŸ”„ ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ RUNorm...\")\n",
        "                \n",
        "                if hasattr(normalizer, 'tokenizer') and hasattr(normalizer, 'model'):\n",
        "                    \n",
        "                    original_norm = normalizer.norm\n",
        "                    \n",
        "                    def patched_norm_final(text):\n",
        "                        try:\n",
        "                            return original_norm(text)\n",
        "                        except Exception as inner_e:\n",
        "                            if \"'token_type_ids'\" in str(inner_e):\n",
        "                                tokenizer = normalizer.tokenizer\n",
        "                                model = normalizer.model\n",
        "                                device = normalizer.device\n",
        "                                \n",
        "                                inputs = tokenizer(\n",
        "                                    text, \n",
        "                                    return_tensors=\"pt\", \n",
        "                                    padding=True,\n",
        "                                    truncation=True,\n",
        "                                    max_length=512\n",
        "                                )\n",
        "                                \n",
        "                                if \"token_type_ids\" in inputs:\n",
        "                                    del inputs[\"token_type_ids\"]\n",
        "                                \n",
        "                                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "                                \n",
        "                                with torch.no_grad():\n",
        "                                    outputs = model.generate(\n",
        "                                        **inputs,\n",
        "                                        max_length=512,\n",
        "                                        num_beams=5,\n",
        "                                        early_stopping=True\n",
        "                                    )\n",
        "                                \n",
        "                                decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "                                return decoded[0] if decoded else text\n",
        "                            else:\n",
        "                                raise inner_e\n",
        "                    \n",
        "                    normalizer.norm = patched_norm_final\n",
        "                    \n",
        "                    try:\n",
        "                        result = normalizer.norm(test_text)\n",
        "                        print(f\"âœ… RUNorm Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚: '{result}'\")\n",
        "                    except:\n",
        "                        print(\"âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ RUNorm, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ·Ğ°Ğ³Ğ»ÑƒÑˆĞºÑƒ\")\n",
        "                        class DummyNormalizer:\n",
        "                            def norm(self, text):\n",
        "                                return text\n",
        "                        normalizer = DummyNormalizer()\n",
        "                        \n",
        "                else:\n",
        "                    print(\"âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°Ğ¼ RUNorm, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ·Ğ°Ğ³Ğ»ÑƒÑˆĞºÑƒ\")\n",
        "                    class DummyNormalizer:\n",
        "                        def norm(self, text):\n",
        "                            return text\n",
        "                    normalizer = DummyNormalizer()\n",
        "            else:\n",
        "                print(\"âš ï¸ ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° RUNorm, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ·Ğ°Ğ³Ğ»ÑƒÑˆĞºÑƒ\")\n",
        "                class DummyNormalizer:\n",
        "                    def norm(self, text):\n",
        "                        return text\n",
        "                normalizer = DummyNormalizer()\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ RUNorm: {e}\")\n",
        "        class DummyNormalizer:\n",
        "            def norm(self, text):\n",
        "                return text\n",
        "        normalizer = DummyNormalizer()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ”§ ĞŸĞĞ”Ğ“ĞĞ¢ĞĞ’ĞšĞ ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "patch_runorm_on_startup()\n",
        "\n",
        "test_text = \"Ğ¢ĞµÑÑ‚ 123\"\n",
        "print(f\"\\nğŸ§ª Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: '{test_text}'\")\n",
        "try:\n",
        "    normalized = normalize_gen_text_with_steps(test_text)\n",
        "    print(f\"âœ… ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚: '{normalized[0]}'\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚: {e}\")\n",
        "\n",
        "def get_current_seed_display():\n",
        "    \"\"\"ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ seed Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\"\"\"\n",
        "    global last_seed\n",
        "    if last_seed == -1:\n",
        "        last_seed = np.random.randint(0, 2**31 - 1)\n",
        "        print(f\"ğŸ² Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ seed: {last_seed}\")\n",
        "    return last_seed\n",
        "\n",
        "def update_model_loading_status(model_name):\n",
        "    \"\"\"ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\"\"\"\n",
        "    global loaded_models\n",
        "    \n",
        "    if not model_name:\n",
        "        return gr.update(value=\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    all_models_config = get_all_models_config()\n",
        "    \n",
        "    if model_name not in all_models_config:\n",
        "        return gr.update(value=f\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_name} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    if model_name in loaded_models:\n",
        "        model_type = \"ğŸ”§ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ\" if all_models_config[model_name]['repo'] == \"local\" else \"ğŸŒ HuggingFace\"\n",
        "        return gr.update(value=f\"<div class='model-status model-loaded'>âœ… {model_name} ({model_type}) Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°</div>\", visible=True)\n",
        "    else:\n",
        "        model_type = \"ğŸ”§ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ\" if all_models_config[model_name]['repo'] == \"local\" else \"ğŸŒ HuggingFace\"\n",
        "        return gr.update(value=f\"<div class='model-status model-loading'>ğŸ”„ {model_name} ({model_type}) Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°</div>\", visible=True)\n",
        "\n",
        "def load_model_with_status(model_name, progress=gr.Progress()):\n",
        "    \"\"\"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ°\"\"\"\n",
        "    global loaded_models\n",
        "    \n",
        "    if not model_name:\n",
        "        return gr.update(value=\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    try:\n",
        "        check_stop_generation()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"ğŸ›‘ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼\")\n",
        "        return gr.update(value=\"<div class='model-status model-error'>ğŸ›‘ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    if model_name in loaded_models:\n",
        "        return update_model_loading_status(model_name)\n",
        "    \n",
        "    try:\n",
        "        check_stop_generation()\n",
        "        \n",
        "        progress(0.1, desc=\"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...\")\n",
        "        \n",
        "        def progress_callback_with_stop(msg, p):\n",
        "            try:\n",
        "                check_stop_generation()\n",
        "            except KeyboardInterrupt:\n",
        "                print(f\"ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ: {msg}\")\n",
        "                raise\n",
        "            \n",
        "            progress(p, desc=msg)\n",
        "        \n",
        "        model = load_model_with_progress(model_name, progress_callback_with_stop)\n",
        "        \n",
        "        if model:\n",
        "            return update_model_loading_status(model_name)\n",
        "        else:\n",
        "            return gr.update(value=\"<div class='model-status model-error'>âŒ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¾Ñ‚Ğ¼ĞµĞ½ĞµĞ½Ğ°</div>\", visible=True)\n",
        "            \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"ğŸ›‘ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼\")\n",
        "        return gr.update(value=\"<div class='model-status model-error'>ğŸ›‘ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼</div>\", visible=True)\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸: {str(e)}\"\n",
        "        print(f\"Model loading error: {traceback.format_exc()}\")\n",
        "        return gr.update(value=f\"<div class='model-status model-error'>{error_msg}</div>\", visible=True)\n",
        "\n",
        "def on_model_select(model_name):\n",
        "    \"\"\"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² dropdown\"\"\"\n",
        "    if not model_name:\n",
        "        return gr.update(value=\"<div class='model-status model-error'>âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ°</div>\", visible=True)\n",
        "    \n",
        "    return update_model_loading_status(model_name)\n",
        "\n",
        "def synthesize(\n",
        "    ref_audio,\n",
        "    ref_text,\n",
        "    gen_text,\n",
        "    remove_silence,\n",
        "    seed_input_value,\n",
        "    remember_seed_checkbox,\n",
        "    model_choice,\n",
        "    cross_fade_duration=0.15,\n",
        "    nfe_step=32,\n",
        "    speed=1.0,\n",
        "    sway_sampling_coef=-1,\n",
        "    cfg_strength=2,\n",
        "    audio_format=\"wav\",\n",
        "    bitrate=\"192k\",\n",
        "    progress=gr.Progress()\n",
        "):\n",
        "    global stop_generation, last_seed, remember_seed, generation_thread, normalized_audio_cache\n",
        "    \n",
        "    remember_seed = remember_seed_checkbox\n",
        "    \n",
        "    reset_generation_flags()\n",
        "    \n",
        "    try:\n",
        "        check_stop_generation()\n",
        "    except KeyboardInterrupt:\n",
        "        gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "        current_model_status = update_model_loading_status(model_choice)\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "    \n",
        "    current_model_status = update_model_loading_status(model_choice)\n",
        "    \n",
        "    if stop_generation:\n",
        "        gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "    \n",
        "    progress(0.05, desc=\"ğŸ”„ ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ°...\")\n",
        "    \n",
        "    if not ref_audio:\n",
        "        gr.Warning(\"âŒ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ğ¾Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "    \n",
        "    if not gen_text or not gen_text.strip():\n",
        "        gr.Warning(\"âŒ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "        \n",
        "    if not ref_text or not ref_text.strip():\n",
        "        gr.Warning(\"âŒ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "\n",
        "    if gen_text and isinstance(gen_text, str):\n",
        "        if any(x in gen_text for x in [\"/tmp/\", \".wav\", \".mp3\", \".ogg\", \".flac\"]):\n",
        "            gr.Warning(\"âš ï¸ ĞŸĞ¾Ğ»Ğµ 'Text to Generate' ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ¿ÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚ĞµĞºÑÑ‚ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ.\")\n",
        "            return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "\n",
        "    if stop_generation:\n",
        "        gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "        return None, None, ref_text, gen_text, gr.update(value=get_current_seed_display()), current_model_status\n",
        "\n",
        "    current_seed = seed_input_value\n",
        "    if seed_input_value is None or seed_input_value < 0 or seed_input_value > 2**31 - 1:\n",
        "        current_seed = np.random.randint(0, 2**31 - 1)\n",
        "        print(f\"ğŸ² Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ seed: {current_seed}\")\n",
        "    \n",
        "    if remember_seed:\n",
        "        last_seed = current_seed\n",
        "        print(f\"ğŸ’¾ Seed ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {current_seed}\")\n",
        "    \n",
        "    torch.manual_seed(int(current_seed))\n",
        "    \n",
        "    print(f\"ğŸ² Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ seed: {current_seed} (Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚ÑŒ: {remember_seed})\")\n",
        "\n",
        "    progress(0.08, desc=\"ğŸ“ ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ°...\")\n",
        "\n",
        "    processed_ref_text = ref_text.strip() if ref_text else \"\"\n",
        "    processed_gen_text = gen_text.strip() if gen_text else \"\"\n",
        "    \n",
        "    processed_ref_text_final = processed_ref_text\n",
        "    \n",
        "    print(f\"ğŸ¯ Ğ ĞµÑ„ĞµÑ€ĞµĞ½Ñ Ñ‚ĞµĞºÑÑ‚ (ĞºĞ°Ğº ĞµÑÑ‚ÑŒ): '{processed_ref_text}'\")\n",
        "    print(f\"ğŸ¯ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ (ĞºĞ°Ğº ĞµÑÑ‚ÑŒ): '{processed_gen_text}'\")  \n",
        "    print(\"â„¹ï¸ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµĞ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹.\")\n",
        "\n",
        "    try:\n",
        "        progress(0.1, desc=\"ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹...\")\n",
        "        \n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        progress(0.15, desc=\"ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ TTS...\")\n",
        "        model = ensure_model(model_choice, lambda msg, p: progress(p, desc=msg))\n",
        "        \n",
        "        if model:\n",
        "            current_model_status = update_model_loading_status(model_choice)\n",
        "        \n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        progress(0.2, desc=\"ğŸ”Š Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ²Ğ¾ĞºĞ¾Ğ´ĞµÑ€Ğ°...\")\n",
        "        vocoder = ensure_vocoder()\n",
        "        \n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "            \n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: {str(e)}\"\n",
        "        gr.Warning(error_msg)\n",
        "        print(f\"Model loading error: {traceback.format_exc()}\")\n",
        "        return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "    if model is None or vocoder is None:\n",
        "        gr.Warning(\"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\")\n",
        "        return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    try:\n",
        "        progress(0.3, desc=\"ğŸ”§ ĞŸÑ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾...\")\n",
        "        \n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        try:\n",
        "            ref_audio_proc, processed_ref_text_final = preprocess_ref_audio_text(\n",
        "                ref_audio,\n",
        "                processed_ref_text,\n",
        "                show_info=gr.Info\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: {str(e)}\"\n",
        "            gr.Warning(error_msg)\n",
        "            traceback.print_exc()\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        progress(0.5, desc=\"ğŸµ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾...\")\n",
        "        \n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        try:\n",
        "            final_wave, final_sample_rate, combined_spectrogram = infer_process(\n",
        "                ref_audio_proc,\n",
        "                processed_ref_text_final,\n",
        "                processed_gen_text,\n",
        "                model,\n",
        "                vocoder,\n",
        "                cross_fade_duration=cross_fade_duration,\n",
        "                nfe_step=nfe_step,\n",
        "                speed=speed,\n",
        "                sway_sampling_coef=sway_sampling_coef,\n",
        "                cfg_strength=cfg_strength,\n",
        "                show_info=gr.Info,\n",
        "                progress=progress,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾: {str(e)}\"\n",
        "            gr.Warning(error_msg)\n",
        "            traceback.print_exc()\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "        \n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "        if remove_silence:\n",
        "            progress(0.7, desc=\"ğŸ”‡ Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñ‹...\")\n",
        "            \n",
        "            if stop_generation:\n",
        "                gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "                return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "            \n",
        "            try:\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".wav\", **tempfile_kwargs) as f:\n",
        "                    temp_path = f.name\n",
        "                    sf.write(temp_path, final_wave, final_sample_rate)\n",
        "                    remove_silence_for_generated_wav(temp_path)\n",
        "                    final_wave_tensor, _ = torchaudio.load(temp_path)\n",
        "                    final_wave = final_wave_tensor.squeeze().cpu().numpy()\n",
        "            except Exception as e:\n",
        "                print(\"âš ï¸ Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¸ÑˆĞ¸Ğ½Ñ‹ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ:\", e)\n",
        "\n",
        "        progress(0.8, desc=\"ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°...\")\n",
        "        \n",
        "        if stop_generation:\n",
        "            gr.Warning(\"ğŸ›‘ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\")\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "        safe_kwargs = {k: v for k, v in tempfile_kwargs.items() if k != 'delete'}\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(suffix=f\".{audio_format}\", delete=False, **safe_kwargs) as tmp:\n",
        "            temp_output_path = tmp.name\n",
        "\n",
        "        wave = final_wave\n",
        "        if wave.ndim == 1:\n",
        "            channels = 1\n",
        "        else:\n",
        "            channels = min(wave.shape[0], 2)\n",
        "            wave = wave[:channels].T\n",
        "\n",
        "        if np.max(np.abs(wave)) == 0:\n",
        "            wave_int16 = np.zeros(wave.shape, dtype=np.int16)\n",
        "        else:\n",
        "            wave_int16 = np.int16(wave / np.max(np.abs(wave)) * 32767)\n",
        "\n",
        "        audio_segment = AudioSegment(\n",
        "            wave_int16.tobytes(),\n",
        "            frame_rate=final_sample_rate,\n",
        "            sample_width=2,\n",
        "            channels=channels\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            if audio_format == \"mp3\":\n",
        "                audio_segment.export(temp_output_path, format=\"mp3\", bitrate=bitrate)\n",
        "            elif audio_format == \"ogg\":\n",
        "                audio_segment.export(temp_output_path, format=\"ogg\", bitrate=bitrate)\n",
        "            elif audio_format == \"flac\":\n",
        "                audio_segment.export(temp_output_path, format=\"flac\")\n",
        "            else:\n",
        "                audio_segment.export(temp_output_path, format=\"wav\")\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ğ°ÑƒĞ´Ğ¸Ğ¾: {str(e)}\"\n",
        "            gr.Warning(error_msg)\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "        timestamp = int(time.time())\n",
        "        safe_text = f\"audio_{timestamp}\"\n",
        "        final_output_path = os.path.join(os.path.dirname(temp_output_path), f\"{safe_text}.{audio_format}\")\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(final_output_path):\n",
        "                os.remove(final_output_path)\n",
        "            os.rename(temp_output_path, final_output_path)\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°: {str(e)}\"\n",
        "            gr.Warning(error_msg)\n",
        "            return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status\n",
        "\n",
        "        progress(0.9, desc=\"ğŸ“Š Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹...\")\n",
        "\n",
        "        spectrogram_path = None\n",
        "        try:\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False, **tempfile_kwargs) as tmp_spectrogram:\n",
        "                spectrogram_path = tmp_spectrogram.name\n",
        "            \n",
        "            save_spectrogram(combined_spectrogram, spectrogram_path)\n",
        "            print(f\"âœ… Ğ¡Ğ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°: {spectrogram_path}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ: {e}\")\n",
        "            spectrogram_path = None\n",
        "\n",
        "        progress(1.0, desc=\"âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!\")\n",
        "\n",
        "        print(\"=\" * 50)\n",
        "        print(\"ğŸ¯ Ğ”Ğ•Ğ‘ĞĞ“ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ Ğ Ğ¤ĞĞ™Ğ›ĞĞ¥:\")\n",
        "        print(f\"ğŸµ ĞÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»: {final_output_path}\")\n",
        "        print(f\"ğŸµ ĞÑƒĞ´Ğ¸Ğ¾ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚: {os.path.exists(final_output_path)}\")\n",
        "\n",
        "        print(f\"ğŸ“Š Ğ¡Ğ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°: {spectrogram_path}\")\n",
        "        if spectrogram_path:\n",
        "            exists = os.path.exists(spectrogram_path)\n",
        "            print(f\"ğŸ“Š Ğ¡Ğ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚: {exists}\")\n",
        "            if exists:\n",
        "                size = os.path.getsize(spectrogram_path)\n",
        "                print(f\"ğŸ“Š Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹: {size} bytes\")\n",
        "        else:\n",
        "            print(\"ğŸ“Š Ğ¡Ğ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°: None\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # ğŸ”´ ĞĞ§Ğ˜Ğ©ĞĞ•Ğœ ĞšĞ­Ğ¨ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ’ĞĞĞĞ«Ğ¥ ĞĞ£Ğ”Ğ˜Ğ Ğ”Ğ›Ğ¯ Ğ­Ğ¢ĞĞ“Ğ Ğ¤ĞĞ™Ğ›Ğ\n",
        "        if final_output_path in normalized_audio_cache:\n",
        "            try:\n",
        "                cached_path = normalized_audio_cache[final_output_path]\n",
        "                if os.path.exists(cached_path) and cached_path != final_output_path:\n",
        "                    os.remove(cached_path)\n",
        "                del normalized_audio_cache[final_output_path]\n",
        "                print(f\"ğŸ—‘ï¸ Ğ£Ğ´Ğ°Ğ»ĞµĞ½ ĞºÑÑˆ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ´Ğ»Ñ: {final_output_path}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return (\n",
        "            final_output_path,\n",
        "            spectrogram_path,\n",
        "            processed_ref_text_final,\n",
        "            processed_gen_text,\n",
        "            gr.update(value=current_seed),\n",
        "            current_model_status,\n",
        "            gr.update(visible=True),  # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ±Ğ»Ğ¾Ğº Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸\n",
        "            gr.update(value=\"\"),  # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\n",
        "            None  # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¿Ğ¾ĞºĞ° Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ĞĞµĞ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {str(e)}\"\n",
        "        print(f\"Unexpected error in synthesize: {traceback.format_exc()}\")\n",
        "        gr.Warning(error_msg)\n",
        "        return None, None, processed_ref_text, processed_gen_text, gr.update(value=current_seed), current_model_status, gr.update(visible=False), gr.update(value=\"\"), None\n",
        "\n",
        "    finally:\n",
        "        if not stop_generation:\n",
        "            try:\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "            except Exception as e:\n",
        "                print(\"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸:\", e)\n",
        "\n",
        "def update_model_check_status():\n",
        "    \"\"\"ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\"\"\"\n",
        "    try:\n",
        "        whisper_ok = test_whisper_model() if asr_processor else False\n",
        "        \n",
        "        runorm_ok = False\n",
        "        try:\n",
        "            test_text = \"13,8 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ¾Ğ² Ğ»ĞµÑ‚\"\n",
        "            result = normalizer.norm(test_text)\n",
        "            runorm_ok = True\n",
        "        except:\n",
        "            runorm_ok = False\n",
        "        \n",
        "        silero_ok = False\n",
        "        try:\n",
        "            test_word = \"Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚\"\n",
        "            result = accentor(test_word)\n",
        "            silero_ok = True\n",
        "        except:\n",
        "            silero_ok = False\n",
        "        \n",
        "        cuda_ok = torch.cuda.is_available()\n",
        "        \n",
        "        hf_auth_ok = HF_TOKEN is not None\n",
        "        \n",
        "        html = \"\"\"\n",
        "        <div style=\"background: #f8f9fa; padding: 15px; border-radius: 8px;\">\n",
        "            <h3>ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹:</h3>\n",
        "            <ul style=\"list-style: none; padding: 0;\">\n",
        "                <li>ğŸ¯ <strong>CUDA:</strong> {}</li>\n",
        "                <li>ğŸ” <strong>HuggingFace Auth:</strong> {}</li>\n",
        "                <li>ğŸ¤– <strong>Whisper ASR:</strong> {}</li>\n",
        "                <li>ğŸ“ <strong>RUNorm:</strong> {}</li>\n",
        "                <li>ğŸ”Š <strong>Silero Stress:</strong> {}</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\".format(\n",
        "            \"âœ… Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½\" if cuda_ok else \"âŒ ĞĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½\",\n",
        "            \"âœ… ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½\" if hf_auth_ok else \"âŒ ĞĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ°\",\n",
        "            \"âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²\" if whisper_ok else \"âŒ ĞĞµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½\",\n",
        "            \"âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²\" if runorm_ok else \"âš ï¸ Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾\",\n",
        "            \"âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²\" if silero_ok else \"âš ï¸ Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾\"\n",
        "        )\n",
        "        \n",
        "        return gr.update(value=html)\n",
        "    except Exception as e:\n",
        "        return gr.update(value=f\"<div class='model-status model-error'>âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸: {str(e)[:100]}</div>\")\n",
        "\n",
        "def update_token_handler(new_token):\n",
        "    return update_hf_token(new_token)\n",
        "\n",
        "# ================ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯ Ğ”Ğ›Ğ¯ ĞĞ‘ĞĞĞ’Ğ›Ğ•ĞĞ˜Ğ¯ Ğ’Ğ˜Ğ”Ğ˜ĞœĞĞ¡Ğ¢Ğ˜ Ğ‘Ğ˜Ğ¢Ğ Ğ•Ğ™Ğ¢Ğ ================\n",
        "def update_bitrate_visibility(audio_format):\n",
        "    \"\"\"ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²Ğ¸Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ±Ğ¸Ñ‚Ñ€ĞµĞ¹Ñ‚Ğ° Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°\"\"\"\n",
        "    # Ğ‘Ğ¸Ñ‚Ñ€ĞµĞ¹Ñ‚ Ğ½ÑƒĞ¶ĞµĞ½ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ mp3 Ğ¸ ogg Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ²\n",
        "    visible = audio_format in [\"mp3\", \"ogg\"]\n",
        "    return gr.update(visible=visible)\n",
        "\n",
        "# ================ Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• Ğ“Ğ ĞĞ”Ğ˜Ğ Ğ˜ĞĞ¢Ğ•Ğ Ğ¤Ğ•Ğ™Ğ¡Ğ ================\n",
        "\n",
        "with gr.Blocks(title=\"ESpeech-TTS\", css=\"\"\"\n",
        "    .error-markdown {\n",
        "        color: red !important;\n",
        "        font-weight: bold;\n",
        "        text-align: center;\n",
        "        font-size: 18px !important;\n",
        "        margin: 10px 0;\n",
        "        animation: fadeIn 0.3s, fadeOut 0.3s 4.7s forwards;\n",
        "    }\n",
        "    .model-status {\n",
        "        padding: 10px;\n",
        "        border-radius: 5px;\n",
        "        margin: 10px 0;\n",
        "        text-align: center;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    \n",
        "    .norm-button {\n",
        "        font-size: 16px !important;\n",
        "        padding: 12px 24px !important;\n",
        "        background: linear-gradient(45deg, #007bff, #0056b3) !important;\n",
        "        color: white !important;\n",
        "        font-weight: bold !important;\n",
        "        margin: 10px 0 !important;\n",
        "        border-radius: 8px !important;\n",
        "    }\n",
        "    .norm-button:hover {\n",
        "        background: linear-gradient(45deg, #0056b3, #003d82) !important;\n",
        "        transform: translateY(-2px) !important;\n",
        "        box-shadow: 0 4px 8px rgba(0, 86, 179, 0.3) !important;\n",
        "    }\n",
        "    \n",
        "    .step-result-box {\n",
        "        background: #f8f9fa !important;\n",
        "        border-left: 4px solid #28a745 !important;\n",
        "        border-radius: 5px !important;\n",
        "        padding: 10px !important;\n",
        "        margin: 5px 0 !important;\n",
        "    }\n",
        "    .step-label {\n",
        "        font-weight: bold;\n",
        "        color: #155724;\n",
        "    }\n",
        "    .step-text {\n",
        "        color: #0c5460;\n",
        "        font-style: italic;\n",
        "        font-size: 14px;\n",
        "        word-break: break-word;\n",
        "    }\n",
        "    \n",
        "    .stop-button {\n",
        "        background: linear-gradient(45deg, #dc3545, #c82333) !important;\n",
        "        color: white !important;\n",
        "        font-weight: bold !important;\n",
        "        border: none !important;\n",
        "        box-shadow: 0 4px 6px rgba(220, 53, 69, 0.3) !important;\n",
        "    }\n",
        "    .stop-button:hover {\n",
        "        background: linear-gradient(45deg, #c82333, #a71d2a) !important;\n",
        "        transform: translateY(-2px) !important;\n",
        "        box-shadow: 0 6px 8px rgba(220, 53, 69, 0.4) !important;\n",
        "    }\n",
        "    \n",
        "    .model-loaded {\n",
        "        background: #d4edda;\n",
        "        color: #155724;\n",
        "        border: 1px solid #c3e6cb;\n",
        "    }\n",
        "    .model-error {\n",
        "        background: #f8d7da;\n",
        "        color: #721c24;\n",
        "        border: 1px solid #f5c6cb;\n",
        "    }\n",
        "    .model-loading {\n",
        "        background: #fff3cd;\n",
        "        color: #856404;\n",
        "        border: 1px solid #ffeaa7;\n",
        "    }\n",
        "    \n",
        "    .audio-tools-section {\n",
        "        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);\n",
        "        padding: 20px;\n",
        "        border-radius: 10px;\n",
        "        border: 1px solid #dee2e6;\n",
        "        margin: 20px 0;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.05);\n",
        "    }\n",
        "               \n",
        "    /* ĞĞĞ’Ğ«Ğ• Ğ¡Ğ¢Ğ˜Ğ›Ğ˜ Ğ”Ğ›Ğ¯ ĞĞšĞšĞĞ Ğ”Ğ˜ĞĞĞĞ’ */\n",
        "    .normalization-accordion {\n",
        "        margin-top: 20px !important;  /* â† Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ¾Ñ‚ÑÑ‚ÑƒĞ¿ ÑĞ²ĞµÑ€Ñ…Ñƒ */\n",
        "        border: 1px solid #dee2e6 !important;\n",
        "        border-radius: 8px !important;\n",
        "        overflow: hidden !important;\n",
        "    }\n",
        "\n",
        "    .normalization-accordion .gr-accordion {\n",
        "        background: #f8f9fa !important;\n",
        "    }\n",
        "\n",
        "    .normalization-accordion .gr-accordion-open {\n",
        "        background: #e9ecef !important;\n",
        "    }\n",
        "\n",
        "    /* Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ñ‹Ğ¶Ğ¾Ğº Ñƒ Ğ²ÑĞµÑ… ĞºĞ½Ğ¾Ğ¿Ğ¾Ğº Ğ¿Ñ€Ğ¸ Ğ½Ğ°Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğ¸ */\n",
        "    .analyze-button:hover,\n",
        "    .normalize-button:hover {\n",
        "        transform: none !important;  /* â† Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ñ‹Ğ¶Ğ¾Ğº */\n",
        "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2) !important;\n",
        "    }\n",
        "    \n",
        "    .loudness-visualization {\n",
        "        margin: 15px 0;\n",
        "        padding: 15px;\n",
        "        background: white;\n",
        "        border-radius: 8px;\n",
        "        border: 1px solid #ced4da;\n",
        "    }\n",
        "    \n",
        "    .normalized-audio-section {\n",
        "        background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);\n",
        "        padding: 15px;\n",
        "        border-radius: 8px;\n",
        "        border: 2px solid #28a745;\n",
        "        margin: 15px 0;\n",
        "    }\n",
        "    \n",
        "    .analyze-button {\n",
        "        background: linear-gradient(45deg, #17a2b8, #138496) !important;\n",
        "        color: white !important;\n",
        "        font-weight: bold !important;\n",
        "        padding: 10px 20px !important;\n",
        "        border-radius: 6px !important;\n",
        "    }\n",
        "    .analyze-button:hover {\n",
        "        background: linear-gradient(45deg, #138496, #117a8b) !important;\n",
        "        box-shadow: 0 4px 8px rgba(23, 162, 184, 0.3) !important;\n",
        "    }\n",
        "    \n",
        "    .normalize-button {\n",
        "        background: linear-gradient(45deg, #ffc107, #e0a800) !important;\n",
        "        color: white !important;\n",
        "        font-weight: bold !important;\n",
        "        padding: 10px 20px !important;\n",
        "        border-radius: 6px !important;\n",
        "    }\n",
        "    .normalize-button:hover {\n",
        "        background: linear-gradient(45deg, #e0a800, #d39e00) !important;\n",
        "        box-shadow: 0 4px 8px rgba(255, 193, 7, 0.3) !important;\n",
        "    }\n",
        "    \n",
        "    @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }\n",
        "    @keyframes fadeOut { from { opacity: 1; } to { opacity: 0; } }\n",
        "    \"\"\") as app:\n",
        "    \n",
        "    gr.Markdown(\"# ğŸ¤ ESpeech-TTS - Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾\")\n",
        "\n",
        "    # ğŸ”´ Ğ‘Ğ›ĞĞš Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡Ğ ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™\n",
        "    with gr.Accordion(\"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\", open=False):\n",
        "        model_check_status = gr.HTML(\n",
        "            value=\"<div class='model-status model-loading'>ğŸ”„ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹...</div>\"\n",
        "        )\n",
        "        check_models_btn = gr.Button(\"ğŸ”„ ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\", variant=\"secondary\")\n",
        "\n",
        "    # ğŸ”´ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ Ğ ĞĞ’Ğ¢ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ˜\n",
        "    auth_status_text = \"âœ… ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ HuggingFace Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ°!\" if HF_TOKEN else \"âš ï¸ ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ HuggingFace Ğ½Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ°. Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹.\"\n",
        "    gr.Markdown(f\"**ğŸ” Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:** {auth_status_text}\")\n",
        "\n",
        "    gr.Markdown(\"ğŸ’¡ **Ğ¡Ğ¾Ğ²ĞµÑ‚:** Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ» '+' Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, 'Ğ¿Ñ€Ğ¸Ğ²+ĞµÑ‚')\")\n",
        "    gr.Markdown(\"ğŸ² **Ğ¡Ğ¾Ğ²ĞµÑ‚:** Seed Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµÑ‚ Ğ·Ğ° Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. Ğ’Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ğ¾Ğ´Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ´Ğ»Ñ ÑĞµĞ±Ñ ÑƒĞ´Ğ°Ñ‡Ğ½Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ»Ğ¸ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ€Ğ°Ğ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ seed\")\n",
        "    gr.Markdown(\"ğŸš€ **CUDA Required:** This application requires GPU with CUDA support\")\n",
        "\n",
        "    # ğŸ”´ Ğ‘Ğ›ĞĞš Ğ”Ğ›Ğ¯ Ğ›ĞĞšĞĞ›Ğ¬ĞĞ«Ğ¥ ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™\n",
        "    with gr.Accordion(\"ğŸ”§ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\", open=False):\n",
        "        gr.Markdown(\"### ğŸ” ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ° HuggingFace\")\n",
        "        gr.Markdown(\"Ğ¢Ğ¾ĞºĞµĞ½ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¼ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸ÑĞ¼ Ğ½Ğ° HuggingFace\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            hf_token_input = gr.Textbox(\n",
        "                label=\"HuggingFace Token\",\n",
        "                placeholder=\"hf_xxxxxxxxxxxxxxxxxxxx\",\n",
        "                type=\"password\",\n",
        "                scale=4\n",
        "            )\n",
        "            update_token_btn = gr.Button(\"ğŸ” ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½\", variant=\"secondary\", scale=1)\n",
        "            token_status = gr.HTML(visible=False)\n",
        "        \n",
        "        gr.Markdown(\"### ğŸ“ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\")\n",
        "        with gr.Row():\n",
        "            local_model_path = gr.Textbox(\n",
        "                label=\"ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\",\n",
        "                placeholder=\"hf://SWivid/F5-TTS/F5TTS_v1_Base/model_1250000.safetensors Ğ¸Ğ»Ğ¸ /path/to/model.safetensors\",\n",
        "                scale=3\n",
        "            )\n",
        "            local_vocab_path = gr.Textbox(\n",
        "                label=\"ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\", \n",
        "                placeholder=\"hf://SWivid/F5-TTS/F5TTS_v1_Base/vocab.txt Ğ¸Ğ»Ğ¸ /path/to/vocab.txt\",\n",
        "                scale=3\n",
        "            )\n",
        "            local_model_name = gr.Textbox(\n",
        "                label=\"Ğ˜Ğ¼Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\",\n",
        "                placeholder=\"My Local Model\",\n",
        "                scale=2\n",
        "            )\n",
        "        with gr.Row():\n",
        "            add_local_model_btn = gr.Button(\"â• Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\", variant=\"secondary\")\n",
        "            local_model_status = gr.HTML(visible=False)\n",
        "\n",
        "    # ğŸ”´ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ ĞœĞĞ”Ğ•Ğ›Ğ˜\n",
        "    all_models = get_all_models_config()\n",
        "    initial_model = list(all_models.keys())[0] if all_models else \"ESpeech-TTS-1_SFT-95K\"\n",
        "    initial_status = update_model_loading_status(initial_model)\n",
        "\n",
        "    model_status = gr.HTML(\n",
        "        value=initial_status[\"value\"],\n",
        "        visible=initial_status[\"visible\"]\n",
        "    )\n",
        "\n",
        "    # ğŸ”´ ĞĞ¡ĞĞĞ’ĞĞ«Ğ• ĞŸĞĞ›Ğ¯ Ğ’Ğ’ĞĞ”Ğ\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            model_choice = gr.Dropdown(\n",
        "                choices=list(all_models.keys()),\n",
        "                value=initial_model,\n",
        "                label=\"Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\",\n",
        "                info=\"ğŸŒ HuggingFace Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ»Ğ¸ ğŸ”§ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\"\n",
        "            )\n",
        "            \n",
        "            load_model_btn = gr.Button(\"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\", variant=\"secondary\")\n",
        "            clear_models_btn = gr.Button(\"ğŸ—‘ï¸ ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\", variant=\"stop\")\n",
        "            \n",
        "        with gr.Column():\n",
        "            ref_audio_input = gr.Audio(label=\"Reference Audio\", type=\"filepath\")\n",
        "\n",
        "            with gr.Row():\n",
        "                check_audio_btn = gr.Button(\"ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾\", variant=\"secondary\")\n",
        "                transcribe_btn = gr.Button(\"ğŸ¤ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾\", variant=\"secondary\")\n",
        "            \n",
        "            audio_check_status = gr.HTML(visible=False)\n",
        "            \n",
        "            ref_text_input = gr.Textbox(\n",
        "                label=\"Reference Text\",\n",
        "                lines=2,\n",
        "                placeholder=\"Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚ĞµĞºÑÑ‚ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ¸Ğ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸\"\n",
        "            )\n",
        "            \n",
        "            normalize_ref_btn = gr.Button(\"ğŸ“ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½Ñ (RUNorm â†’ Silero)\", \n",
        "                                        variant=\"secondary\", \n",
        "                                        size=\"lg\",\n",
        "                                        elem_classes=\"norm-button\")\n",
        "\n",
        "        with gr.Column():\n",
        "            gen_text_input = gr.Textbox(\n",
        "                label=\"Text to Generate\",\n",
        "                lines=5,\n",
        "                max_lines=20,\n",
        "                placeholder=\"Enter text to synthesize...\"\n",
        "            )\n",
        "    \n",
        "            normalize_gen_btn = gr.Button(\"âœï¸ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚ (RUNorm â†’ Silero)\", \n",
        "                                        variant=\"secondary\", \n",
        "                                        size=\"lg\",\n",
        "                                        elem_classes=\"norm-button\")\n",
        "\n",
        "    # ğŸ”´ ĞŸĞ¾Ğ»Ñ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\n",
        "    with gr.Accordion(\"ğŸ“Š ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ°\", open=False):\n",
        "        ref_norm_step1 = gr.Textbox(label=\"Ğ¨Ğ°Ğ³ 1: RUNorm Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚\", interactive=False, visible=True)\n",
        "        ref_norm_step2 = gr.Textbox(label=\"Ğ¨Ğ°Ğ³ 2: Silero Stress Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚\", interactive=False, visible=True)\n",
        "\n",
        "    with gr.Accordion(\"ğŸ“Š ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°\", open=False):\n",
        "        gen_norm_step1 = gr.Textbox(label=\"Ğ¨Ğ°Ğ³ 1: RUNorm Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚\", interactive=False, visible=True)\n",
        "        gen_norm_step2 = gr.Textbox(label=\"Ğ¨Ğ°Ğ³ 2: Silero Stress Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚\", interactive=False, visible=True)\n",
        "\n",
        "    # ğŸ”´ Ğ”ĞĞŸĞĞ›ĞĞ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜\n",
        "    with gr.Accordion(\"Advanced Settings\", open=False):\n",
        "        with gr.Row():\n",
        "            seed_input = gr.Number(label=\"Seed (random)\", value=get_current_seed_display(), precision=0)\n",
        "            remember_seed_checkbox = gr.Checkbox(label=\"ğŸ’¾ Ğ—Ğ°Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ¾Ñ‚ seed\", value=False)\n",
        "            remove_silence = gr.Checkbox(label=\"Remove Silences\", value=False)\n",
        "        with gr.Row():\n",
        "            speed_slider = gr.Slider(label=\"Speed\", minimum=0.3, maximum=2.0, value=1.0, step=0.1)\n",
        "            nfe_slider = gr.Slider(label=\"NFE Steps\", minimum=4, maximum=64, value=48, step=2)\n",
        "        with gr.Row():\n",
        "            cross_fade_slider = gr.Slider(label=\"Cross-Fade Duration (s)\", minimum=0.0, maximum=1.0, value=0.15, step=0.01)\n",
        "            sway_sampling_slider = gr.Slider(label=\"Sway Sampling Coef\", minimum=-1, maximum=1, value=-1, step=0.1)\n",
        "        with gr.Row():\n",
        "            cfg_strength_slider = gr.Slider(label=\"CFG Strength\", minimum=0.5, maximum=5.0, value=2.0, step=0.1)\n",
        "        with gr.Row():\n",
        "            audio_format = gr.Radio([\"wav\", \"mp3\", \"ogg\", \"flac\"], label=\"Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚\", value=\"wav\")\n",
        "            bitrate = gr.Radio([\"128k\", \"192k\", \"320k\"], label=\"Ğ‘Ğ¸Ñ‚Ñ€ĞµĞ¹Ñ‚ (mp3/ogg)\", value=\"192k\", visible=lambda fmt: fmt in [\"mp3\", \"ogg\"])\n",
        "\n",
        "    # ğŸ”´ ĞšĞĞĞŸĞšĞ˜ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ Ğ˜ ĞĞ¡Ğ¢ĞĞĞĞ’ĞšĞ˜\n",
        "    with gr.Row():\n",
        "        generate_btn = gr.Button(\"ğŸ¤ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
        "        stop_btn = gr.Button(\"ğŸ›‘ Stop Generation\", variant=\"stop\", size=\"lg\")\n",
        "\n",
        "    # ğŸ”´ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜\n",
        "    with gr.Row():\n",
        "        audio_output = gr.Audio(label=\"ğŸ§ Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾\", type=\"filepath\")\n",
        "        spectrogram_output = gr.Image(label=\"Spectrogram\", type=\"filepath\")\n",
        "\n",
        "    # ğŸ”´ğŸ”´ğŸ”´ ĞĞĞ’Ğ«Ğ™ Ğ‘Ğ›ĞĞš: Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞœĞ•ĞĞ¢Ğ« Ğ”Ğ›Ğ¯ Ğ ĞĞ‘ĞĞ¢Ğ« Ğ¡ ĞĞ£Ğ”Ğ˜Ğ ğŸ”´ğŸ”´ğŸ”´\n",
        "    audio_tools_section = gr.Accordion(\n",
        "        \"ğŸ› ï¸ Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾\", \n",
        "        open=False,  # â† Ğ¡Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ğ¾ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ\n",
        "        visible=False,\n",
        "        elem_classes=\"audio-tools-section\"\n",
        "    )\n",
        "\n",
        "    with audio_tools_section:\n",
        "        # Ğ£Ğ”ĞĞ›Ğ˜Ğ›Ğ˜: gr.Markdown(\"### ğŸ› ï¸ Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾\")\n",
        "        # Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ğ² ÑĞ°Ğ¼Ğ¾Ğ¼ Accordion\n",
        "        \n",
        "        # ğŸ”´ ĞĞĞĞ›Ğ˜Ğ— Ğ“Ğ ĞĞœĞšĞĞ¡Ğ¢Ğ˜\n",
        "        with gr.Row():\n",
        "            analyze_loudness_btn = gr.Button(\"ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸\", variant=\"secondary\", elem_classes=\"analyze-button\")\n",
        "        \n",
        "        loudness_analysis = gr.HTML(label=\"Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸\", visible=False)\n",
        "        \n",
        "        # ğŸ”´ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ĞĞ£Ğ”Ğ˜Ğ - Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°ĞºĞºĞ¾Ñ€Ğ´Ğ¸Ğ¾Ğ½ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸\n",
        "        with gr.Accordion(\"ğŸšï¸ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸\", open=False, elem_classes=\"normalization-accordion\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=2):\n",
        "                    target_loudness = gr.Slider(\n",
        "                        label=\"Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ (dBFS)\",\n",
        "                        minimum=-30,\n",
        "                        maximum=-6,\n",
        "                        value=-16,\n",
        "                        step=0.5,\n",
        "                        info=\"Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ: -16 dBFS Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´ĞºĞ°ÑÑ‚Ğ¾Ğ², -14 dBFS Ğ´Ğ»Ñ Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸, -18 dBFS Ğ´Ğ»Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ĞºĞ½Ğ¸Ğ³\"\n",
        "                    )\n",
        "                    headroom_db = gr.Slider(\n",
        "                        label=\"Ğ—Ğ°Ğ¿Ğ°Ñ Ğ´Ğ¾ ĞºĞ»Ğ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° (dB)\",\n",
        "                        minimum=0.5,\n",
        "                        maximum=3.0,\n",
        "                        value=1.0,\n",
        "                        step=0.1,\n",
        "                        info=\"Ğ—Ğ°Ğ¿Ğ°Ñ Ğ´Ğ¾ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ğ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºĞ¸\"\n",
        "                    )\n",
        "                \n",
        "                with gr.Column(scale=1):\n",
        "                    normalize_audio_btn = gr.Button(\"ğŸšï¸ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ\", variant=\"secondary\", elem_classes=\"normalize-button\")\n",
        "                    normalize_status = gr.HTML(visible=False)\n",
        "        \n",
        "        # ğŸ”´ ĞŸĞ Ğ•Ğ”ĞŸĞ ĞĞ¡ĞœĞĞ¢Ğ  ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ’ĞĞĞĞĞ™ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜\n",
        "        with gr.Group(visible=False, elem_classes=\"normalized-audio-section\") as normalized_audio_section:\n",
        "            gr.Markdown(\"### âœ… ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°!\")\n",
        "            normalized_audio_player = gr.Audio(\n",
        "                label=\"ğŸ§ ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ (ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ‡ĞµÑ€ĞµĞ· Ğ¸ĞºĞ¾Ğ½ĞºÑƒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ ÑĞ¿Ñ€Ğ°Ğ²Ğ°)\",\n",
        "                type=\"filepath\",\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "    # ================ ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜ĞšĞ˜ Ğ¡ĞĞ‘Ğ«Ğ¢Ğ˜Ğ™ ================\n",
        "\n",
        "    # 1. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾\n",
        "    check_audio_btn.click(\n",
        "        fn=check_audio_file,\n",
        "        inputs=[ref_audio_input],\n",
        "        outputs=[audio_check_status]\n",
        "    )\n",
        "    \n",
        "    # 2. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    check_models_btn.click(\n",
        "        fn=update_model_check_status,\n",
        "        outputs=[model_check_status]\n",
        "    )\n",
        "\n",
        "    # 3. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ°\n",
        "    update_token_btn.click(\n",
        "        fn=update_token_handler,\n",
        "        inputs=hf_token_input,\n",
        "        outputs=token_status\n",
        "    )\n",
        "\n",
        "    # 4. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "    add_local_model_btn.click(\n",
        "        fn=add_local_model_with_auth,\n",
        "        inputs=[local_model_path, local_vocab_path, local_model_name, hf_token_input],\n",
        "        outputs=[model_choice, local_model_status]\n",
        "    )\n",
        "\n",
        "    # 5. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    clear_models_btn.click(\n",
        "        fn=clear_loaded_models,\n",
        "        outputs=[model_status, local_model_path, local_vocab_path, local_model_name, model_choice]\n",
        "    )\n",
        "\n",
        "    # 6. ĞĞ²Ñ‚Ğ¾Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğµ\n",
        "    model_choice.change(\n",
        "        fn=on_model_select,\n",
        "        inputs=model_choice,\n",
        "        outputs=model_status\n",
        "    )\n",
        "\n",
        "    # 7. ĞšĞ½Ğ¾Ğ¿ĞºĞ° Ğ¿Ñ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸\n",
        "    load_model_btn.click(\n",
        "        fn=load_model_with_status,\n",
        "        inputs=[model_choice],\n",
        "        outputs=model_status\n",
        "    )\n",
        "\n",
        "    # 8. ĞšĞ½Ğ¾Ğ¿ĞºĞ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸\n",
        "    transcribe_btn.click(\n",
        "        fn=manual_transcribe_audio,\n",
        "        inputs=[ref_audio_input],\n",
        "        outputs=[ref_text_input, audio_check_status]\n",
        "    )\n",
        "\n",
        "    # 9. ĞšĞ½Ğ¾Ğ¿ĞºĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ°\n",
        "    normalize_ref_btn.click(\n",
        "        fn=normalize_ref_text_with_steps,\n",
        "        inputs=[ref_text_input],\n",
        "        outputs=[ref_text_input, ref_norm_step1, ref_norm_step2]\n",
        "    )\n",
        "\n",
        "    # 10. ĞšĞ½Ğ¾Ğ¿ĞºĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸\n",
        "    normalize_gen_btn.click(\n",
        "        fn=lambda text: (\n",
        "            print(\"\\n\" + \"=\"*60),\n",
        "            print(\"ğŸ”´ [COLAB DEBUG] ĞšĞĞĞŸĞšĞ ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ˜ ĞĞĞ–ĞĞ¢Ğ\"),\n",
        "            print(f\"ğŸ“– ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚: '{text}'\"),\n",
        "            print(f\"ğŸ“Š Ğ”Ğ»Ğ¸Ğ½Ğ° Ñ‚ĞµĞºÑÑ‚Ğ°: {len(text) if text else 0}\"),\n",
        "            print(\"=\"*60),\n",
        "            \n",
        "            print(\"ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹...\"),\n",
        "            print(f\"  â€¢ RUNorm Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {hasattr(normalizer, 'norm')}\"),\n",
        "            print(f\"  â€¢ Silero Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {accentor is not None}\"),\n",
        "            \n",
        "            (print(\"ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°:\"),\n",
        "            print(f\"  â€¢ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ†Ğ¸Ñ„Ñ€Ñ‹: {any(char.isdigit() for char in text)}\"),\n",
        "            print(f\"  â€¢ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ (+): {'+' in text}\"),\n",
        "            print(f\"  â€¢ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ÑĞºĞ¾Ğ±ĞºĞ¸ []: {'[' in text or ']' in text}\")) if text else None,\n",
        "            \n",
        "            result := normalize_gen_text_with_steps(text),\n",
        "            \n",
        "            print(\"\\n\" + \"=\"*60),\n",
        "            print(\"âœ… [DEBUG COLAB] ĞĞĞ ĞœĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ\"),\n",
        "            print(f\"ğŸ“¤ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ÑÑ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ\"),\n",
        "            print(f\"ğŸ“ Ğ¨Ğ°Ğ³ 1: {result[1][:50]}...\"),\n",
        "            print(f\"ğŸ“ Ğ¨Ğ°Ğ³ 2: {result[2][:50]}...\"),\n",
        "            print(\"=\"*60),\n",
        "            \n",
        "            result\n",
        "        )[-1],\n",
        "        inputs=[gen_text_input],\n",
        "        outputs=[gen_text_input, gen_norm_step1, gen_norm_step2]\n",
        "    )\n",
        "\n",
        "    # 11. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°\n",
        "    audio_format.change(\n",
        "        update_bitrate_visibility,\n",
        "        inputs=audio_format,\n",
        "        outputs=bitrate\n",
        "    )\n",
        "\n",
        "    # 12. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸\n",
        "    stop_btn.click(\n",
        "        fn=stop_generation_process,\n",
        "        outputs=None,\n",
        "        queue=False\n",
        "    )\n",
        "\n",
        "    # 13. ğŸ”´ ĞĞĞ’Ğ«Ğ™ ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜Ğš: ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾\n",
        "    def analyze_audio_handler(audio_path):\n",
        "        \"\"\"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾\"\"\"\n",
        "        if not audio_path:\n",
        "            return (\n",
        "                gr.update(visible=False),\n",
        "                gr.update(value=\"âŒ ĞĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°\", visible=True)\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            loudness, max_loudness, dynamic_range, analysis_report, visualization = analyze_audio_loudness(audio_path)\n",
        "            \n",
        "            if analysis_report:\n",
        "                return (\n",
        "                    gr.update(value=analysis_report, visible=True),\n",
        "                    gr.update(visible=True)\n",
        "                )\n",
        "            else:\n",
        "                return (\n",
        "                    gr.update(visible=False),\n",
        "                    gr.update(value=\"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾\", visible=True)\n",
        "                )\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸: {e}\")\n",
        "            return (\n",
        "                gr.update(visible=False),\n",
        "                gr.update(value=f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {str(e)[:100]}\", visible=True)\n",
        "            )\n",
        "\n",
        "    analyze_loudness_btn.click(\n",
        "        fn=analyze_audio_handler,\n",
        "        inputs=[audio_output],\n",
        "        outputs=[loudness_analysis, normalize_status]\n",
        "    )\n",
        "\n",
        "    # 14. ğŸ”´ ĞĞĞ’Ğ«Ğ™ ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜Ğš: ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾\n",
        "    def normalize_audio_handler(audio_path, target_loudness, headroom_db_value):\n",
        "        \"\"\"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾\"\"\"\n",
        "        if not audio_path:\n",
        "            return (\n",
        "                gr.update(visible=False),\n",
        "                gr.update(value=\"âŒ ĞĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ´Ğ»Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\", visible=True),\n",
        "                None,\n",
        "                gr.update(visible=False)\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¸Ğ· Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°\n",
        "            audio_format_from_file = os.path.splitext(audio_path)[1].lower().replace('.', '')\n",
        "            if audio_format_from_file not in ['wav', 'mp3', 'ogg', 'flac']:\n",
        "                audio_format_from_file = 'wav'\n",
        "            \n",
        "            print(f\"ğŸšï¸ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾. Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: {audio_format_from_file}\")\n",
        "            print(f\"ğŸ¯ Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ: {target_loudness} dBFS\")\n",
        "            print(f\"ğŸ›¡ï¸ Ğ—Ğ°Ğ¿Ğ°Ñ Ğ´Ğ¾ ĞºĞ»Ğ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ°: {headroom_db_value} dB\")\n",
        "            \n",
        "            normalized_path, report = normalize_audio_enhanced(\n",
        "                audio_path, \n",
        "                target_loudness=target_loudness,\n",
        "                headroom=headroom_db_value,\n",
        "                audio_format=audio_format_from_file\n",
        "            )\n",
        "            \n",
        "            if normalized_path and os.path.exists(normalized_path):\n",
        "                return (\n",
        "                    gr.update(value=report, visible=True),\n",
        "                    gr.update(value=\"âœ… ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!\", visible=True),\n",
        "                    normalized_path,\n",
        "                    gr.update(visible=True)\n",
        "                )\n",
        "            else:\n",
        "                return (\n",
        "                    gr.update(visible=False),\n",
        "                    gr.update(value=f\"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾: {report}\", visible=True),\n",
        "                    None,\n",
        "                    gr.update(visible=False)\n",
        "                )\n",
        "                \n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {str(e)[:100]}\"\n",
        "            print(f\"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {traceback.format_exc()}\")\n",
        "            return (\n",
        "                gr.update(visible=False),\n",
        "                gr.update(value=error_msg, visible=True),\n",
        "                None,\n",
        "                gr.update(visible=False)\n",
        "            )\n",
        "\n",
        "    normalize_audio_btn.click(\n",
        "        fn=normalize_audio_handler,\n",
        "        inputs=[audio_output, target_loudness, headroom_db],\n",
        "        outputs=[loudness_analysis, normalize_status, normalized_audio_player, normalized_audio_section]\n",
        "    )\n",
        "\n",
        "    # 16. ğŸ”´ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞ«Ğ™ ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜Ğš Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜\n",
        "    generate_btn.click(\n",
        "        synthesize,\n",
        "        inputs=[\n",
        "            ref_audio_input,\n",
        "            ref_text_input,\n",
        "            gen_text_input,\n",
        "            remove_silence,\n",
        "            seed_input,\n",
        "            remember_seed_checkbox,\n",
        "            model_choice,\n",
        "            cross_fade_slider,\n",
        "            nfe_slider,\n",
        "            speed_slider,\n",
        "            sway_sampling_slider,\n",
        "            cfg_strength_slider,\n",
        "            audio_format,\n",
        "            bitrate,\n",
        "        ],\n",
        "        outputs=[\n",
        "            audio_output, \n",
        "            spectrogram_output, \n",
        "            ref_text_input, \n",
        "            gen_text_input, \n",
        "            seed_input,\n",
        "            model_status,\n",
        "            audio_tools_section,  # â† Ğ’ĞĞ—Ğ’Ğ ĞĞ©ĞĞ•Ğœ Ğ¡ĞĞœ ĞšĞĞœĞŸĞĞĞ•ĞĞ¢, Ğ½Ğµ gr.update()\n",
        "            normalize_status,\n",
        "            normalized_audio_player\n",
        "        ]\n",
        "    ).then(\n",
        "        # ĞŸĞ¾ÑĞ»Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞĞ¢ĞšĞ Ğ«Ğ’ĞĞ•Ğœ Ğ°ĞºĞºĞ¾Ñ€Ğ´Ğ¸Ğ¾Ğ½\n",
        "        fn=lambda: gr.update(open=True),\n",
        "        inputs=[],\n",
        "        outputs=[audio_tools_section],\n",
        "        queue=False\n",
        "    ).then(\n",
        "        # Ğ¡ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ¹ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\n",
        "        fn=lambda: (\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "        ),\n",
        "        outputs=[loudness_analysis, normalized_audio_section]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸš€ ĞŸĞĞ”Ğ“ĞĞ¢ĞĞ’ĞšĞ Ğš Ğ—ĞĞŸĞ£Ğ¡ĞšĞ£\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    models_ok = check_all_models_before_launch()\n",
        "    \n",
        "    if models_ok:\n",
        "        print(\"\\nâœ… Ğ’ÑĞµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ñ‹, Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ...\")\n",
        "        app.launch(share=True)\n",
        "    else:\n",
        "        print(\"\\nâš ï¸ ĞĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾\")\n",
        "        print(\"   Ğ˜Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ\")\n",
        "        app.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
